{
    "document_id": "D-2023-2429",
    "LinkTitle": "D-2023-2429",
    "file_name": "D-2023-2429.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2023-2429.pdf",
    "metadata": {
        "title": "Identifying Dyslexia Earlier in Life",
        "author": "N/A",
        "num_pages": 6
    },
    "content": {
        "full_text": "Identifying Dyslexia Earlier in Life\nIdentifying Dyslexia Earlier in Life\nA Data Management Plan created using DMPonline.be\nCreators: \nCreators: \nWendy Verheijen, Marlies Gillis\nAffiliation: \nAffiliation: \nKU Leuven (KUL)\nTemplate: \nTemplate: \nKU Leuven BOF-IOF\nProject Administrator:\nProject Administrator:\n \nWendy Verheijen\nGrant number / URL: \nGrant number / URL: \nPDMT1/23/011\nID: \nID: \n202885\nStart date: \nStart date: \n01-11-2023\nEnd date: \nEnd date: \n30-09-2024\nProject abstract:\nProject abstract:\nDiagnosing dyslexia relies on a waiting-to-fail approach, i.e., the diagnosis relies on persistent struggles with reading and writing after some years of\nreading instruction. By earlier identifying children with a high risk for developing dyslexia, one could start earlier and more effective intervention so\nthat the impact of dyslexia on an individual's life is reduced. Although dyslexia manifests as a reading and writing disorder, it is thought to be rooted in\nreduced auditory temporal processing. Therefore, investigating the neural responses to sounds might be key to identifying dyslexia earlier in life. We\naim to distinguish children with dyslexia from neurotypical children using a wide set of neural metrics derived from two novel approaches, i.e., (1)\nneural tracking and (2)\nfunctional connectivity measures applied to M/EEG data of children listening to natural speech. These approaches allow us to investigate the temporal\ncharacteristics of the neural responses and how these are related to the neural connectivity networks across the hierarchical levels of neural speech\nprocessing ranging from purely acoustic processing to linguistic speech processing. Using the combination of these approaches on different unique\ndatasets allows us to identify dyslexia objectively using neural metrics.\nLast modified: \nLast modified: \n16-01-2024\nCreated using DMPonline.be. Last modiﬁed 16 January 2024\n1 of 6\nIdentifying Dyslexia Earlier in Life\nIdentifying Dyslexia Earlier in Life\nResearch Data Summary\nResearch Data Summary\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or\ndata type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate\ndata type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate\nwhether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its\nwhether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its\ntechnical format (file extension), and an estimate of the upper limit of the volume of the data.\ntechnical format (file extension), and an estimate of the upper limit of the volume of the data.\nDataset name / ID\nDescription\nNew or\nreuse\nDigital\nor\nPhysical\ndata\nData Type\nFile\nformat\nData\nvolume\nPhysical\nvolume\nCTSiN\nThe role of reading experience\nin atypical cortical tracking of\nspeech and speech-in-noise in\ndyslexia\nOpen source available dataset which contains MEG\ndata of children with and without dyslexia listening to\nspeech (presented with or without lip movements /\nwith or without noise)\n \nE\nE\n(existing)\n(existing)\n \nD\nD\n(digital)\n(digital)\nA\nA\nudiovisual\nS\nS\nound\nN\nN\numerical\nT\nT\nextual\n .fif\n \n<300GB\n \nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data\nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data\ntype:\ntype:\nThe dataset (CTSiN) is available through this link: https://osf.io/9ce5t/\nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, refer to\nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, refer to\nspecific datasets or data types when appropriate and provide the relevant ethical approval number.\nspecific datasets or data types when appropriate and provide the relevant ethical approval number.\nYes, human subject data (Provide SMEC or EC approval number below)\nThe study which collected the dataset was approved by the local ethics committee (Comité d’Ethique Hospitalo-Facultaire Erasme-ULB,\n021/406, Brussels, Belgium; approval number: P2017/081). Since this project only will reuse the existing data from the public available\ndataset, no ethical approval by EC is required (confirmed by EC Leuven on 20/12/2023).\nWill you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven or UZ\nWill you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven or UZ\nLeuven privacy register number (G or S number).\nLeuven privacy register number (G or S number).\nNo\nIn this project no additional data are collected. However, we still filled in a PRET form:  PRET G-number: G-2023-7308\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)?  If so,\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)?  If so,\nplease comment per dataset or data type where appropriate. \nplease comment per dataset or data type where appropriate. \nNo\nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer agreements,\nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer agreements,\nResearch collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place.\nResearch collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place.\nNo\nCreated using DMPonline.be. Last modiﬁed 16 January 2024\n2 of 6\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please\nexplain in the comment section to what data they relate and which restrictions will be asserted.\nexplain in the comment section to what data they relate and which restrictions will be asserted.\nNo\nDocumentation and Metadata\nDocumentation and Metadata\nClearly describe what approach will be followed to capture the accompanying information necessary to keep \nClearly describe what approach will be followed to capture the accompanying information necessary to keep \ndata understandable and usable\ndata understandable and usable\n,\n,\nfor yourself and others, now and in the future (e.g. in terms of documentation levels and types required, procedures used, Electronic Lab\nfor yourself and others, now and in the future (e.g. in terms of documentation levels and types required, procedures used, Electronic Lab\nNotebooks, README.txt files, codebook.tsv etc. where this information is recorded). \nNotebooks, README.txt files, codebook.tsv etc. where this information is recorded). \nCurrently, the data is stored in a custom format.\nBefore starting the first analysis, we will convert the dataset to BIDS structure (https://bids.neuroimaging.io/). The BIDS data structure is an\ninternationally recognized dataset format to improve replicability.\nThe generated script will be stored on GitLab. \nWill a metadata standard be used to make it easier to \nWill a metadata standard be used to make it easier to \nfind and reuse the data\nfind and reuse the data\n?  \n?  \nIf so, please specify which metadata standard will be used. \nIf so, please specify which metadata standard will be used. \nIf not, please specify which metadata will be created to make the data easier to find and reuse. \nIf not, please specify which metadata will be created to make the data easier to find and reuse. \nYes\nThe BIDS data structure requires some additional metadata files to increase readability and reproducabitiy of the dataset. As far as they are\navailable, these metadata will be added. \nData Storage & Back-up during the Research Project\nData Storage & Back-up during the Research Project\nWhere will the data be stored?\nWhere will the data be stored?\nOther (specify below)\nThe raw data is stored online (https://osf.io/9ce5t/). In order to analyze the data, some files will need to be stored on the (encrypted) hard drive\n(since calculations from a non-local source are too slow and lead to computational failures).\nA copy of the data will be stored on KU Leuven managed drives. \nThe generated script will be stored on Gitlab. Important intermediate results will be saved on OneDrive. \nHow will the data be backed up?\nHow will the data be backed up?\nPersonal back-ups I make (specify below)\nA backup on the encrypted local hard drive is taken automatically twice a week. \nGitLab manages the code and its versions, and therefore, also functions as a back up of all code to generate intermediate results. \nIs there currently sufficient storage & backup capacity during the project? \nIs there currently sufficient storage & backup capacity during the project? \nCreated using DMPonline.be. Last modiﬁed 16 January 2024\n3 of 6\nIf no or insufficient storage or backup capacities are available, explain how this will be taken care of. \nIf no or insufficient storage or backup capacities are available, explain how this will be taken care of. \nYes\nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? \nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? \nDuring analysis, the data is stored on the researcher’s hard drive, which is encrypted.\nAt the beginning of the project, the dataset will be copied onto the local hard drive and the KU Leuven managed drive to prevent changes in\nthe online dataset from affecting the planned project. \nThe scripts are backed up through GitLab, which is accessible to all team members and PI, but, not for unauthorized persons. \nHowever, since the raw data are publicly available, no additional measures are necessary. \nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nNo additional costs are expected.\nOneDrive is maintained centrally by KU Leuven. The personal hard drive has already been purchased. KU Leuven researchers can make use of\nthe Gitlab services free of charge. \nData Preservation after the end of the Research Project\nData Preservation after the end of the Research Project\nWhich data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of the project? \nWhich data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of the project? \nIn case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, institutional\nIn case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, institutional\npolicies...).\npolicies...).\nAll data will be preserved for 10 years according to KU Leuven RDM policy\nWhere will these data be archived (stored and curated for the long-term)? \nWhere will these data be archived (stored and curated for the long-term)? \nOther (specify below)\nThe data is stored online (https://osf.io/9ce5t/). \nA copy of the data will be stored on KU Leuven maintained drives. \nAfter finalizing the study, the caches and results will be stored on KU Leuven-managed drives (for min. 10 years). The processing code will be\nstored in Gitlab (and a Gitlab tag will be generated). \nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\nExpected costs are: €11,384/year/100GB * 3 * 10years = €341.52. These costs will be covered by a reserve credit (as the annual costs are\nrather low). \nData Sharing and Reuse\nData Sharing and Reuse\nWill the data (or part of the data) be made available for reuse after/during the project?  \nWill the data (or part of the data) be made available for reuse after/during the project?  \nPlease explain per dataset or data type which data will be made available.\nPlease explain per dataset or data type which data will be made available.\nCreated using DMPonline.be. Last modiﬁed 16 January 2024\n4 of 6\nOther (specify below)\nThis dataset is already open-accessible data. This dataset can be found here: https://osf.io/9ce5t/\nRegarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the\nresults will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. \nIf access is restricted, please specify who will be able to access the data and under what conditions. \nIf access is restricted, please specify who will be able to access the data and under what conditions. \nNA\nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal\nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal\nrestrictions)? \nrestrictions)? \nPlease explain per dataset or data type where appropriate.\nPlease explain per dataset or data type where appropriate.\nNo\nWhere will the data be made available?  \nWhere will the data be made available?  \nIf already known, please provide a repository per dataset or data type.\nIf already known, please provide a repository per dataset or data type.\nOther (specify below)\nThe data is readily available on: https://osf.io/9ce5t/\nRegarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the\nresults will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. \nWhen will the data be made available? \nWhen will the data be made available? \nOther (specify below)\nThe data is readily available on: https://osf.io/9ce5t/\nRegarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the\nresults will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. \nWhich data usage licenses are you going to provide? \nWhich data usage licenses are you going to provide? \nIf none, please explain why. \nIf none, please explain why. \nOther (specify below)\nRegarding the raw data, available in the public database, the license is not specified on https://osf.io/9ce5t/\nRegarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the\nresults will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. \nDo you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please provide it\nDo you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please provide it\nhere. \nhere. \nNo\nCreated using DMPonline.be. Last modiﬁed 16 January 2024\n5 of 6\nWhat are the expected costs for data sharing? How will these costs be covered?  \nWhat are the expected costs for data sharing? How will these costs be covered?  \nNA. The data is readily available on: https://osf.io/9ce5t/\nResponsibilities\nResponsibilities\nWho will manage data documentation and metadata during the research project? \nWho will manage data documentation and metadata during the research project? \nI (Marlies Gillis) will convert the data set into BIDS structure and create the metadata to increase the readability of the dataset. The end-\nresponsibility lies with professor Francart (PI). \nWho will manage data storage and backup during the research project? \nWho will manage data storage and backup during the research project? \nI (Marlies Gillis) perform an automatic backup at least twice a week of the encrypted hard drive and on OneDrive. Similarly, I will store the\ncode on Gitlab.\nThe data is also stored online at https://osf.io/9ce5t/\nWho will manage data preservation and sharing? \nWho will manage data preservation and sharing? \nRegarding the raw data available in the public database, ULB professor Mathieu Bourguignon is responsible for data preservation and sharing.\nIf the data of the current project is shared, I (Marlies Gillis) will manage the data sharing. The end-responsibility lies with professor Francart\n(PI). \nWho will update and implement this DMP? \nWho will update and implement this DMP? \nI (Marlies Gillis) will update and implement this DMP.\nCreated using DMPonline.be. Last modiﬁed 16 January 2024\n6 of 6"
    },
    "clean_full_text": "Identifying Dyslexia Earlier in Life Identifying Dyslexia Earlier in Life A Data Management Plan created using DMPonline.be Creators: Creators: Wendy Verheijen, Marlies Gillis Affiliation: Affiliation: KU Leuven (KUL) Template: Template: KU Leuven BOF-IOF Project Administrator: Project Administrator: Wendy Verheijen Grant number / URL: Grant number / URL: PDMT1/23/011 ID: ID: 202885 Start date: Start date: 01-11-2023 End date: End date: 30-09-2024 Project abstract: Project abstract: Diagnosing dyslexia relies on a waiting-to-fail approach, i.e., the diagnosis relies on persistent struggles with reading and writing after some years of reading instruction. By earlier identifying children with a high risk for developing dyslexia, one could start earlier and more effective intervention so that the impact of dyslexia on an individual's life is reduced. Although dyslexia manifests as a reading and writing disorder, it is thought to be rooted in reduced auditory temporal processing. Therefore, investigating the neural responses to sounds might be key to identifying dyslexia earlier in life. We aim to distinguish children with dyslexia from neurotypical children using a wide set of neural metrics derived from two novel approaches, i.e., (1) neural tracking and (2) functional connectivity measures applied to M/EEG data of children listening to natural speech. These approaches allow us to investigate the temporal characteristics of the neural responses and how these are related to the neural connectivity networks across the hierarchical levels of neural speech processing ranging from purely acoustic processing to linguistic speech processing. Using the combination of these approaches on different unique datasets allows us to identify dyslexia objectively using neural metrics. Last modified: Last modified: 16-01-2024 Created using DMPonline.be. Last modiﬁed 16 January 2024 1 of 6 Identifying Dyslexia Earlier in Life Identifying Dyslexia Earlier in Life Research Data Summary Research Data Summary List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its whether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data. technical format (file extension), and an estimate of the upper limit of the volume of the data. Dataset name / ID Description New or reuse Digital or Physical data Data Type File format Data volume Physical volume CTSiN The role of reading experience in atypical cortical tracking of speech and speech-in-noise in dyslexia Open source available dataset which contains MEG data of children with and without dyslexia listening to speech (presented with or without lip movements / with or without noise) E E (existing) (existing) D D (digital) (digital) A A udiovisual S S ound N N umerical T T extual .fif <300GB If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data type: type: The dataset (CTSiN) is available through this link: https://osf.io/9ce5t/ Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, refer to Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, refer to specific datasets or data types when appropriate and provide the relevant ethical approval number. specific datasets or data types when appropriate and provide the relevant ethical approval number. Yes, human subject data (Provide SMEC or EC approval number below) The study which collected the dataset was approved by the local ethics committee (Comité d’Ethique Hospitalo-Facultaire Erasme-ULB, 021/406, Brussels, Belgium; approval number: P2017/081). Since this project only will reuse the existing data from the public available dataset, no ethical approval by EC is required (confirmed by EC Leuven on 20/12/2023). Will you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven or UZ Will you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven or UZ Leuven privacy register number (G or S number). Leuven privacy register number (G or S number). No In this project no additional data are collected. However, we still filled in a PRET form: PRET G-number: G-2023-7308 Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so, Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so, please comment per dataset or data type where appropriate. please comment per dataset or data type where appropriate. No Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer agreements, Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer agreements, Research collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place. Research collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place. No Created using DMPonline.be. Last modiﬁed 16 January 2024 2 of 6 Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted. explain in the comment section to what data they relate and which restrictions will be asserted. No Documentation and Metadata Documentation and Metadata Clearly describe what approach will be followed to capture the accompanying information necessary to keep Clearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable and usable data understandable and usable , , for yourself and others, now and in the future (e.g. in terms of documentation levels and types required, procedures used, Electronic Lab for yourself and others, now and in the future (e.g. in terms of documentation levels and types required, procedures used, Electronic Lab Notebooks, README.txt files, codebook.tsv etc. where this information is recorded). Notebooks, README.txt files, codebook.tsv etc. where this information is recorded). Currently, the data is stored in a custom format. Before starting the first analysis, we will convert the dataset to BIDS structure (https://bids.neuroimaging.io/). The BIDS data structure is an internationally recognized dataset format to improve replicability. The generated script will be stored on GitLab. Will a metadata standard be used to make it easier to Will a metadata standard be used to make it easier to find and reuse the data find and reuse the data ? ? If so, please specify which metadata standard will be used. If so, please specify which metadata standard will be used. If not, please specify which metadata will be created to make the data easier to find and reuse. If not, please specify which metadata will be created to make the data easier to find and reuse. Yes The BIDS data structure requires some additional metadata files to increase readability and reproducabitiy of the dataset. As far as they are available, these metadata will be added. Data Storage & Back-up during the Research Project Data Storage & Back-up during the Research Project Where will the data be stored? Where will the data be stored? Other (specify below) The raw data is stored online (https://osf.io/9ce5t/). In order to analyze the data, some files will need to be stored on the (encrypted) hard drive (since calculations from a non-local source are too slow and lead to computational failures). A copy of the data will be stored on KU Leuven managed drives. The generated script will be stored on Gitlab. Important intermediate results will be saved on OneDrive. How will the data be backed up? How will the data be backed up? Personal back-ups I make (specify below) A backup on the encrypted local hard drive is taken automatically twice a week. GitLab manages the code and its versions, and therefore, also functions as a back up of all code to generate intermediate results. Is there currently sufficient storage & backup capacity during the project? Is there currently sufficient storage & backup capacity during the project? Created using DMPonline.be. Last modiﬁed 16 January 2024 3 of 6 If no or insufficient storage or backup capacities are available, explain how this will be taken care of. If no or insufficient storage or backup capacities are available, explain how this will be taken care of. Yes How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? During analysis, the data is stored on the researcher’s hard drive, which is encrypted. At the beginning of the project, the dataset will be copied onto the local hard drive and the KU Leuven managed drive to prevent changes in the online dataset from affecting the planned project. The scripts are backed up through GitLab, which is accessible to all team members and PI, but, not for unauthorized persons. However, since the raw data are publicly available, no additional measures are necessary. What are the expected costs for data storage and backup during the research project? How will these costs be covered? What are the expected costs for data storage and backup during the research project? How will these costs be covered? No additional costs are expected. OneDrive is maintained centrally by KU Leuven. The personal hard drive has already been purchased. KU Leuven researchers can make use of the Gitlab services free of charge. Data Preservation after the end of the Research Project Data Preservation after the end of the Research Project Which data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of the project? Which data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of the project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, institutional In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, institutional policies...). policies...). All data will be preserved for 10 years according to KU Leuven RDM policy Where will these data be archived (stored and curated for the long-term)? Where will these data be archived (stored and curated for the long-term)? Other (specify below) The data is stored online (https://osf.io/9ce5t/). A copy of the data will be stored on KU Leuven maintained drives. After finalizing the study, the caches and results will be stored on KU Leuven-managed drives (for min. 10 years). The processing code will be stored in Gitlab (and a Gitlab tag will be generated). What are the expected costs for data preservation during the expected retention period? How will these costs be covered? What are the expected costs for data preservation during the expected retention period? How will these costs be covered? Expected costs are: €11,384/year/100GB * 3 * 10years = €341.52. These costs will be covered by a reserve credit (as the annual costs are rather low). Data Sharing and Reuse Data Sharing and Reuse Will the data (or part of the data) be made available for reuse after/during the project? Will the data (or part of the data) be made available for reuse after/during the project? Please explain per dataset or data type which data will be made available. Please explain per dataset or data type which data will be made available. Created using DMPonline.be. Last modiﬁed 16 January 2024 4 of 6 Other (specify below) This dataset is already open-accessible data. This dataset can be found here: https://osf.io/9ce5t/ Regarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the results will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. If access is restricted, please specify who will be able to access the data and under what conditions. If access is restricted, please specify who will be able to access the data and under what conditions. NA Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions)? restrictions)? Please explain per dataset or data type where appropriate. Please explain per dataset or data type where appropriate. No Where will the data be made available? Where will the data be made available? If already known, please provide a repository per dataset or data type. If already known, please provide a repository per dataset or data type. Other (specify below) The data is readily available on: https://osf.io/9ce5t/ Regarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the results will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. When will the data be made available? When will the data be made available? Other (specify below) The data is readily available on: https://osf.io/9ce5t/ Regarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the results will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. Which data usage licenses are you going to provide? Which data usage licenses are you going to provide? If none, please explain why. If none, please explain why. Other (specify below) Regarding the raw data, available in the public database, the license is not specified on https://osf.io/9ce5t/ Regarding the scripts and results generated during the current project, it is not clear whether these will be shared. This depends on whether the results will be published. It is unclear whether a publication of the current project will be realized in the timeframe of the PDM. Do you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please provide it Do you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please provide it here. here. No Created using DMPonline.be. Last modiﬁed 16 January 2024 5 of 6 What are the expected costs for data sharing? How will these costs be covered? What are the expected costs for data sharing? How will these costs be covered? NA. The data is readily available on: https://osf.io/9ce5t/ Responsibilities Responsibilities Who will manage data documentation and metadata during the research project? Who will manage data documentation and metadata during the research project? I (Marlies Gillis) will convert the data set into BIDS structure and create the metadata to increase the readability of the dataset. The end- responsibility lies with professor Francart (PI). Who will manage data storage and backup during the research project? Who will manage data storage and backup during the research project? I (Marlies Gillis) perform an automatic backup at least twice a week of the encrypted hard drive and on OneDrive. Similarly, I will store the code on Gitlab. The data is also stored online at https://osf.io/9ce5t/ Who will manage data preservation and sharing? Who will manage data preservation and sharing? Regarding the raw data available in the public database, ULB professor Mathieu Bourguignon is responsible for data preservation and sharing. If the data of the current project is shared, I (Marlies Gillis) will manage the data sharing. The end-responsibility lies with professor Francart (PI). Who will update and implement this DMP? Who will update and implement this DMP? I (Marlies Gillis) will update and implement this DMP. Created using DMPonline.be. Last modiﬁed 16 January 2024 6 of 6"
}