{
    "document_id": "D-2024-3404",
    "LinkTitle": "D-2024-3404",
    "file_name": "D-2024-3404.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2024-3404.pdf",
    "metadata": {
        "title": "AI-Driven Analysis and Design of Protein-Ligand Interactions for Advancing De Novo Drug Discovery",
        "author": "N/A",
        "num_pages": 6
    },
    "content": {
        "full_text": "Plan Overview\nPlan Overview\nA Data Management Plan created using DMPonline.be\nTitle: \nTitle: \nAI-Driven Analysis and Design of Protein-Ligand Interactions for Advancing De Novo Drug Discovery\nCreator:\nCreator:\nRobin Poelmans\nAffiliation: \nAffiliation: \nKU Leuven (KUL)\nFunder: \nFunder: \nFonds voor Wetenschappelijk Onderzoek - Research Foundation Flanders (FWO)\nTemplate: \nTemplate: \nFWO DMP (Flemish Standard DMP)\nProject abstract:\nProject abstract:\nOver the past years, deep learning methods have claimed an increasingly important place in the field of computer-aided drug design.\nHowever, since these models are usually exclusively trained on common drug targets such as kinases and GCPRs, they often have\ndifficulties in generalizing to unexplored target proteins. Therefore I want to create an unbiased dataset for the binding of small ligands\nto underexplored protein pocket clusters in the human pocketome. To achieve this, I will chart the human pocketome using a novel\nhypervoxel descriptor method developed by the LBMD lab, and attempt to link this with the ligand chemical space by creating a wormhole\nalgorithm. Subsequently, by using computationally designed protein scaffolds, I will design a set of protein pockets representative for the\nunderexplored clusters in the human pocketome. Using the wormhole algorithm, I will match compounds from the chemical library at the\nLBMD lab to these pockets, and further optimize these pockets to create specific small molecule binders. I will then experimentally\nevaluate the binding of these chosen ligands and their derivatives to all the designed pockets using biolayer interferometry, in this way\ncreating a low-sparsity and high-diversity dataset ideal for the training of deep learning methods. This dataset will then finally be released\nas a blind predictive community challenge within the SAMPL framework.\nID: \nID: \n212134\nStart date: \nStart date: \n01-11-2024\nEnd date: \nEnd date: \n31-10-2028\nLast modified: \nLast modified: \n11-03-2025\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n1 of 6\nAI-Driven Analysis and Design of Protein-Ligand Interactions for Advancing De Novo Drug Discovery\nAI-Driven Analysis and Design of Protein-Ligand Interactions for Advancing De Novo Drug Discovery\nFWO DMP (Flemish Standard DMP)\nFWO DMP (Flemish Standard DMP)\n1. Research Data Summary\n1. Research Data Summary\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For\neach dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know\neach dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know\nwhat data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type\nwhat data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type\nof the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data.\nof the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data.\n \n \n \n \nOnly for digital data\nOnly for digital data\nOnly\nOnly\nfor\nfor\ndigital\ndigital\ndata \ndata \nOnly for\nOnly for\ndigital data \ndigital data \nOnly for\nOnly for\nphysical\nphysical\ndata\ndata\nDataset\nDataset\nName\nName\nDescription\nDescription\nNew or\nNew or\nreused\nreused\nDigital\nDigital\nor\nor\nPhysical\nPhysical\nDigital Data Type\nDigital Data Type\nDigital\nDigital\nData\nData\nformat\nformat\nDigital data\nDigital data\nvolume\nvolume\n(MB/GB/TB)\n(MB/GB/TB)\nPhysical\nPhysical\nvolume\nvolume\nPLINDER\ndataset\nRaw data of protein-ligand interaction\nsystems\nReuse\nexisting\ndata\nDigital\nCompiled/aggregated\ndata\n.cif,\n.mol2\n<1TB\n/\nPYkPocket\ntraining set\nPre-processed training data for joint\nmanifold learning algorithm:\ne.g. cleaned structure files, voxel grids,...\nGenerate\nnew\ndata\nDigital\nExperimental\n.cif,\n.csv,\n.pkl\n<5TB\n/\nPYkPocket\nsoftware\npackage\nRepository with scripts for knowledge-\nbased potentials, grid scoring and joint\nmanifold learning algorithms\nGenerate\nnew\ndata\nDigital\nSoftware\n.py\n<1GB\n/\nDesigned\nprotein\nsequences\nDNA sequences for the modified SAKe\nconstructs. Plasmids stored at -20°C,\nglycerol stocks stored at -80°C\nGenerate\nnew\ndata\nPhysical\n \n \n \nBetween\n50 and\n100 DNA\nconstructs\nDesigned\nprotein\nstructures\nData from X-ray crystallography\nexperiments\nGenerate\nnew\ndata\nDigital\nExperimental\n.raw,\n.mtz,\n.cif\n<10TB\n/\nSPR data\nData from surface plasmon resonance\nexperiments, measuring protein-ligand\ninteractions\nGenerate\nnew\ndata\nDigital\nExperimental\n.csv\n<1GB\n/\nSAMPL\nanalysis\nscripts\nSoftware to analyse predictions from\nSAMPL challenges\nReuse\nexisting\ndata\nDigital\nSoftware\n.py\n<1GB\n/\nSAMPL raw\nprediction\ndata\nCompound rankings and binding poses\nsent in by competitors\nReuse\nexisting\ndata\nDigital\nCompiled/aggregated\ndata\n.mol2,\n.csv\n<1TB\n/\nSAMPL\nanalysed\nresults\nAnalysis of received prediction results\nGenerate\nnew\ndata\nDigital\nExperimental\n.csv,\n.png\n<10GB\n/\nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per\nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per\ndataset or data type:\ndataset or data type:\nPLINDER: \nhttps://console.cloud.google.com/storage/browser/plinder\n                \nhttps://github.com/plinder-org/plinder\nWe make use of (a subset of) PLINDER to obtain the raw training data for the PYkPocket models\nSAMPL: \nhttps://github.com/samplchallenges\nThe SAMPL challenges have a well-established workflow for data analysis, so scripts from previous challenges can be re-\nused for our new challenge\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n2 of 6\nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)?\nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)?\nDescribe these issues in the comment section. Please refer to specific datasets or data types when appropriate.\nDescribe these issues in the comment section. Please refer to specific datasets or data types when appropriate.\nNo\nWill you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer\nWill you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer\nto specific datasets or data types when appropriate.\nto specific datasets or data types when appropriate.\nNo\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)?\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)?\nIf so, please comment per dataset or data type where appropriate.\nIf so, please comment per dataset or data type where appropriate.\nYes\nThe designed protein-ligand complexes could potentially be valorised as biosensors or as inducible switches in regulatory gene\nnetworks for synthetic biology. However, these applications do not lie within the scope of this PhD project.\nIf the software developed in this project is found to perform very well, we can opt for paid licenses for commercial use.\nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer\nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer\nagreements/ research collaboration agreements)? If so, please explain in the comment section to what data they relate and what\nagreements/ research collaboration agreements)? If so, please explain in the comment section to what data they relate and what\nrestrictions are in place.\nrestrictions are in place.\nNo\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you\n(re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted.\n(re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted.\nNo\n2. Documentation and Metadata\n2. Documentation and Metadata\nClearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable\nClearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable\nand usable, for yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures\nand usable, for yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures\nused, Electronic Lab Notebooks, README.txt files, Codebook.tsv etc. where this information is recorded).\nused, Electronic Lab Notebooks, README.txt files, Codebook.tsv etc. where this information is recorded).\nGitHub repositories will be created for both the PYkPocket and the SAMPL projects. These repositories will contain the raw data,\nprocessed data and all software created for data analysis. Version control of the Python scripts will be maintained through these\nGit repositories. Python scripts within these repositories will be documented and commented to facilitate reuse of the code.\nRaw data and processed data for the crystallography and SPR experiments will be stored locally. We will keep track of the\ngenerated files using a well-documented file tree, with each folder containing a README.txt file, specifying the data formats\nstored within a folder and how they should be processed.\nLocation and contents of glycerol stocks and plasmids are documented on a shared Benchling database in the LBMD lab.\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n3 of 6\nWill a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per\nWill a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per\ndataset or data type) which metadata standard will be used. If not, please specify (where appropriate per dataset or data type)\ndataset or data type) which metadata standard will be used. If not, please specify (where appropriate per dataset or data type)\nwhich metadata will be created to make the data easier to find and reuse.\nwhich metadata will be created to make the data easier to find and reuse.\nYes\nThe RCSB PDB and ChEMBL databases both make use of specific metadata requirements for contributions. The PDB database\nfor example makes use of the Crystallographic Information Framework standards, which will be followed in our research.\n3. Data storage & back-up during the research project\n3. Data storage & back-up during the research project\nWhere will the data be stored?\nWhere will the data be stored?\nSoftware, training data and analysis results for the PYkPocket and SAMPL projects will be stored in their respective GitHub\nrepositories.\nPYkPocket: \nhttps://github.com/robin-poelmans/PYkPocket/tree/main\nSAMPL: \nhttps://github.com/samplchallenges\nThese GitHub repositories will be kept private until the date of publication.\nCrystallography and SPR data will be stored locally on the systems of the LBMD lab. Back-ups of these systems to a Network-\nAttached Storage (NAS) will be performed at regular time intervals and after important / intensive calculations. This centralized\nstorage can only be accessed by other desktops within the LBMD local network.\nPlasmids for the designer proteins are stored at -20°C in the LBMD lab, while glycerol stocks are stored within the -80°C freezer of\nLBMD. Exact locations for the plasmids and glycerol stocks can be found through the lab's Benchling database.\nHow will the data be backed up?\nHow will the data be backed up?\nBack-ups of these systems to a Network-Attached Storage (NAS) will be performed at regular time intervals (by means of a cron\njob) and after important / intensive calculations.\nIs there currently sufficient storage & backup capacity during the project? If yes, specify concisely.\nIs there currently sufficient storage & backup capacity during the project? If yes, specify concisely.\nIf no or insufficient storage or backup capacities are available, then explain how this will be taken care of.\nIf no or insufficient storage or backup capacities are available, then explain how this will be taken care of.\nYes\n/\nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons?\nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons?\nSince we work in Linux environments on the local LBMD systems, writing rights can easily be limited for other users within the\nLBMD system. Access to my own user is password-protected.\nDuring the research, writing rights to the data will be limited to myself and my supervisor. \nWriting rights for the GitHub repositories are limited to my own account, unless other collaborators are explicitly invited by me.\nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nSince the regular back-ups to the NAS are already in place, there are no additional costs for back-ups. All storage costs are\ncovered by the LBMD.\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n4 of 6\n4. Data preservation after the end of the research project\n4. Data preservation after the end of the research project\nWhich data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after\nWhich data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after\nthe end of the project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual\nthe end of the project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual\nrestrictions, storage/budget issues, institutional policies...).\nrestrictions, storage/budget issues, institutional policies...).\nAll data specified above can and will be maintained for at least five years. Digital data will be maintained in GitHub repositories\nand/or local NAS storage, as specified above.\nPhysical data (in the form of plasmids and glycerol stocks) will be stored within the LBMD lab, with their location specified in the\nLBMD Benchling database.\nWhere will these data be archived (stored and curated for the long-term)?\nWhere will these data be archived (stored and curated for the long-term)?\nData will be archived in dedicated GitHub repositories for the PYkPocket and SAMPL projects. Solved crystal structures will be\nuploaded to the PDB database.\nPYkPocket: \nhttps://github.com/robin-poelmans/PYkPocket/tree/main\nSAMPL: \nhttps://github.com/samplchallenges\nRaw data from X-ray diffraction experiments will be stored on the local NAS for at least five years, but this will not be archived\nelsewhere due to the large size of these datasets.\nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\nNo additional costs are expected, since storage in the GitHub repositories is free of charge and the local NAS system is already\noperational.\n5. Data sharing and reuse\n5. Data sharing and reuse\nWill the data (or part of the data) be made available for reuse after/during the project?  In the comment section please explain per\nWill the data (or part of the data) be made available for reuse after/during the project?  In the comment section please explain per\ndataset or data type which data will be made available.\ndataset or data type which data will be made available.\nYes, in an Open Access repository\nBoth raw and processed data for the PYkPocket and SAMPL projects will be made openly available through their respective\nGitHub repositories, while solved crystal structures will be available through the PDB database. Protein-ligand interaction\nmeasurements from the SPR experiments will also be archived on ChEMBL.\nIf access is restricted, please specify who will be able to access the data and under what conditions.\nIf access is restricted, please specify who will be able to access the data and under what conditions.\nNot applicable.\nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party,\nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party,\nlegal restrictions)? Please explain in the comment section per dataset or data type where appropriate.\nlegal restrictions)? Please explain in the comment section per dataset or data type where appropriate.\nNo\nWhere will the data be made available? If already known, please provide a repository per dataset or data type.\nWhere will the data be made available? If already known, please provide a repository per dataset or data type.\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n5 of 6\nGitHub repositories:\nPYkPocket: \nhttps://github.com/robin-poelmans/PYkPocket/tree/main\nSAMPL: \nhttps://github.com/samplchallenges\nWhen will the data be made available?\nWhen will the data be made available?\nData will be made available upon publication of research results.\nWhich data usage licenses are you going to provide? If none, please explain why.\nWhich data usage licenses are you going to provide? If none, please explain why.\nIn principle, all software produced during this PhD will fall under the MIT license. This license gives express permission for users\nto reuse code for any purpose.\nIf the software is found to outperform other drug design and/or protein design tools, we can opt for dual licensing, where\nacademic use falls under the MIT license and business use falls under a commercial license.\nThe data from the crystallography and SPR experiments will fall under the CC0 license, as requested by their respective\nrepositories.\nDo you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the\nDo you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the\ncomment section.\ncomment section.\nYes\nGitHub repositories have a numeric ID which, unlike the repository URL, is a unique and persistent identifier. The repositories for\nPYkPocket and SAMPL will also be linked to their respective publications.\nWhat are the expected costs for data sharing? How will these costs be covered?\nWhat are the expected costs for data sharing? How will these costs be covered?\nThe archived data should be sufficiently small to archive free of cost on GitHub repositories.\n6. Responsibilities\n6. Responsibilities\nWho will manage data documentation and metadata during the research project?\nWho will manage data documentation and metadata during the research project?\nData documentation will be managed by myself. \nWho will manage data storage and backup during the research project?\nWho will manage data storage and backup during the research project?\nData storage will be managed by myself. Backups of locally stored data are performed on a regular basis through cron jobs \nWho will manage data preservation and sharing?\nWho will manage data preservation and sharing?\nArchiving data on the Git repositories will be managed by myself. Preservation of locally stored data on the LBMD systems will be\nmanaged by the supervisor, Prof. Arnout Voet. \nWho will update and implement this DMP?\nWho will update and implement this DMP?\nThis will be managed by myself, Robin Poelmans \nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n6 of 6"
    },
    "clean_full_text": "Plan Overview Plan Overview A Data Management Plan created using DMPonline.be Title: Title: AI-Driven Analysis and Design of Protein-Ligand Interactions for Advancing De Novo Drug Discovery Creator: Creator: Robin Poelmans Affiliation: Affiliation: KU Leuven (KUL) Funder: Funder: Fonds voor Wetenschappelijk Onderzoek - Research Foundation Flanders (FWO) Template: Template: FWO DMP (Flemish Standard DMP) Project abstract: Project abstract: Over the past years, deep learning methods have claimed an increasingly important place in the field of computer-aided drug design. However, since these models are usually exclusively trained on common drug targets such as kinases and GCPRs, they often have difficulties in generalizing to unexplored target proteins. Therefore I want to create an unbiased dataset for the binding of small ligands to underexplored protein pocket clusters in the human pocketome. To achieve this, I will chart the human pocketome using a novel hypervoxel descriptor method developed by the LBMD lab, and attempt to link this with the ligand chemical space by creating a wormhole algorithm. Subsequently, by using computationally designed protein scaffolds, I will design a set of protein pockets representative for the underexplored clusters in the human pocketome. Using the wormhole algorithm, I will match compounds from the chemical library at the LBMD lab to these pockets, and further optimize these pockets to create specific small molecule binders. I will then experimentally evaluate the binding of these chosen ligands and their derivatives to all the designed pockets using biolayer interferometry, in this way creating a low-sparsity and high-diversity dataset ideal for the training of deep learning methods. This dataset will then finally be released as a blind predictive community challenge within the SAMPL framework. ID: ID: 212134 Start date: Start date: 01-11-2024 End date: End date: 31-10-2028 Last modified: Last modified: 11-03-2025 Created using DMPonline.be. Last modiﬁed 11 March 2025 1 of 6 AI-Driven Analysis and Design of Protein-Ligand Interactions for Advancing De Novo Drug Discovery AI-Driven Analysis and Design of Protein-Ligand Interactions for Advancing De Novo Drug Discovery FWO DMP (Flemish Standard DMP) FWO DMP (Flemish Standard DMP) 1. Research Data Summary 1. Research Data Summary List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know each dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type what data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data. of the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data. Only for digital data Only for digital data Only Only for for digital digital data data Only for Only for digital data digital data Only for Only for physical physical data data Dataset Dataset Name Name Description Description New or New or reused reused Digital Digital or or Physical Physical Digital Data Type Digital Data Type Digital Digital Data Data format format Digital data Digital data volume volume (MB/GB/TB) (MB/GB/TB) Physical Physical volume volume PLINDER dataset Raw data of protein-ligand interaction systems Reuse existing data Digital Compiled/aggregated data .cif, .mol2 <1TB / PYkPocket training set Pre-processed training data for joint manifold learning algorithm: e.g. cleaned structure files, voxel grids,... Generate new data Digital Experimental .cif, .csv, .pkl <5TB / PYkPocket software package Repository with scripts for knowledge- based potentials, grid scoring and joint manifold learning algorithms Generate new data Digital Software .py <1GB / Designed protein sequences DNA sequences for the modified SAKe constructs. Plasmids stored at -20°C, glycerol stocks stored at -80°C Generate new data Physical Between 50 and 100 DNA constructs Designed protein structures Data from X-ray crystallography experiments Generate new data Digital Experimental .raw, .mtz, .cif <10TB / SPR data Data from surface plasmon resonance experiments, measuring protein-ligand interactions Generate new data Digital Experimental .csv <1GB / SAMPL analysis scripts Software to analyse predictions from SAMPL challenges Reuse existing data Digital Software .py <1GB / SAMPL raw prediction data Compound rankings and binding poses sent in by competitors Reuse existing data Digital Compiled/aggregated data .mol2, .csv <1TB / SAMPL analysed results Analysis of received prediction results Generate new data Digital Experimental .csv, .png <10GB / If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data type: dataset or data type: PLINDER: https://console.cloud.google.com/storage/browser/plinder https://github.com/plinder-org/plinder We make use of (a subset of) PLINDER to obtain the raw training data for the PYkPocket models SAMPL: https://github.com/samplchallenges The SAMPL challenges have a well-established workflow for data analysis, so scripts from previous challenges can be re- used for our new challenge Created using DMPonline.be. Last modiﬁed 11 March 2025 2 of 6 Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? Describe these issues in the comment section. Please refer to specific datasets or data types when appropriate. Describe these issues in the comment section. Please refer to specific datasets or data types when appropriate. No Will you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer Will you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer to specific datasets or data types when appropriate. to specific datasets or data types when appropriate. No Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so, please comment per dataset or data type where appropriate. If so, please comment per dataset or data type where appropriate. Yes The designed protein-ligand complexes could potentially be valorised as biosensors or as inducible switches in regulatory gene networks for synthetic biology. However, these applications do not lie within the scope of this PhD project. If the software developed in this project is found to perform very well, we can opt for paid licenses for commercial use. Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer agreements/ research collaboration agreements)? If so, please explain in the comment section to what data they relate and what agreements/ research collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place. restrictions are in place. No Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted. (re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted. No 2. Documentation and Metadata 2. Documentation and Metadata Clearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable Clearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable and usable, for yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures and usable, for yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures used, Electronic Lab Notebooks, README.txt files, Codebook.tsv etc. where this information is recorded). used, Electronic Lab Notebooks, README.txt files, Codebook.tsv etc. where this information is recorded). GitHub repositories will be created for both the PYkPocket and the SAMPL projects. These repositories will contain the raw data, processed data and all software created for data analysis. Version control of the Python scripts will be maintained through these Git repositories. Python scripts within these repositories will be documented and commented to facilitate reuse of the code. Raw data and processed data for the crystallography and SPR experiments will be stored locally. We will keep track of the generated files using a well-documented file tree, with each folder containing a README.txt file, specifying the data formats stored within a folder and how they should be processed. Location and contents of glycerol stocks and plasmids are documented on a shared Benchling database in the LBMD lab. Created using DMPonline.be. Last modiﬁed 11 March 2025 3 of 6 Will a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per Will a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per dataset or data type) which metadata standard will be used. If not, please specify (where appropriate per dataset or data type) dataset or data type) which metadata standard will be used. If not, please specify (where appropriate per dataset or data type) which metadata will be created to make the data easier to find and reuse. which metadata will be created to make the data easier to find and reuse. Yes The RCSB PDB and ChEMBL databases both make use of specific metadata requirements for contributions. The PDB database for example makes use of the Crystallographic Information Framework standards, which will be followed in our research. 3. Data storage & back-up during the research project 3. Data storage & back-up during the research project Where will the data be stored? Where will the data be stored? Software, training data and analysis results for the PYkPocket and SAMPL projects will be stored in their respective GitHub repositories. PYkPocket: https://github.com/robin-poelmans/PYkPocket/tree/main SAMPL: https://github.com/samplchallenges These GitHub repositories will be kept private until the date of publication. Crystallography and SPR data will be stored locally on the systems of the LBMD lab. Back-ups of these systems to a Network- Attached Storage (NAS) will be performed at regular time intervals and after important / intensive calculations. This centralized storage can only be accessed by other desktops within the LBMD local network. Plasmids for the designer proteins are stored at -20°C in the LBMD lab, while glycerol stocks are stored within the -80°C freezer of LBMD. Exact locations for the plasmids and glycerol stocks can be found through the lab's Benchling database. How will the data be backed up? How will the data be backed up? Back-ups of these systems to a Network-Attached Storage (NAS) will be performed at regular time intervals (by means of a cron job) and after important / intensive calculations. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. If no or insufficient storage or backup capacities are available, then explain how this will be taken care of. If no or insufficient storage or backup capacities are available, then explain how this will be taken care of. Yes / How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? Since we work in Linux environments on the local LBMD systems, writing rights can easily be limited for other users within the LBMD system. Access to my own user is password-protected. During the research, writing rights to the data will be limited to myself and my supervisor. Writing rights for the GitHub repositories are limited to my own account, unless other collaborators are explicitly invited by me. What are the expected costs for data storage and backup during the research project? How will these costs be covered? What are the expected costs for data storage and backup during the research project? How will these costs be covered? Since the regular back-ups to the NAS are already in place, there are no additional costs for back-ups. All storage costs are covered by the LBMD. Created using DMPonline.be. Last modiﬁed 11 March 2025 4 of 6 4. Data preservation after the end of the research project 4. Data preservation after the end of the research project Which data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after Which data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after the end of the project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual the end of the project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, institutional policies...). restrictions, storage/budget issues, institutional policies...). All data specified above can and will be maintained for at least five years. Digital data will be maintained in GitHub repositories and/or local NAS storage, as specified above. Physical data (in the form of plasmids and glycerol stocks) will be stored within the LBMD lab, with their location specified in the LBMD Benchling database. Where will these data be archived (stored and curated for the long-term)? Where will these data be archived (stored and curated for the long-term)? Data will be archived in dedicated GitHub repositories for the PYkPocket and SAMPL projects. Solved crystal structures will be uploaded to the PDB database. PYkPocket: https://github.com/robin-poelmans/PYkPocket/tree/main SAMPL: https://github.com/samplchallenges Raw data from X-ray diffraction experiments will be stored on the local NAS for at least five years, but this will not be archived elsewhere due to the large size of these datasets. What are the expected costs for data preservation during the expected retention period? How will these costs be covered? What are the expected costs for data preservation during the expected retention period? How will these costs be covered? No additional costs are expected, since storage in the GitHub repositories is free of charge and the local NAS system is already operational. 5. Data sharing and reuse 5. Data sharing and reuse Will the data (or part of the data) be made available for reuse after/during the project? In the comment section please explain per Will the data (or part of the data) be made available for reuse after/during the project? In the comment section please explain per dataset or data type which data will be made available. dataset or data type which data will be made available. Yes, in an Open Access repository Both raw and processed data for the PYkPocket and SAMPL projects will be made openly available through their respective GitHub repositories, while solved crystal structures will be available through the PDB database. Protein-ligand interaction measurements from the SPR experiments will also be archived on ChEMBL. If access is restricted, please specify who will be able to access the data and under what conditions. If access is restricted, please specify who will be able to access the data and under what conditions. Not applicable. Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions)? Please explain in the comment section per dataset or data type where appropriate. legal restrictions)? Please explain in the comment section per dataset or data type where appropriate. No Where will the data be made available? If already known, please provide a repository per dataset or data type. Where will the data be made available? If already known, please provide a repository per dataset or data type. Created using DMPonline.be. Last modiﬁed 11 March 2025 5 of 6 GitHub repositories: PYkPocket: https://github.com/robin-poelmans/PYkPocket/tree/main SAMPL: https://github.com/samplchallenges When will the data be made available? When will the data be made available? Data will be made available upon publication of research results. Which data usage licenses are you going to provide? If none, please explain why. Which data usage licenses are you going to provide? If none, please explain why. In principle, all software produced during this PhD will fall under the MIT license. This license gives express permission for users to reuse code for any purpose. If the software is found to outperform other drug design and/or protein design tools, we can opt for dual licensing, where academic use falls under the MIT license and business use falls under a commercial license. The data from the crystallography and SPR experiments will fall under the CC0 license, as requested by their respective repositories. Do you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the Do you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the comment section. comment section. Yes GitHub repositories have a numeric ID which, unlike the repository URL, is a unique and persistent identifier. The repositories for PYkPocket and SAMPL will also be linked to their respective publications. What are the expected costs for data sharing? How will these costs be covered? What are the expected costs for data sharing? How will these costs be covered? The archived data should be sufficiently small to archive free of cost on GitHub repositories. 6. Responsibilities 6. Responsibilities Who will manage data documentation and metadata during the research project? Who will manage data documentation and metadata during the research project? Data documentation will be managed by myself. Who will manage data storage and backup during the research project? Who will manage data storage and backup during the research project? Data storage will be managed by myself. Backups of locally stored data are performed on a regular basis through cron jobs Who will manage data preservation and sharing? Who will manage data preservation and sharing? Archiving data on the Git repositories will be managed by myself. Preservation of locally stored data on the LBMD systems will be managed by the supervisor, Prof. Arnout Voet. Who will update and implement this DMP? Who will update and implement this DMP? This will be managed by myself, Robin Poelmans Created using DMPonline.be. Last modiﬁed 11 March 2025 6 of 6"
}