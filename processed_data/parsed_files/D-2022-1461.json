{
    "document_id": "D-2022-1461",
    "LinkTitle": "D-2022-1461",
    "file_name": "D-2022-1461.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2022-1461.pdf",
    "metadata": {
        "title": "DMP FWO G080822N - DMP title",
        "author": "N/A",
        "num_pages": 7
    },
    "content": {
        "full_text": "DMP title\nProject Name\n DMP FWO G080822N - DMP title\nProject Identifier\n G080822N\nGrant Title\n G080822N\nPrincipal Investigator / Researcher\n Nick Vannieuwenhoven\nDescription\n Our objective is to develop the ManiFactor framework for surrogate models of maps\ninto manifolds based on a generalization of the factor analysis model that includes generic\nmathematical techniques, practical learning algorithms, and research software. Numerical\nsimulation data will be generated to demonstrate the efficacy of the developed algorithms.\nInstitution\n KU Leuven\n1. General Information\nName applicant\nNick Vannieuwenhoven\nFWO Project Number & Title\nG080822N - ManiFactor: Factor analysis for maps into manifolds\nAffiliation\nKU Leuven\n2. Data description\nWill you generate/collect new data and/or make use of existing data?\nGenerate new data\nReuse existing data\nDescribe in detail the origin, type and format of the data (per dataset) and its\n(estimated) volume. This may be easiest in a table (see example) or as a data flow and\nper WP or objective of the project. If you reuse existing data, specify the source of these\ndata. \nDistinguish data types (the kind of content) from data formats (the technical\nformat).\nWork\npackage\nType of\ndata\nFormat\nVolume\nHow created\nWP1-4\nJulia\nprogram\ncode\n.jl\n< 10 MB\nImplementation into a computer programming\nlanguage of algorithms developed in WPs 1 through 4.\nWP1\nNumerical\nsimulation\ndata of\nperformance\n(error,\ntimings,\nmemory\nusage, etc)\nof the\ndeveloped\nalgorithm\nfor\ngenerating\nthe anchor\npoint\n.csv\n< 100\nMB\nResult of running Julia code.\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n1 of 7\nWP2\nNumerical\nsimulation\ndata of\nperformance\n(error,\ntimings,\nmemory\nusage, etc)\nof the\ndeveloped\nalgorithm\nfor delation-\nbased pre-\nlearning.\n.csv\n< 250\nMB\nResults of running Julia code.\nWP3\nNumerical\nsimulation\ndata of\nperformance\n(error,\ntimings,\nmemory\nusage, etc)\nof the\ndeveloped\nalgorithm\nfor\nalternating\nminimization\nlearning.\n.csv\n<\n250MB\nResults of running Julia code.\nWP4\nNumerical\nresults of\nmanifold-\nvalued\nimage\nprocessing\ntasks,\nincluding\nraw\npredicted\nimage\nvalues,\nerror,\ntimings,\nmemory\nusage\n.csv\n< 250\nMB\nResults of running Julia code.\nWP4\nMagnetic\nresonance\nimaging\ndata.\nprimarily\n.nii and\ncompressed\n.nii.gz\n< 5GB /\nsubject\nDownloaded\nfrom \nhttps://doi.org/10.6084/m9.figshare.c.5315474.v1\n3. Legal and ethical issues\nWill you use personal data? \nIf so, shortly describe the kind of personal data you will use.\nAdd the reference to your file in KU Leuven's Register of Data Processing for Research\nand Public Service Purposes (PRET application). \nBe aware that registering the fact that\nyou process personal data is a legal obligation.\nNo\nThe anonymized data set is described by Tian, Fan, Witzel, et al. (2022) in Scientific Data 9, no. 7\nand consists of diffusion MRI scans of human brains. Ethical approval and written consent of\ncognitively normal individuals was obtained by these authors to collect and distribute this data set.\nThis data set is distributed under CC0 - No Copyright.\nWhile the MRI scans reveal anatomic details of individual brains, no personally identifying\ninformation (names, social security numbers, address, etc) is included with the data set that would\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n2 of 7\nenable precise or even plausible identification of any individual. Since the anonymized data is freely\navailable on a public figshare repository and no distribution restrictions apply, with the subjects's\nconsent, none of the essential data management aspects (privacy, access control, secure storage,\nsharing and redistribution, retention period) apply.\nThe data set will be used exclusively to generate realistic diffusion tensor images, which consist of\na grid of small-scale positive semi-definite matrices. This grid of matrices will be approximated (for\nthe purpose of error correction, data compression, and missing data completion) using the\nManiFactor algorithms.\nThe other data we generate is not personal data.\nAre there any ethical issues concerning the creation and/or use of the data (e.g.\nexperiments on humans or animals, dual use)? If so, add the reference to the formal\napproval by the relevant ethical review committee(s)\nNo\nThe purpose of our analysis of the reused data set is to apply diffusion tensor imaging techniques\nto obtain small-scale positive semi-definite matrices arranged on a regular grid. These will then be\ninvestigated from a purely mathematical point of view as regards to the potential of the developed\nmethods to clean (noise reduction) such data sets and to evaluate insofar as such data could be\neffectively and accurately (but lossy) compressed using the developed mathematical methods. We\nwill not redistribute this data set or modifications thereof.\nThere are no ethical issues with the convergence and performance data we will generate ourselves.\nDoes your work possibly result in research data with potential for tech transfer and\nvalorisation? Will IP restrictions be claimed for the data you created? If so, for what data\nand which restrictions will be asserted?\nYes\nIf the scientific hypotheses are all largely correct, we may anticipate that ManiFactor algorithms\ncould be used to compress, among others, tensor diffusion imaging data. Such a technology could\nbe valorized and may even be commercially exploitable. We do not believe it plausible that IP\nrestrictions will be claimed for the derived numerical predictions we will construct from a subset of\nthe MRI data set.\nThe predictions made by ManiFactor algorithms and the compression results will not be distributed\nas a new data set. These comprise our raw data.\nThe employed data set (https://doi.org/10.6084/m9.figshare.c.5315474.v1) is licensed under CC0 -\nNo Copyright, so no IP restrictions apply.\nDo existing 3rd party agreements restrict dissemination or exploitation of the data you\n(re)use? If so, to what data do they relate and what restrictions are in place?\nNo\nThe reused data set (https://doi.org/10.6084/m9.figshare.c.5315474.v1) is licensed under CC0, so\nno copyright restrictions apply. We will not distribute any derived data sets.\nThe data we will generate ourselves is not subject to any restrictions.\n4. Documentation and metadata\nWhat documentation will be provided to enable reuse of the data collected/generated in\nthis project?\nAll of the numerical data generated in this project, both raw and processed, will be the result of\nrunning computer codes. These codes describe in a mathematically rigorous, completely precise\nand unambiguous way how the data is generated. The codes for generating and processing the\ndata will be documented in a human-readable format as well (as part of the Julia code files),\nexplaining what they intend to do.\nThe comma separated values-files from WP1-4 are intimately linked with the code that generated\nthem. This linking is described in a bash script file that calls the code and generates the output file.\nThe comments in these bash scripts will describe what numerical experiment the bash script will\nexecute. For each experiment, a ReadMe file documents the computer architecture on which the\nexperiments were carried out. \nThe foregoing means that for each experimental data file X.csv, there is a corresponding X.sh that\nwhen executed generates the X.csv data file, and finally an X.txt plain text file that describes the\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n3 of 7\nintention of the experiment, the computer architecture and computer parameters that were used,\nand if applicable, the precise table, figure, or section that the X.csv provides the data for in the\npreprint based on this data. The .csv-files will always start with a header that identifies the\ninformation contained in each column in a human-readable format. For example \"relative backward\nerror\", \"time (s)\", \"peak memory consumption (MB)\", etc. The mathematically precise definition of\nthe data items is rigorously encoded in the program code.\nThe default file structure, limited to the data aspects, we use is:\n>AuthorInitials\n-> code\n-> experiments\n--> date of experiment\n---> relevant code files\n---> X.csv\n---> X.sh\n---> X.txt\n-> literature\n-> paper\n-> plots\n--> date of processing\n---> relevant processing code files\n---> generated figure output files (.eps, .pdf)\n---> generated table output files (.txt, .tex)\nThe raw data in the .csv-files will be processed exclusively using additional computer codes in,\namong others, Julia (.jl), Python (.py), Perl (.pl), Matlab/Octave (.m), or Gnuplot (.plot). They will\ngenerate, as necessary, the relevant plots in vector graphic formats like .eps and .pdf, or the\nrelevant tables in LaTeX code, either as a standalone, importable LaTeX file (.tex) or simply as the\nrelevant table environment that can be directly copied into the paper (.txt). \nWill a metadata standard be used? If so, \ndescribe in detail which standard will be used.\nIf no, state in detail which metadata will be created to make the data easy/easier to find\nand reuse.\nNo\nNo standard metadata formats exist in our domain due to the highly variable types of data that is\ngenerated as a result of numerical simulations. In addition, as described above, the data-generating\nprocess is described in a fully formal way through the program code that generates the data. As\nsuch, most aspects that one would otherwise describe with metadata are formally encoded in the\n(human-readable and machine-executable) program code. In some sense, this code is the\nmetadata.\n5. Data storage and backup during the FWO project\nWhere will the data be stored?\nAll of the program codes, including the ones to generate and process the data, will be developed\nusing a version management system, in particular KU Leuven GitLab. One (private) GitLab\nrepository will be created wherein the codes will be developed by the authors. This private\nrepository is also used to host and develop the LaTeX files of the scientific article based on the\ndeveloped theory, algorithms, and data. This repository will be completely private with read and\nwrite access restricted to the authors involved in performing the research.\nWhen the final article is completed, a new fully public GitLab repository is created, hosting the final\nprogram codes and developed algorithms, including the codes for generating the data files and\nproducing the processed data (i.e. figures and tables). This repository will have public read rights,\nbut no write rights. Our articles will then reference this public repository. The articles themselves\nare posted as preprints to the arXiv.org preprint servers.\nUpon acceptance of the article, the final article's pdf-file, figures, code, and processed data is\narchived both to the PI's KU Leuven OneDrive (identified by the author's last names initials, then a\ndash, and then the arXiv identifier), as well as to the Department of Computer Science's NextCloud\nstorage, under the modalities of the NUMA division's data management plan.\nDuring theoretical and practical development, the article files and codes will also be present on the\nauthor's personal work computer. After completing small chunks of work (e.g., once per day), these\nfiles are to be synchronized with the version management system (i.e., KU Leuven GitLab). During\ndevelopment, generated raw data files will be stored exclusively on the author's personal work\ncomputer (or potentially on external compute servers such as the VSC's). These data files are not\ncrucial and can always be generated from the current version of the code in the private GitLab\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n4 of 7\nrepository.\nHow is backup of the data provided?\nThe program code will be stored in a KU Leuven GitLab repository, which provides both version\ncontrol (i.e. tracking what changes were made when and by who) and automatic backups. Note that\nresearchers developing the program code will keep their updates synchronized with the GitLab\nrepository by committing and pushing the changes at least on a daily basis.\nThe data generated and used by any of our articles will be stored in KU Leuven OneDrive, which\nprovides automatic backups to KU Leuven servers. In addition, the paper, codes, figures, and\nprocessed data will be archived on the Department of Computer Science's NextCloud service upon\ncompletion and final acceptance of each article. These servers are also automatically backed up (in\nthe Department of Computer Science).\nThe data that is stored only on the author's work computers is not critical and can be generated\nfrom the code files or downloaded from public repositories (in the case of the MRI data files).\nNevertheless, the Department of Computer Science automatically provides monthly backups of the\nhome directories of all work computers. No specific backup policy is enforced on these files due to\ntheir transient and noncritical status.\nIs there currently sufficient storage & backup capacity during the project? If yes, specify\nconcisely. If no or insufficient storage or backup capacities are available then explain\nhow this will be taken care of.\nYes\nThe storage offered within KU Leuven OneDrive will suffice for our long-term data storage needs,\nwhich are expected to be well below a hundred megabytes (in uncompressed format).\nWhat are the expected costs for data storage and back up during the project? How will\nthese costs be covered?\nWe will use free solutions offered by KU Leuven.\nData security: how will you ensure that the data are securely stored and not accessed or\nmodified by unauthorized persons?\nNo sensitive data will be processed. Recall that the MRI data is anonymous and contains no\npersonally identifying information. Since this data is available in a public persistent figshare\nrepository, we will not keep publically accessible copies of this data. The only copies will be local\nworking copies on the researcher's computer. \nAside from this MRI data from a public repository, our data mainly consists of numerical\nexperimental data that we will generate and which is absolutely not sensitive, as it consists of\nalgorithmic performance data. Consequently, no specific security measures will be taken, other\nthan password protection of the work computers and usage of a private GitLab repository during\nthe research phase of the project. This GitLab repository is secured with the KU Leuven\nAuthenticator (which uses two-factor authentication).\n6. Data preservation after the FWO project\nWhich data will be retained for the expected 5 year period after the end of the project?\nIn case only a selection of the data can/will be preserved, clearly state the reasons for\nthis (legal or contractual restrictions, physical preservation issues, ...).\nThe data that is reused will not be retained, as it is freely publically available in a persistent\nfigshare repository and fully documented in a scientific article published in Scientific Data 9, no. 7.\nAll generated convergence and performance data will be retained in the private GitLab repository\nfor this project.\nAll final data that constitutes the basis of our scientific articles will be replicated in the public GitLab\nrepository for that paper. In addition, a version will be archived on the Department of Computer\nScience's NextCloud solution (as per the data management plan of the NUMA division). Finally,\nanother copy will be archived in the PI's KU Leuven OneDrive repository, employing the naming\nconventions outlined above.\nNote that all of our data can be generated anew using our program codes. These codes are also\nstored in the private GitLab (for the working copies and research version), the public GitLab (for the\nfinal version), and private NextCloud and OneDrive (archived, final versions).\nWhere will the data be archived (= stored for the longer term)?\nThe final data, including the program codes that can generate these data anew, that are the basis\nof our scientific articles will be archived both in NextCloud (as per our division NUMA's data\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n5 of 7\nmanagement plan) and the PI's OneDrive. In addition, the fully public GitLab page corresponding to\nthe article, as explained above, will also host the final data and codes.\nIn the unlikely case that the volume of data is too large to store on GitLab, only the codes that can\ngenerate that data will be stored. Any researcher can then generate the data anew using these\ncodes.\nWhat are the expected costs for data preservation during the retention period of 5\nyears? How will the costs be covered?\nSince the data volumes are expected to be very small (well below a few hundred megabytes), the\nstorage limits of the Department of Computer Science's NextCloud, KU Leuven's OneDrive, and KU\nLeuven's GitLab will not be exceeded. Hence, the expected cost is zero.\n7. Data sharing and reuse\nAre there any factors restricting or preventing the sharing of (some of) the data (e.g. as\ndefined in an agreement with a 3rd party, legal restrictions)?\nNo\nAll final research data that support our scientific articles will be made publically available in the\naforementioned public GitLab repository. The reused data set will not be shared, since it is already\navailable in the public domain in a public figshare repository.\nWhich data will be made available after the end of the project?\nAll final research data that support our scientific articles will be made publically available in the\naforementioned public GitLab repository. The articles themselves will additionally be posted to the\narXiv.org preprint servers.\nWhere/how will the data be made available for reuse?\nIn an Open Access repository\nAll final research data, including our computer codes that can generate these data anew, that\nsupport our scientific articles will be made publically available in the aforementioned public GitLab\nrepository.\nWhen will the data be made available?\nImmediately after the end of the project\nAll final research data including our computer source code will be made publicly available in\naforementioned GitHub repository after completing the project and uploading the resulting\nscientific article to the preprint server arXiv.org.\nWho will be able to access the data and under what conditions?\nAll final data, excluding the computer source codes, will be released into the public domain through\nthe aforementioned public GitLab repository of the article. No access control is necessary for this.\nThe source codes will be released under a CC-BY-SA 4.0 licence, in the GitLab repository. This\nmeans that anyone can modify, update, and incorporate our code, as long as any redistribution of\nsaid codes documents these changes, attributes the original source, and imposes the same CC-BY-\nSA 4.0 license conditions.\nWhat are the expected costs for data sharing? How will the costs be covered?\nSince the data volumes are expected to be very small (well below a few hundred megabytes), the\nstorage limits of KU Leuven's GitLab will not be exceeded. Hence, the expected cost is zero.\n8. Responsibilities\nWho will be responsible for data documentation & metadata?\nPh.D. student Simon Jacobsson is responsible for documenting the data, following the data\nprotocols, and supplying the metadata (including computer codes).\nWho will be responsible for data storage & back up during the project?\nPh.D. student Simon Jacobsson will be responsible for uploading all relevant data to GitLab.\nThe PI Nick Vannieuwenhoven will be responsible for final archiving in the Department of Computer\nScience NextCloud storage system and in KU Leuven's OneDrive.\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n6 of 7\nWho will be responsible for ensuring data preservation and reuse ?\nThe PI bears the end responsibility of ensuring the data is preserved in NextCloud, OneDrive, and\nGitLab.\nWho bears the end responsibility for updating & implementing this DMP?\nThe PI bears the end responsibility of updating & implementing this DMP.\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n7 of 7"
    },
    "clean_full_text": "DMP title Project Name DMP FWO G080822N - DMP title Project Identifier G080822N Grant Title G080822N Principal Investigator / Researcher Nick Vannieuwenhoven Description Our objective is to develop the ManiFactor framework for surrogate models of maps into manifolds based on a generalization of the factor analysis model that includes generic mathematical techniques, practical learning algorithms, and research software. Numerical simulation data will be generated to demonstrate the efficacy of the developed algorithms. Institution KU Leuven 1. General Information Name applicant Nick Vannieuwenhoven FWO Project Number & Title G080822N - ManiFactor: Factor analysis for maps into manifolds Affiliation KU Leuven 2. Data description Will you generate/collect new data and/or make use of existing data? Generate new data Reuse existing data Describe in detail the origin, type and format of the data (per dataset) and its (estimated) volume. This may be easiest in a table (see example) or as a data flow and per WP or objective of the project. If you reuse existing data, specify the source of these data. Distinguish data types (the kind of content) from data formats (the technical format). Work package Type of data Format Volume How created WP1-4 Julia program code .jl < 10 MB Implementation into a computer programming language of algorithms developed in WPs 1 through 4. WP1 Numerical simulation data of performance (error, timings, memory usage, etc) of the developed algorithm for generating the anchor point .csv < 100 MB Result of running Julia code. This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 1 of 7 WP2 Numerical simulation data of performance (error, timings, memory usage, etc) of the developed algorithm for delation- based pre- learning. .csv < 250 MB Results of running Julia code. WP3 Numerical simulation data of performance (error, timings, memory usage, etc) of the developed algorithm for alternating minimization learning. .csv < 250MB Results of running Julia code. WP4 Numerical results of manifold- valued image processing tasks, including raw predicted image values, error, timings, memory usage .csv < 250 MB Results of running Julia code. WP4 Magnetic resonance imaging data. primarily .nii and compressed .nii.gz < 5GB / subject Downloaded from https://doi.org/10.6084/m9.figshare.c.5315474.v1 3. Legal and ethical issues Will you use personal data? If so, shortly describe the kind of personal data you will use. Add the reference to your file in KU Leuven's Register of Data Processing for Research and Public Service Purposes (PRET application). Be aware that registering the fact that you process personal data is a legal obligation. No The anonymized data set is described by Tian, Fan, Witzel, et al. (2022) in Scientific Data 9, no. 7 and consists of diffusion MRI scans of human brains. Ethical approval and written consent of cognitively normal individuals was obtained by these authors to collect and distribute this data set. This data set is distributed under CC0 - No Copyright. While the MRI scans reveal anatomic details of individual brains, no personally identifying information (names, social security numbers, address, etc) is included with the data set that would This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 2 of 7 enable precise or even plausible identification of any individual. Since the anonymized data is freely available on a public figshare repository and no distribution restrictions apply, with the subjects's consent, none of the essential data management aspects (privacy, access control, secure storage, sharing and redistribution, retention period) apply. The data set will be used exclusively to generate realistic diffusion tensor images, which consist of a grid of small-scale positive semi-definite matrices. This grid of matrices will be approximated (for the purpose of error correction, data compression, and missing data completion) using the ManiFactor algorithms. The other data we generate is not personal data. Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, add the reference to the formal approval by the relevant ethical review committee(s) No The purpose of our analysis of the reused data set is to apply diffusion tensor imaging techniques to obtain small-scale positive semi-definite matrices arranged on a regular grid. These will then be investigated from a purely mathematical point of view as regards to the potential of the developed methods to clean (noise reduction) such data sets and to evaluate insofar as such data could be effectively and accurately (but lossy) compressed using the developed mathematical methods. We will not redistribute this data set or modifications thereof. There are no ethical issues with the convergence and performance data we will generate ourselves. Does your work possibly result in research data with potential for tech transfer and valorisation? Will IP restrictions be claimed for the data you created? If so, for what data and which restrictions will be asserted? Yes If the scientific hypotheses are all largely correct, we may anticipate that ManiFactor algorithms could be used to compress, among others, tensor diffusion imaging data. Such a technology could be valorized and may even be commercially exploitable. We do not believe it plausible that IP restrictions will be claimed for the derived numerical predictions we will construct from a subset of the MRI data set. The predictions made by ManiFactor algorithms and the compression results will not be distributed as a new data set. These comprise our raw data. The employed data set (https://doi.org/10.6084/m9.figshare.c.5315474.v1) is licensed under CC0 - No Copyright, so no IP restrictions apply. Do existing 3rd party agreements restrict dissemination or exploitation of the data you (re)use? If so, to what data do they relate and what restrictions are in place? No The reused data set (https://doi.org/10.6084/m9.figshare.c.5315474.v1) is licensed under CC0, so no copyright restrictions apply. We will not distribute any derived data sets. The data we will generate ourselves is not subject to any restrictions. 4. Documentation and metadata What documentation will be provided to enable reuse of the data collected/generated in this project? All of the numerical data generated in this project, both raw and processed, will be the result of running computer codes. These codes describe in a mathematically rigorous, completely precise and unambiguous way how the data is generated. The codes for generating and processing the data will be documented in a human-readable format as well (as part of the Julia code files), explaining what they intend to do. The comma separated values-files from WP1-4 are intimately linked with the code that generated them. This linking is described in a bash script file that calls the code and generates the output file. The comments in these bash scripts will describe what numerical experiment the bash script will execute. For each experiment, a ReadMe file documents the computer architecture on which the experiments were carried out. The foregoing means that for each experimental data file X.csv, there is a corresponding X.sh that when executed generates the X.csv data file, and finally an X.txt plain text file that describes the This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 3 of 7 intention of the experiment, the computer architecture and computer parameters that were used, and if applicable, the precise table, figure, or section that the X.csv provides the data for in the preprint based on this data. The .csv-files will always start with a header that identifies the information contained in each column in a human-readable format. For example \"relative backward error\", \"time (s)\", \"peak memory consumption (MB)\", etc. The mathematically precise definition of the data items is rigorously encoded in the program code. The default file structure, limited to the data aspects, we use is: >AuthorInitials -> code -> experiments --> date of experiment ---> relevant code files ---> X.csv ---> X.sh ---> X.txt -> literature -> paper -> plots --> date of processing ---> relevant processing code files ---> generated figure output files (.eps, .pdf) ---> generated table output files (.txt, .tex) The raw data in the .csv-files will be processed exclusively using additional computer codes in, among others, Julia (.jl), Python (.py), Perl (.pl), Matlab/Octave (.m), or Gnuplot (.plot). They will generate, as necessary, the relevant plots in vector graphic formats like .eps and .pdf, or the relevant tables in LaTeX code, either as a standalone, importable LaTeX file (.tex) or simply as the relevant table environment that can be directly copied into the paper (.txt). Will a metadata standard be used? If so, describe in detail which standard will be used. If no, state in detail which metadata will be created to make the data easy/easier to find and reuse. No No standard metadata formats exist in our domain due to the highly variable types of data that is generated as a result of numerical simulations. In addition, as described above, the data-generating process is described in a fully formal way through the program code that generates the data. As such, most aspects that one would otherwise describe with metadata are formally encoded in the (human-readable and machine-executable) program code. In some sense, this code is the metadata. 5. Data storage and backup during the FWO project Where will the data be stored? All of the program codes, including the ones to generate and process the data, will be developed using a version management system, in particular KU Leuven GitLab. One (private) GitLab repository will be created wherein the codes will be developed by the authors. This private repository is also used to host and develop the LaTeX files of the scientific article based on the developed theory, algorithms, and data. This repository will be completely private with read and write access restricted to the authors involved in performing the research. When the final article is completed, a new fully public GitLab repository is created, hosting the final program codes and developed algorithms, including the codes for generating the data files and producing the processed data (i.e. figures and tables). This repository will have public read rights, but no write rights. Our articles will then reference this public repository. The articles themselves are posted as preprints to the arXiv.org preprint servers. Upon acceptance of the article, the final article's pdf-file, figures, code, and processed data is archived both to the PI's KU Leuven OneDrive (identified by the author's last names initials, then a dash, and then the arXiv identifier), as well as to the Department of Computer Science's NextCloud storage, under the modalities of the NUMA division's data management plan. During theoretical and practical development, the article files and codes will also be present on the author's personal work computer. After completing small chunks of work (e.g., once per day), these files are to be synchronized with the version management system (i.e., KU Leuven GitLab). During development, generated raw data files will be stored exclusively on the author's personal work computer (or potentially on external compute servers such as the VSC's). These data files are not crucial and can always be generated from the current version of the code in the private GitLab This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 4 of 7 repository. How is backup of the data provided? The program code will be stored in a KU Leuven GitLab repository, which provides both version control (i.e. tracking what changes were made when and by who) and automatic backups. Note that researchers developing the program code will keep their updates synchronized with the GitLab repository by committing and pushing the changes at least on a daily basis. The data generated and used by any of our articles will be stored in KU Leuven OneDrive, which provides automatic backups to KU Leuven servers. In addition, the paper, codes, figures, and processed data will be archived on the Department of Computer Science's NextCloud service upon completion and final acceptance of each article. These servers are also automatically backed up (in the Department of Computer Science). The data that is stored only on the author's work computers is not critical and can be generated from the code files or downloaded from public repositories (in the case of the MRI data files). Nevertheless, the Department of Computer Science automatically provides monthly backups of the home directories of all work computers. No specific backup policy is enforced on these files due to their transient and noncritical status. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. If no or insufficient storage or backup capacities are available then explain how this will be taken care of. Yes The storage offered within KU Leuven OneDrive will suffice for our long-term data storage needs, which are expected to be well below a hundred megabytes (in uncompressed format). What are the expected costs for data storage and back up during the project? How will these costs be covered? We will use free solutions offered by KU Leuven. Data security: how will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? No sensitive data will be processed. Recall that the MRI data is anonymous and contains no personally identifying information. Since this data is available in a public persistent figshare repository, we will not keep publically accessible copies of this data. The only copies will be local working copies on the researcher's computer. Aside from this MRI data from a public repository, our data mainly consists of numerical experimental data that we will generate and which is absolutely not sensitive, as it consists of algorithmic performance data. Consequently, no specific security measures will be taken, other than password protection of the work computers and usage of a private GitLab repository during the research phase of the project. This GitLab repository is secured with the KU Leuven Authenticator (which uses two-factor authentication). 6. Data preservation after the FWO project Which data will be retained for the expected 5 year period after the end of the project? In case only a selection of the data can/will be preserved, clearly state the reasons for this (legal or contractual restrictions, physical preservation issues, ...). The data that is reused will not be retained, as it is freely publically available in a persistent figshare repository and fully documented in a scientific article published in Scientific Data 9, no. 7. All generated convergence and performance data will be retained in the private GitLab repository for this project. All final data that constitutes the basis of our scientific articles will be replicated in the public GitLab repository for that paper. In addition, a version will be archived on the Department of Computer Science's NextCloud solution (as per the data management plan of the NUMA division). Finally, another copy will be archived in the PI's KU Leuven OneDrive repository, employing the naming conventions outlined above. Note that all of our data can be generated anew using our program codes. These codes are also stored in the private GitLab (for the working copies and research version), the public GitLab (for the final version), and private NextCloud and OneDrive (archived, final versions). Where will the data be archived (= stored for the longer term)? The final data, including the program codes that can generate these data anew, that are the basis of our scientific articles will be archived both in NextCloud (as per our division NUMA's data This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 5 of 7 management plan) and the PI's OneDrive. In addition, the fully public GitLab page corresponding to the article, as explained above, will also host the final data and codes. In the unlikely case that the volume of data is too large to store on GitLab, only the codes that can generate that data will be stored. Any researcher can then generate the data anew using these codes. What are the expected costs for data preservation during the retention period of 5 years? How will the costs be covered? Since the data volumes are expected to be very small (well below a few hundred megabytes), the storage limits of the Department of Computer Science's NextCloud, KU Leuven's OneDrive, and KU Leuven's GitLab will not be exceeded. Hence, the expected cost is zero. 7. Data sharing and reuse Are there any factors restricting or preventing the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions)? No All final research data that support our scientific articles will be made publically available in the aforementioned public GitLab repository. The reused data set will not be shared, since it is already available in the public domain in a public figshare repository. Which data will be made available after the end of the project? All final research data that support our scientific articles will be made publically available in the aforementioned public GitLab repository. The articles themselves will additionally be posted to the arXiv.org preprint servers. Where/how will the data be made available for reuse? In an Open Access repository All final research data, including our computer codes that can generate these data anew, that support our scientific articles will be made publically available in the aforementioned public GitLab repository. When will the data be made available? Immediately after the end of the project All final research data including our computer source code will be made publicly available in aforementioned GitHub repository after completing the project and uploading the resulting scientific article to the preprint server arXiv.org. Who will be able to access the data and under what conditions? All final data, excluding the computer source codes, will be released into the public domain through the aforementioned public GitLab repository of the article. No access control is necessary for this. The source codes will be released under a CC-BY-SA 4.0 licence, in the GitLab repository. This means that anyone can modify, update, and incorporate our code, as long as any redistribution of said codes documents these changes, attributes the original source, and imposes the same CC-BY- SA 4.0 license conditions. What are the expected costs for data sharing? How will the costs be covered? Since the data volumes are expected to be very small (well below a few hundred megabytes), the storage limits of KU Leuven's GitLab will not be exceeded. Hence, the expected cost is zero. 8. Responsibilities Who will be responsible for data documentation & metadata? Ph.D. student Simon Jacobsson is responsible for documenting the data, following the data protocols, and supplying the metadata (including computer codes). Who will be responsible for data storage & back up during the project? Ph.D. student Simon Jacobsson will be responsible for uploading all relevant data to GitLab. The PI Nick Vannieuwenhoven will be responsible for final archiving in the Department of Computer Science NextCloud storage system and in KU Leuven's OneDrive. This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 6 of 7 Who will be responsible for ensuring data preservation and reuse ? The PI bears the end responsibility of ensuring the data is preserved in NextCloud, OneDrive, and GitLab. Who bears the end responsibility for updating & implementing this DMP? The PI bears the end responsibility of updating & implementing this DMP. This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 7 of 7"
}