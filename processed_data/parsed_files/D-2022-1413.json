{
    "document_id": "D-2022-1413",
    "LinkTitle": "D-2022-1413",
    "file_name": "D-2022-1413.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2022-1413.pdf",
    "metadata": {
        "title": "caracal.docx",
        "author": "Marion MAETENS",
        "num_pages": 9
    },
    "content": {
        "full_text": "C14/21/114  DMP  V1.0 \n1  \nDMP in the context of the  C1 internal fund : UPTIDER (UZ/KU Leuven Program for post -mortem Tissue \nDonation to Enhance Research), a unique setting to unravel treatment resistance and disease \nprogression in patients with breast cancer.  \nADMIN DETAILS  \nProject Name: DMP UPTIDER  \nPrincipal Investigator / Researcher: Christine Desmedt  \nInstitution: KU Leuven  \n \n1. GENERAL INFORMATION  \nName of the project lead (PI)  \nDMP UPTIDER  \nChristine Desmedt  \n \nInternal Funds Project number & title  \nC14/21/114: UPTIDER (UZ/KU Leuven Program for post -mortem Tissue Donation to Enhance Research), \na unique setting to unravel treatment resistance and disease progression in patients with breast cancer.  \n \n \n2. DATA DESCRIP TION  \n2.1. Will you generate/collect new data and/or make use of existing data?  \n \nWe will generate and collect new data (prospective data and samples collection and make use of existing \ndata (retrospective data and samples collection).  \n \nThe project will collect pseudonymized clinical data collected after the patient consented to the study. \nClinical, histopathological and treatment data will be entered in the eCRF that we have designed in REDcap. \nAlso sample metadata (SPREC based) will be collected in LabCollector, a database that we have \ncustomized for the needs of UPTIDER.  \n \nOur research will generate: a) sequencing data  (fastqc and .bam files) on tissue and liquid samples \nincluding RNAseq bulk, single -nuclei, whole genome as well as targe ted genome sequencing, scripts (R, \nbash) to analyze the data, a web platform allowing browsing the results, Code Ocean capsules and framagit  \npages to reproduce and access the code, respectively, and, finally, manuscripts and publications.  \n \nC14/21/114  DMP  V1.0 \n2 In terms of data storage, data will be stored on UZ Leuven drives (eCRF) and KU Leuven drives (all other \ndata) in a GDPR compliant manner and with regular backups provided by the IT services for at least 5 years \nafter the end of the UPTIDER program.  \nWith regard to manuscript publication: in line  with GDPR and KU Leuven Open Science policy, no personnel \ndata will be made publicly available through public repositories such as GitHub and Code Ocean. A version \nof the manuscript will be uploaded to Lirias. Pers onal data (e.g. raw sequencing data) will be deposited on \npublic repositories such as the EGA, under restricted access. A Data Access Committee (DAC) will be \nnominated and will be in charge for reviewing access requests based on scientific project descript ions and \ngranting access to successful applicants.  \n \n2.2. What data will you collect, generate or reuse? Describe the origin, type and format of the data \n(per dataset) and its (estimated) volume. This may be easiest in a numbered list or table and per \nobjec tive of the project . \n \nWork \npackage  Data type  N° of \ncases  Data \nSource  Data content  Data \nFormat  Volume  \n(Go) \nWP1  Primary use, Pre -\nmortem prospective \nsamples collection  30   Samples  data Lab \ncollector, \nExcel files   0.5 \nWP2  Primary use, Post -\nmortem prospective \nsamples collection  30   Samples  data Lab \ncollector, \nExcel files   0.5 \nWP3  Secondary use, \nClinical data  30 Patient file  Demographic, \npathological, \nclinical, \ntreatment, \noutcome data \nand blood \nresults  eCRF \n(RedCap), \nR files   1 \nWP4  Secondary use, Pre-\nmortem \nretrospective \nsamples collection  30 MBC \nbiobank  Samples  data Lab \ncollector, \nExcel files   0.5 \nPrimary use, \nHisto(immunological) \ndata 1500    Pathological \ndata including \nmarkers \nscoring  Lab \ncollector, \nExcel files \nand \nimages   3000  \nPrimary use, \nAdipocyte \nmeasurement  30 HALO  Adipocytes \ncount and size  Images   1 \nWP5  Primary use, Bulk \nRNA seq  240 HiSeq \n4000  Gene \nexpression  fastq and \n.bam files   360 \nC14/21/114  DMP  V1.0 \n3 Primary use, snRNA \nseq  80 HiSeq \n4000  Gene \nexpression  .fastq and \n.bam files   800 \nWP6  Primary use, MILAN  120 MILAN  Multiplex  \nimaging  Text file  1 \nWP7  Primary use, WGS  250 HiSeq \n4000  genomics \ndata fastq and \n.bam files   7500  \nWP9  Primary use, TGS  540 HiSeq \n4000  genomics \ndata fastq and \n.bam files   1620  \n \n3. ETHICAL AND LEGAL ISSUES  \n3.1. Will you use personal data? If so, shortly describe the kind of personal data you will use. Add \nthe reference to the file in KU Leuven's Record of Processing Activities. Be aware that registering \nthe fact that you process personal data is a leg al obligation.  \n \nYes, we will use personal data. Data, irrespective of the WPs, include demographic (age, gender),  \npathological, clinical, treatment and outcome data as well as sequencing data  on tissue and liquid  samples \nincluding RNAseq  bulk, single -nuclei, whole genome as well as targeted genome sequencing.  \n \nPlease note, GDPR does not apply to deceased patients.  \n \nThe compliance monitoring form is the following: E-2021 -2282 . \n \n3.2. Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments \non humans or animals, dual use)? If so, add the reference to the formal approval by the relevant \nethical review committee(s).  \n \nThe UPTIDER project was approved by the EC UZ/KU Leuven: S64410.  \n \n3.3. Does your researc h possibly result in research data with potential for tech transfer and \nvalorisation? Will IP restrictions be claimed for the data you created? If so, for what data and \nwhich restrictions will be asserted?  \n \nThere is potential tech transfer/valorization in the putative assays/biomarkers we measure or we aim to \ndiscover. We are working with the Leuven Research and Development department (LRD) and the legal \nadvisors from UZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer \nAgreements (MTA/DTAs) we have set -up in the context of this project.  \n \n3.4. Do existing 3rd party agreements restrict dissemination or exploitation of the data you \n(re)use? If so, to what data do they relate and what restrictions regarding reuse and sharing ar e in \nplace?  \n \nC14/21/114  DMP  V1.0 \n4 We are working with the Leuven Research and Development department (LRD) and the legal advisors from \nUZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer Agreements \n(MTA/DTAs) we have set -up in the context of this project.  There is no specific data restriction.  \n \n4. DOCUMENTATION AND METADATA  \n4.1. What documentation will be provided to enable understanding and reuse of the data \ncollected/generated in this project?  \n \nAll collected clinical data are stored  in an e CRF (REDCap)  in which the documentation is automatically \nprovided though the auto generated dictionary and code book where all the requested data are described. \nAll collected data belonging to the sample collection are stored in an online lab management sy stem called \nLab Collector  based on SPREC requirements where all the requested data are described.  \n \nThe lab-specific generic data management plan  will guide researchers through data collection and \nprocessing workflows, ensuring efficient safe storage, keeping track of data use and associated processing \nrelated to each experimental step, and enabling data query filtering of the collected data.  \n \nRegarding omics data, bioinformatics pipeline s are shared on a common git repository and heavily \ndescribed so that they can be reproduced. When possible docker -like structure container will be used to \neasily share and perform bioinformatics pipeline. This c ontainer allows to enclose code and software so \nthat they can be reused with the exact same versions and parameters . \n \nThird -party software and algorithms that are used are referenced by their version numbers in our method \nsection and are installed as modul es on the VSC and/or containers (Docker, Singularity) on the VSC, to \nensure reproducibility . \n \nAt the publication level, a companion code capsule hosted by code ocean  will be build. It  will allow \nreproducing the figures of the paper , browsing code and accessing raw d ata. In case of restricted access \non the data, a synthetic dataset mimicking  the characteristic of the real data will be made available instead  \n(see section 7.2) . \n \n4.2. Will a metadata standard be used? If so, describe in detail which standard will be used. If  not, \nstate in detail which metadata will be created to make the data easy/easier to find and reuse.  \n \nMetadata will follow Data Cite’s recommendations  (Fenner et al., 2019) . \n \n5. DATA STORAGE AND BACKUP DURING THE PROJECT  \n5.1. Where will the data be stored?  \n \nThe minimum prese rvation term of 10 years after the end of the project will be applied to all datasets.  \nC14/21/114  DMP  V1.0 \n5 Biological samples obtained under research agreement will be kept according to the EC licenses and \nagreements. In effect, consent is obtained to store the samples for t he specific research purposes stipulated \nin the informed consent. Putative remnant clinical/patient samples are stored in the UZ Leuven biobank. \nThe digital data will be archived at special space provided by KU/UZ Leuven networks with restricted \naccess, co ntrolled by the PI. Hard copies (eg. the Informed Consent forms  and paper lab notebooks) are \nkept in locked cabinets in the lab of the PI concerned.  \n \nThe data will be stored on the KU Leuven servers. All systems but Lab Collector run on a secured and \nbacke d up server of KULeuven (managed by ICT of the Biomedical Sciences Group). These systems also \nprovide a logging system so no data can ever be erased, making that everything will be traceable and \nstored long -term (well beyond the common 5 -year requirement).  Lab Collector data base is externally and \nprofessionally managed by the company “AgileBio”.  \n \nDeveloped algorithms and software will be stored on  the KU Leuven servers , as well on public repositories \nsuch as framagit.com and codeocean.com.  \n \nRegarding the web platform, it will be hosted on a virtual server that will be created by the IT department of \nthe KU Leuven  (500 euros / year, covered by laboratory funds). Aggregated data will be transferred from \nthe L -drive to the virtual serve r at the time of publication.  \n \n5.2. How will the data be backed up?  \n \nThe hosting KUL server is automatically backed up using KUL services, multiple times per day. Concerning \nLabCollector, backups are automatically performed twice a day.  \n \n5.3. Is there currently sufficient storage & backup capacity during the project? If yes, specify \nconcisely. If no or insufficient storage or backup capacities are available, then explain how this \nwill be taken care of.  \n \nThere is sufficient storage and bac k-up capacity on all KU Leuven servers:  \n- the “L -drive” is an easily scalable system, built from General Parallel File System (GPFS) cluster with \nNetApp series storage systems, and a CTDB samba cluster in the front -end.  \n- the Staging and Archive on VSC are also sufficiently scalable (petabyte scale).  \n \n5.4. What are the expected costs for data storage and backup during the project? How will these \ncosts be covered ?  \n \nThe total estimated cost of data storage and backup during the project is  2100  per year . This estimation is \nbased on the following costs:  \n- 1500  euros  for storage on the L -drive of 13500 Go at 0.111 EUR/Go/year .  \n- 600 euros  for storage on the VSC cluster of 1000  Go at 0.6 EUR/Go/year . \n \nC14/21/114  DMP  V1.0 \n6 Budget for compute and data storage is budgeted in the C1 for one year, additional cost will be covered by \nthe fun ds of the laboratory .  \n \n5.5. Data security: how will you ensure that the data are securely stored and not accessed or \nmodified by unauthorized persons?  \n  \nOur eCRF, our lab management system (Lab Collector), and the network drive dedicated to the team (L-\ndrive) are password access -protected by users, with person -based decision on rights to access and modify \ndata. Moreover, this is the same for the VSC secured storage which is only accessible to VSC accounts, \nand specifically our volume will only be acce ssible to group members.  \n \n6. DATA PRESERVATION AFTER THE END OF THE PROJECT  \n6.1. Which data will be retained for the expected 10  year period after the end of the project? If only \na selection of the data can/will be preserved, clearly state why this is the case (legal or contractual \nrestrictions, physical preservation issues, ...).  \n \nThe minimum preservation term of 10 years after the end of the project will be applied to all datasets  \ndescribed above.  \n \n6.2. Where will these data be archived (= stored for the  long term)?  \n \nAs a general rule, datasets will be made openly accessible, whenever possible via existing platforms that \nsupport FAIR data sharing (www.fairsharing.org), at the latest at the time of publication or preprint \ndeposition.  \n \nFor all other datase ts, long term storage will be ensured as follows:  \n- Large sequencing/omics data: will be stored on “L -drive”.  \n- Small digital files: files will be stored on the “L -drive”.  \n- Developed algorithms and software will be stored on L -drive, as well on public repositories such as \nframagit.com and codeocean.com.  \n- Clinical and sample data will be stored in our lab management tools (eCRF and Lab Collector).  \n \n6.3. What are the expected  costs for data preservation during these 10 years? How will the costs \nbe covered ?  \n \nThe total estimated cost of data storage during the 10 years after the end of the project is  15000 euros . \nThis estimation is based on the total given in Table 1 and the cost of storage on the L -Drive (0,11 1/Go/year). \nThe cost will be covered by the laboratory budget.  \n \n \n \nC14/21/114  DMP  V1.0 \n7 7. DATA SHARING AND RE -USE \n7.1. Are there any factors restricting or preventing the sharing of (some of) the data (e.g. as \ndefined in an agreement with a 3rd party, legal restrictions or because of IP potential)?  \n \nThere is no specific restriction.  \nPersonal data will only be published after de -identification and identifiers will not be published.  \nPlease note, GDPR does not apply to deceased patients.  \n \n7.2. Which data will be made available after the end of the project?  \n \nWe are committed to publish research results  (concerning all datasets)  to communicate them to peers and \nto a wide audience. All research outputs supporting publications will be made ope nly accessible. Depending \non their nature, some data may be made available prior to publication, either on an individual basis to \ninterested researchers and/or potential new collaborators, or publicly via repositories (e.g. negative data). \nMTA and or DTA h ave been set -up in this sense and will be set -up if needed.  \n \nAs part of the open access plan, data will be put available for external users through open source pathways . \nIn that case, these data will be made available after appropriate IP protection.  \n \nUpon  publication, all anonymized patient details supporting a manuscript will be made publicly available as \nsupplemental information. Personal data will only be published/shared after de -identification and identifiers \nwill not be published/shared.  \n \nOmics datas ets will be deposited in open access repositories such the NCBI Gene Expression Omnibus \n(GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software \ncode driving the project will be stored in a private online git re pository of the laboratory. As soon as the \nmanuscript is publicly available, the repository will be changed to a public repository. The platform Code \nCapsule will be used upon publication to increase reproducibility of the research and open both data and \ncode supporting the publication. The code required to generate the figures of the paper will be available \nonline. Publicly available data will be directly included in the capsule allowing to easily reproduce the paper \nonline. In case part of the data falls under restricted access, a synthetic  version of it will be made available, \nallowing the user to run the code. Proper data will be made available with a granted MTA or DTA.  \n \n7.3. Where/how will the data be made available for reuse?  \n \nIn an Open Access repository.  \nUpon publication, all anonymized patient details supporting a manuscript will be made publicly available as \nsupplemental information.  \n \nOmics datasets will be deposited in open access repositories such the NCBI Gene Expression Omnibus \n(GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software \nC14/21/114  DMP  V1.0 \n8 code driving the project will be stored in a private online git repository of the laboratory. As soon as the \nmanuscript is publicly available, the repositor y will be changed to a public repository . \nA web platform  hosted on a virtual server at the KU Leuven will allow browsing the results of the publication, \nshowing only aggregated data.  \n \n7.4. When will the data be made available?  \n \nUpon publication. However, depending on their nature, some data may be made available prior to \npublication, either on an individual basis to interested researchers and/or potential new collaborators, or \npublicly via repositories (e.g. negative data). MTA and or DTA have been set -up in this sense and will be \nset-up if needed.  \n \n7.5. Who will be able to access the data and under what conditions?  \n \nWhenever possible, datasets and the appropriate metadata will be made publicly available through \nrepositories that support FAIR data sharing.  \nMoreover, as mentioned above MTA and or DTA have been set -up and will be set -up if needed.  \n \n7.6. What are the expected costs for data sharing? How will these costs be covered?  \n \nIt is the intention to minimize data management costs by implementing standard procedures e.g. for \nmetadata collection and file storage and organization from the start of the project, and by using free -to-use \ndata repositories and dissemination facilities whenever possible.  Data management costs will be covered \nby the labora tory budget.  \n \n8. RESPONSIBILITIES  \n8.1. Who will be responsible for the data documentation & metadata?  \n \nMetadata will be documented by the senior post -doc, research manager, PhD students and technical staff \nat the time of data collection and analysis.  \n \n8.2. Who will be responsible for data storage & back up during the project?  \n  \nThe senior post -doc, research manager and technical staff will ensure data storage and back up, with \nsupport from ICTS, gbiomed -IT staff, and UZ -IT staff.  \n \n8.3. Who will be responsi ble for ensuring data preservation and sharing?  \n  \nThe PI is responsible for data preservation and sharing, with support from the team, ICTS, gbiomed -IT staff, \nand UZ -IT staff.  \n \nC14/21/114  DMP  V1.0 \n9 8.4. Who bears the end responsibility for updating & implementing this DMP?  \n  \nThe PI is ultimately responsible for all data management during and after data collection, including \nimplementing and updating the DMP.  \n "
    },
    "clean_full_text": "C14/21/114 DMP V1.0 1 DMP in the context of the C1 internal fund : UPTIDER (UZ/KU Leuven Program for post -mortem Tissue Donation to Enhance Research), a unique setting to unravel treatment resistance and disease progression in patients with breast cancer. ADMIN DETAILS Project Name: DMP UPTIDER Principal Investigator / Researcher: Christine Desmedt Institution: KU Leuven 1. GENERAL INFORMATION Name of the project lead (PI) DMP UPTIDER Christine Desmedt Internal Funds Project number & title C14/21/114: UPTIDER (UZ/KU Leuven Program for post -mortem Tissue Donation to Enhance Research), a unique setting to unravel treatment resistance and disease progression in patients with breast cancer. 2. DATA DESCRIP TION 2.1. Will you generate/collect new data and/or make use of existing data? We will generate and collect new data (prospective data and samples collection and make use of existing data (retrospective data and samples collection). The project will collect pseudonymized clinical data collected after the patient consented to the study. Clinical, histopathological and treatment data will be entered in the eCRF that we have designed in REDcap. Also sample metadata (SPREC based) will be collected in LabCollector, a database that we have customized for the needs of UPTIDER. Our research will generate: a) sequencing data (fastqc and .bam files) on tissue and liquid samples including RNAseq bulk, single -nuclei, whole genome as well as targe ted genome sequencing, scripts (R, bash) to analyze the data, a web platform allowing browsing the results, Code Ocean capsules and framagit pages to reproduce and access the code, respectively, and, finally, manuscripts and publications. C14/21/114 DMP V1.0 2 In terms of data storage, data will be stored on UZ Leuven drives (eCRF) and KU Leuven drives (all other data) in a GDPR compliant manner and with regular backups provided by the IT services for at least 5 years after the end of the UPTIDER program. With regard to manuscript publication: in line with GDPR and KU Leuven Open Science policy, no personnel data will be made publicly available through public repositories such as GitHub and Code Ocean. A version of the manuscript will be uploaded to Lirias. Pers onal data (e.g. raw sequencing data) will be deposited on public repositories such as the EGA, under restricted access. A Data Access Committee (DAC) will be nominated and will be in charge for reviewing access requests based on scientific project descript ions and granting access to successful applicants. 2.2. What data will you collect, generate or reuse? Describe the origin, type and format of the data (per dataset) and its (estimated) volume. This may be easiest in a numbered list or table and per objec tive of the project . Work package Data type N° of cases Data Source Data content Data Format Volume (Go) WP1 Primary use, Pre - mortem prospective samples collection 30 Samples data Lab collector, Excel files 0.5 WP2 Primary use, Post - mortem prospective samples collection 30 Samples data Lab collector, Excel files 0.5 WP3 Secondary use, Clinical data 30 Patient file Demographic, pathological, clinical, treatment, outcome data and blood results eCRF (RedCap), R files 1 WP4 Secondary use, Pre- mortem retrospective samples collection 30 MBC biobank Samples data Lab collector, Excel files 0.5 Primary use, Histo(immunological) data 1500 Pathological data including markers scoring Lab collector, Excel files and images 3000 Primary use, Adipocyte measurement 30 HALO Adipocytes count and size Images 1 WP5 Primary use, Bulk RNA seq 240 HiSeq 4000 Gene expression fastq and .bam files 360 C14/21/114 DMP V1.0 3 Primary use, snRNA seq 80 HiSeq 4000 Gene expression .fastq and .bam files 800 WP6 Primary use, MILAN 120 MILAN Multiplex imaging Text file 1 WP7 Primary use, WGS 250 HiSeq 4000 genomics data fastq and .bam files 7500 WP9 Primary use, TGS 540 HiSeq 4000 genomics data fastq and .bam files 1620 3. ETHICAL AND LEGAL ISSUES 3.1. Will you use personal data? If so, shortly describe the kind of personal data you will use. Add the reference to the file in KU Leuven's Record of Processing Activities. Be aware that registering the fact that you process personal data is a leg al obligation. Yes, we will use personal data. Data, irrespective of the WPs, include demographic (age, gender), pathological, clinical, treatment and outcome data as well as sequencing data on tissue and liquid samples including RNAseq bulk, single -nuclei, whole genome as well as targeted genome sequencing. Please note, GDPR does not apply to deceased patients. The compliance monitoring form is the following: E-2021 -2282 . 3.2. Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, add the reference to the formal approval by the relevant ethical review committee(s). The UPTIDER project was approved by the EC UZ/KU Leuven: S64410. 3.3. Does your researc h possibly result in research data with potential for tech transfer and valorisation? Will IP restrictions be claimed for the data you created? If so, for what data and which restrictions will be asserted? There is potential tech transfer/valorization in the putative assays/biomarkers we measure or we aim to discover. We are working with the Leuven Research and Development department (LRD) and the legal advisors from UZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer Agreements (MTA/DTAs) we have set -up in the context of this project. 3.4. Do existing 3rd party agreements restrict dissemination or exploitation of the data you (re)use? If so, to what data do they relate and what restrictions regarding reuse and sharing ar e in place? C14/21/114 DMP V1.0 4 We are working with the Leuven Research and Development department (LRD) and the legal advisors from UZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer Agreements (MTA/DTAs) we have set -up in the context of this project. There is no specific data restriction. 4. DOCUMENTATION AND METADATA 4.1. What documentation will be provided to enable understanding and reuse of the data collected/generated in this project? All collected clinical data are stored in an e CRF (REDCap) in which the documentation is automatically provided though the auto generated dictionary and code book where all the requested data are described. All collected data belonging to the sample collection are stored in an online lab management sy stem called Lab Collector based on SPREC requirements where all the requested data are described. The lab-specific generic data management plan will guide researchers through data collection and processing workflows, ensuring efficient safe storage, keeping track of data use and associated processing related to each experimental step, and enabling data query filtering of the collected data. Regarding omics data, bioinformatics pipeline s are shared on a common git repository and heavily described so that they can be reproduced. When possible docker -like structure container will be used to easily share and perform bioinformatics pipeline. This c ontainer allows to enclose code and software so that they can be reused with the exact same versions and parameters . Third -party software and algorithms that are used are referenced by their version numbers in our method section and are installed as modul es on the VSC and/or containers (Docker, Singularity) on the VSC, to ensure reproducibility . At the publication level, a companion code capsule hosted by code ocean will be build. It will allow reproducing the figures of the paper , browsing code and accessing raw d ata. In case of restricted access on the data, a synthetic dataset mimicking the characteristic of the real data will be made available instead (see section 7.2) . 4.2. Will a metadata standard be used? If so, describe in detail which standard will be used. If not, state in detail which metadata will be created to make the data easy/easier to find and reuse. Metadata will follow Data Cite’s recommendations (Fenner et al., 2019) . 5. DATA STORAGE AND BACKUP DURING THE PROJECT 5.1. Where will the data be stored? The minimum prese rvation term of 10 years after the end of the project will be applied to all datasets. C14/21/114 DMP V1.0 5 Biological samples obtained under research agreement will be kept according to the EC licenses and agreements. In effect, consent is obtained to store the samples for t he specific research purposes stipulated in the informed consent. Putative remnant clinical/patient samples are stored in the UZ Leuven biobank. The digital data will be archived at special space provided by KU/UZ Leuven networks with restricted access, co ntrolled by the PI. Hard copies (eg. the Informed Consent forms and paper lab notebooks) are kept in locked cabinets in the lab of the PI concerned. The data will be stored on the KU Leuven servers. All systems but Lab Collector run on a secured and backe d up server of KULeuven (managed by ICT of the Biomedical Sciences Group). These systems also provide a logging system so no data can ever be erased, making that everything will be traceable and stored long -term (well beyond the common 5 -year requirement). Lab Collector data base is externally and professionally managed by the company “AgileBio”. Developed algorithms and software will be stored on the KU Leuven servers , as well on public repositories such as framagit.com and codeocean.com. Regarding the web platform, it will be hosted on a virtual server that will be created by the IT department of the KU Leuven (500 euros / year, covered by laboratory funds). Aggregated data will be transferred from the L -drive to the virtual serve r at the time of publication. 5.2. How will the data be backed up? The hosting KUL server is automatically backed up using KUL services, multiple times per day. Concerning LabCollector, backups are automatically performed twice a day. 5.3. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. If no or insufficient storage or backup capacities are available, then explain how this will be taken care of. There is sufficient storage and bac k-up capacity on all KU Leuven servers: - the “L -drive” is an easily scalable system, built from General Parallel File System (GPFS) cluster with NetApp series storage systems, and a CTDB samba cluster in the front -end. - the Staging and Archive on VSC are also sufficiently scalable (petabyte scale). 5.4. What are the expected costs for data storage and backup during the project? How will these costs be covered ? The total estimated cost of data storage and backup during the project is 2100 per year . This estimation is based on the following costs: - 1500 euros for storage on the L -drive of 13500 Go at 0.111 EUR/Go/year . - 600 euros for storage on the VSC cluster of 1000 Go at 0.6 EUR/Go/year . C14/21/114 DMP V1.0 6 Budget for compute and data storage is budgeted in the C1 for one year, additional cost will be covered by the fun ds of the laboratory . 5.5. Data security: how will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? Our eCRF, our lab management system (Lab Collector), and the network drive dedicated to the team (L- drive) are password access -protected by users, with person -based decision on rights to access and modify data. Moreover, this is the same for the VSC secured storage which is only accessible to VSC accounts, and specifically our volume will only be acce ssible to group members. 6. DATA PRESERVATION AFTER THE END OF THE PROJECT 6.1. Which data will be retained for the expected 10 year period after the end of the project? If only a selection of the data can/will be preserved, clearly state why this is the case (legal or contractual restrictions, physical preservation issues, ...). The minimum preservation term of 10 years after the end of the project will be applied to all datasets described above. 6.2. Where will these data be archived (= stored for the long term)? As a general rule, datasets will be made openly accessible, whenever possible via existing platforms that support FAIR data sharing (www.fairsharing.org), at the latest at the time of publication or preprint deposition. For all other datase ts, long term storage will be ensured as follows: - Large sequencing/omics data: will be stored on “L -drive”. - Small digital files: files will be stored on the “L -drive”. - Developed algorithms and software will be stored on L -drive, as well on public repositories such as framagit.com and codeocean.com. - Clinical and sample data will be stored in our lab management tools (eCRF and Lab Collector). 6.3. What are the expected costs for data preservation during these 10 years? How will the costs be covered ? The total estimated cost of data storage during the 10 years after the end of the project is 15000 euros . This estimation is based on the total given in Table 1 and the cost of storage on the L -Drive (0,11 1/Go/year). The cost will be covered by the laboratory budget. C14/21/114 DMP V1.0 7 7. DATA SHARING AND RE -USE 7.1. Are there any factors restricting or preventing the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions or because of IP potential)? There is no specific restriction. Personal data will only be published after de -identification and identifiers will not be published. Please note, GDPR does not apply to deceased patients. 7.2. Which data will be made available after the end of the project? We are committed to publish research results (concerning all datasets) to communicate them to peers and to a wide audience. All research outputs supporting publications will be made ope nly accessible. Depending on their nature, some data may be made available prior to publication, either on an individual basis to interested researchers and/or potential new collaborators, or publicly via repositories (e.g. negative data). MTA and or DTA h ave been set -up in this sense and will be set -up if needed. As part of the open access plan, data will be put available for external users through open source pathways . In that case, these data will be made available after appropriate IP protection. Upon publication, all anonymized patient details supporting a manuscript will be made publicly available as supplemental information. Personal data will only be published/shared after de -identification and identifiers will not be published/shared. Omics datas ets will be deposited in open access repositories such the NCBI Gene Expression Omnibus (GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software code driving the project will be stored in a private online git re pository of the laboratory. As soon as the manuscript is publicly available, the repository will be changed to a public repository. The platform Code Capsule will be used upon publication to increase reproducibility of the research and open both data and code supporting the publication. The code required to generate the figures of the paper will be available online. Publicly available data will be directly included in the capsule allowing to easily reproduce the paper online. In case part of the data falls under restricted access, a synthetic version of it will be made available, allowing the user to run the code. Proper data will be made available with a granted MTA or DTA. 7.3. Where/how will the data be made available for reuse? In an Open Access repository. Upon publication, all anonymized patient details supporting a manuscript will be made publicly available as supplemental information. Omics datasets will be deposited in open access repositories such the NCBI Gene Expression Omnibus (GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software C14/21/114 DMP V1.0 8 code driving the project will be stored in a private online git repository of the laboratory. As soon as the manuscript is publicly available, the repositor y will be changed to a public repository . A web platform hosted on a virtual server at the KU Leuven will allow browsing the results of the publication, showing only aggregated data. 7.4. When will the data be made available? Upon publication. However, depending on their nature, some data may be made available prior to publication, either on an individual basis to interested researchers and/or potential new collaborators, or publicly via repositories (e.g. negative data). MTA and or DTA have been set -up in this sense and will be set-up if needed. 7.5. Who will be able to access the data and under what conditions? Whenever possible, datasets and the appropriate metadata will be made publicly available through repositories that support FAIR data sharing. Moreover, as mentioned above MTA and or DTA have been set -up and will be set -up if needed. 7.6. What are the expected costs for data sharing? How will these costs be covered? It is the intention to minimize data management costs by implementing standard procedures e.g. for metadata collection and file storage and organization from the start of the project, and by using free -to-use data repositories and dissemination facilities whenever possible. Data management costs will be covered by the labora tory budget. 8. RESPONSIBILITIES 8.1. Who will be responsible for the data documentation & metadata? Metadata will be documented by the senior post -doc, research manager, PhD students and technical staff at the time of data collection and analysis. 8.2. Who will be responsible for data storage & back up during the project? The senior post -doc, research manager and technical staff will ensure data storage and back up, with support from ICTS, gbiomed -IT staff, and UZ -IT staff. 8.3. Who will be responsi ble for ensuring data preservation and sharing? The PI is responsible for data preservation and sharing, with support from the team, ICTS, gbiomed -IT staff, and UZ -IT staff. C14/21/114 DMP V1.0 9 8.4. Who bears the end responsibility for updating & implementing this DMP? The PI is ultimately responsible for all data management during and after data collection, including implementing and updating the DMP."
}