{
    "document_id": "D-2024-3133",
    "LinkTitle": "D-2024-3133",
    "file_name": "D-2024-3133.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/converted_pdf/D-2024-3133.pdf",
    "metadata": {
        "title": "D-2024-3133",
        "author": "Naomi Vanlessen",
        "num_pages": 5
    },
    "content": {
        "full_text": "GENERAL\nVarious data collection methods are employed depending on the specific experiments planned within \nthe ERC project:\nData(set) Description New or reusedFile format Estimated \nmax \nvolume\nAesthetic \npreferences for \nimagesOnline studies; \nPreference ratings \nof images collected \nin experiments \nprogrammed in the \njsPsych frameworkNewRaw image data is \nexported in .json and \npreference ratings are \nsaved in .csv for \nfurther analyses.<1GB\nDrawings/Notes \nfrom focus groups \nwith artists and \nteachers in art and \ndesignPen and paper data \ncollected in focus \ngroups will be \nscanned and \npreserved as pdf \nfilesNew.pdf <1TB\nRecordings from \nfocus groups with \nartists and \nteachers in art and \ndesignAudio- and video \nrecordings of focus \ngroupsNewStored as .mp3 \nor .mp4-files<1TB\nPsychophysical \ndataPsychophysical \ndata collected in \nin-lab experiments \ndeveloped in the \nPsychoPy \nframeworkNewRaw data exported \nas .csv files<1GB\nQuestionnaire \ndataCollected on a \ncomputer or tablet, \nor pen-and-paper \nquestionnairesNewData collected on \ncomputer or tablet are \nstored as .csv or .txt-\nfiles; paper \nquestionnaires will be \nscanned and stored \nas .pdf-files.\nEye tracking data Collected during \nin-lab experiments \nusing the SR \nresearch eye \ntracking NewRaw data stored \nas .edf.\nSince the raw data are \ncompressed and \nencoded to be only < 1 TB\nequipment. readable with the \nmanufacturer's analysis  \nsoftware (dataviewer), \nwe also provide \ndatafiles in a text \nformat.\nIf applicable, \nparameters used for \npreprocessing are \ndescribed in a readme \nfile.\nCollected using the \nTobii Glasses \nmobile eye \ntracking devices \nduring museum \nexhibitionsNewRaw data stored in \nfolders with \nstructure for Tobii \neyetrackers (including \ncompressed data \nin .json-files and \nvideos in .mkv \nformat from the scene \ncamera).\nSince the raw data are \ncompressed and \nencoded to be only \nreadable with the \nmanufacturer's analysis  \nsoftware (Tobii Pro \nLab), we also provide \ndatafiles in a text \nformat.\nIf applicable, \nparameters used for \npossible preprocessing \nare described in a \nreadme file.< 1 TB\nModel source code In addition to \ntraining and \nevaluation, the \nmodel source code \nis used to predict \naesthetic scores. New and \nreused: \nspecifies \nwhether the \nsource code is \nnewly written \nor reused, \nincluding \npretrained \nmodels and \nexisting codes.Typically provided in \nPython (.py) or Jupyter  \nnotebook (.ipynb) files.  \nAdditionally, a \nReadMe file (.me)\nexplaining how to use \nthe code.< 1 TB\nTrained model Metadata and \ntraining details of NewStored in Python \nframeworks such as < 1 TB\nthe saved model \nafter training, \nincluding all \nlearned parameters \nand weights of the \nmodel.PyTorch, Keras, or \nTensorflow.\nGenerated \ndatasetsDatasets that have \nbeen created \nduring the project, \nincluding any \nsynthetic data, data \ntransformations \napplied to original \ndatasets, or \nartificial images \ngenerated by AI \ntools.NewImages are described \nin .csv-files, or stored \nas .jpeg, .png or .pdf-\nfiles.< 1 TB\n(Annotated) image \ndatasetsDatasets with \nbehavioral ratings \nused for model \ntraining.New (e.g. \nLAPIS)Images are described \nin .csv-files, or stored \nas .jpeg, .png or .pdf-\nfiles.< 1 TB\nBenchmark \ndatasetsStandardized \ndatasets, publicly \navailable, used for \nevaluating and \ncomparing the \nperformance of \nmodels.Reused\nBenchmark \ndatasets for \naesthetics: \nJenAesthetics, \nPARA, \nTAD66k, ...\nBenchmark \ndatasets for \nnatural images: \nMNIST, \nImageNet, … \nMore may be \nadded during \nthe course of \nthe project.Images are described \nin .csv-files, or stored \nas .jpeg, .png or .pdf-\nfiles.< 1 TB\n1. MAKING DATA FINDABLE (dataset description: metadata, persistent and unique identifiers \ne.g., DOI)\nDuring the research project, the research data are stored on the researchers’ computer and software \nscripts are uploaded on the Gitlab repository hosted by KU Leuven. The computers and storage \nsolutions are managed by KU Leuven which means that all data is backed up automatically.  \nUpon completion of a study, data will be stored on a KU Leuven long-term data storage solution (e.g., \nSharepoint) using a similar folder structure within each study. Additionally, all data, code and material \nwill be handed to the PI upon completion of a study.  \nFurthermore, the research data will be made available via de KU Leuven data repository RDR or OSF \nwhere they will be assigned a unique DOI for further accessibility. Both RDR and OSF use metadata \nto facilitate findability of data.\n2. MAKING DATA OPENLY ACCESSIBLE (which data will be made openly available and if some  \ndatasets remain closed, the reasons for not giving access; where the data and associated metadata, \ndocumentation and code are deposited (repository?); how the data can be accessed (are relevant \nsoftware tools/methods provided?)\nData from online experiments, computer-based experiments, questionnaires and eye-tracking-\nexperiments will be anonymized and shared via the RDR managed by the KU Leuven or the osf.io \nplatform (field standard). Next to the research data file, we will share  –as far as possible- stimuli, \nexperiment programs, analysis code and extensive documentation of the data files. If full \nanonymization is not possible, the datasets will only be shared upon request.\nCode used for machine learning studies is stored on GitLab. The trained models, datasets, and training \ndetails are shared via the RDR managed by the KU Leuven or the osf.io platform (field standard).\nFor scientific publications, open access will be guaranteed either through the journal’s open access \nsystem or through publishing the preproof publications on the open access system of the KU Leuven \n(i.e., Lirias).\n3. MAKING DATA INTEROPERABLE (which standard or field-specific data and metadata \nvocabularies and methods will be used)\nThe anonymized data and/or the data formatted as text or .cvs files are shared (depending on the size \nof the raw datafiles). Data will be deposited in a format that can be accessible for everyone whenever \npossible. Most of our experiments yield data that can be represented in .csv file format. Datasets \nconsist of images represented in common image file formats (e.g., .jpeg, .png, …).\nWe will use relevant metadata descriptor standards that apply to each specific type of data set (e.g., \ndata dictionaries/code books for behavioral and eye-tracking studies, code is documented and made \npublicly available in Gitlab).\nFor the studies based on machine learning, datasets and code are released in .readme files that explain \nin detail the content of code, annotation and data, and how to use them.\n4. INCREASE DATA RE-USE (what data will remain re-usable and for how long, is embargo \nforeseen; how the data is licensed;  data quality assurance procedures)\nRich metadata and documentation will be provided for all data files. This can include:\nA codebook that will accompany the output of each experiment, which properly describes the \ncontent of the data files.  \nA file containing the methodology of the experiment stored as .txt, .pdf, or .readme-files\nAnnotated scripts/code for running the experiment and analysis if applicable. Data are \nanalyzed using R, Matlab and/or Python, saved in their native formats (respectively, .R, .m \nand .py). Scripts formatting the text data files outputted by the manufacturer's software \n(EDF2ASC, dataviewer or Tobii Pro Lab) prior to formal analyses, are provided.\nResearch output will be made available via RDR or OSF, at the moment of publication. Creative \ncommons attribution licenses will be selected in RDR or OSF.\nTo ensure qualitative data storage, XXXXXXXXXXXXXXXX will check the completeness  of the \ndocumentation.\n5. ALLOCATION OF RESOURCES and DATA SECURITY (estimated costs for making the \nproject data open access and potential value of long-term data preservation; procedures for data \nbackup and recovery; transfer of sensitive data and secure storage in repositories for long term \npreservation and curation)\nThere are no costs attached to apply the FAIR-principles to the data and research outputs because \nrepositories and other resources are provided by KU Leuven free of charge , including GitLab and \nRDR. Additionally, also the usage of OSF is free of charge. Individual researchers are responsible for \ndata management during the course of their projects. The grant-holder will ensure the long-term \nstorage of the data at KU Leuven."
    },
    "clean_full_text": "GENERAL Various data collection methods are employed depending on the specific experiments planned within the ERC project: Data(set) Description New or reusedFile format Estimated max volume Aesthetic preferences for imagesOnline studies; Preference ratings of images collected in experiments programmed in the jsPsych frameworkNewRaw image data is exported in .json and preference ratings are saved in .csv for further analyses.<1GB Drawings/Notes from focus groups with artists and teachers in art and designPen and paper data collected in focus groups will be scanned and preserved as pdf filesNew.pdf <1TB Recordings from focus groups with artists and teachers in art and designAudio- and video recordings of focus groupsNewStored as .mp3 or .mp4-files<1TB Psychophysical dataPsychophysical data collected in in-lab experiments developed in the PsychoPy frameworkNewRaw data exported as .csv files<1GB Questionnaire dataCollected on a computer or tablet, or pen-and-paper questionnairesNewData collected on computer or tablet are stored as .csv or .txt- files; paper questionnaires will be scanned and stored as .pdf-files. Eye tracking data Collected during in-lab experiments using the SR research eye tracking NewRaw data stored as .edf. Since the raw data are compressed and encoded to be only < 1 TB equipment. readable with the manufacturer's analysis software (dataviewer), we also provide datafiles in a text format. If applicable, parameters used for preprocessing are described in a readme file. Collected using the Tobii Glasses mobile eye tracking devices during museum exhibitionsNewRaw data stored in folders with structure for Tobii eyetrackers (including compressed data in .json-files and videos in .mkv format from the scene camera). Since the raw data are compressed and encoded to be only readable with the manufacturer's analysis software (Tobii Pro Lab), we also provide datafiles in a text format. If applicable, parameters used for possible preprocessing are described in a readme file.< 1 TB Model source code In addition to training and evaluation, the model source code is used to predict aesthetic scores. New and reused: specifies whether the source code is newly written or reused, including pretrained models and existing codes.Typically provided in Python (.py) or Jupyter notebook (.ipynb) files. Additionally, a ReadMe file (.me) explaining how to use the code.< 1 TB Trained model Metadata and training details of NewStored in Python frameworks such as < 1 TB the saved model after training, including all learned parameters and weights of the model.PyTorch, Keras, or Tensorflow. Generated datasetsDatasets that have been created during the project, including any synthetic data, data transformations applied to original datasets, or artificial images generated by AI tools.NewImages are described in .csv-files, or stored as .jpeg, .png or .pdf- files.< 1 TB (Annotated) image datasetsDatasets with behavioral ratings used for model training.New (e.g. LAPIS)Images are described in .csv-files, or stored as .jpeg, .png or .pdf- files.< 1 TB Benchmark datasetsStandardized datasets, publicly available, used for evaluating and comparing the performance of models.Reused Benchmark datasets for aesthetics: JenAesthetics, PARA, TAD66k, ... Benchmark datasets for natural images: MNIST, ImageNet, … More may be added during the course of the project.Images are described in .csv-files, or stored as .jpeg, .png or .pdf- files.< 1 TB 1. MAKING DATA FINDABLE (dataset description: metadata, persistent and unique identifiers e.g., DOI) During the research project, the research data are stored on the researchers’ computer and software scripts are uploaded on the Gitlab repository hosted by KU Leuven. The computers and storage solutions are managed by KU Leuven which means that all data is backed up automatically. Upon completion of a study, data will be stored on a KU Leuven long-term data storage solution (e.g., Sharepoint) using a similar folder structure within each study. Additionally, all data, code and material will be handed to the PI upon completion of a study. Furthermore, the research data will be made available via de KU Leuven data repository RDR or OSF where they will be assigned a unique DOI for further accessibility. Both RDR and OSF use metadata to facilitate findability of data. 2. MAKING DATA OPENLY ACCESSIBLE (which data will be made openly available and if some datasets remain closed, the reasons for not giving access; where the data and associated metadata, documentation and code are deposited (repository?); how the data can be accessed (are relevant software tools/methods provided?) Data from online experiments, computer-based experiments, questionnaires and eye-tracking- experiments will be anonymized and shared via the RDR managed by the KU Leuven or the osf.io platform (field standard). Next to the research data file, we will share –as far as possible- stimuli, experiment programs, analysis code and extensive documentation of the data files. If full anonymization is not possible, the datasets will only be shared upon request. Code used for machine learning studies is stored on GitLab. The trained models, datasets, and training details are shared via the RDR managed by the KU Leuven or the osf.io platform (field standard). For scientific publications, open access will be guaranteed either through the journal’s open access system or through publishing the preproof publications on the open access system of the KU Leuven (i.e., Lirias). 3. MAKING DATA INTEROPERABLE (which standard or field-specific data and metadata vocabularies and methods will be used) The anonymized data and/or the data formatted as text or .cvs files are shared (depending on the size of the raw datafiles). Data will be deposited in a format that can be accessible for everyone whenever possible. Most of our experiments yield data that can be represented in .csv file format. Datasets consist of images represented in common image file formats (e.g., .jpeg, .png, …). We will use relevant metadata descriptor standards that apply to each specific type of data set (e.g., data dictionaries/code books for behavioral and eye-tracking studies, code is documented and made publicly available in Gitlab). For the studies based on machine learning, datasets and code are released in .readme files that explain in detail the content of code, annotation and data, and how to use them. 4. INCREASE DATA RE-USE (what data will remain re-usable and for how long, is embargo foreseen; how the data is licensed; data quality assurance procedures) Rich metadata and documentation will be provided for all data files. This can include: A codebook that will accompany the output of each experiment, which properly describes the content of the data files. A file containing the methodology of the experiment stored as .txt, .pdf, or .readme-files Annotated scripts/code for running the experiment and analysis if applicable. Data are analyzed using R, Matlab and/or Python, saved in their native formats (respectively, .R, .m and .py). Scripts formatting the text data files outputted by the manufacturer's software (EDF2ASC, dataviewer or Tobii Pro Lab) prior to formal analyses, are provided. Research output will be made available via RDR or OSF, at the moment of publication. Creative commons attribution licenses will be selected in RDR or OSF. To ensure qualitative data storage, XXXXXXXXXXXXXXXX will check the completeness of the documentation. 5. ALLOCATION OF RESOURCES and DATA SECURITY (estimated costs for making the project data open access and potential value of long-term data preservation; procedures for data backup and recovery; transfer of sensitive data and secure storage in repositories for long term preservation and curation) There are no costs attached to apply the FAIR-principles to the data and research outputs because repositories and other resources are provided by KU Leuven free of charge , including GitLab and RDR. Additionally, also the usage of OSF is free of charge. Individual researchers are responsible for data management during the course of their projects. The grant-holder will ensure the long-term storage of the data at KU Leuven."
}