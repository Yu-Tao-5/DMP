{
    "document_id": "D-2024-3069",
    "LinkTitle": "D-2024-3069",
    "file_name": "D-2024-3069.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2024-3069.pdf",
    "metadata": {
        "title": "IGNITE: Injecting Global iNformation In local opTimization mEthods",
        "author": "N/A",
        "num_pages": 6
    },
    "content": {
        "full_text": "Plan Overview\nPlan Overview\nA Data Management Plan created using DMPonline.be\nTitle: \nTitle: \nIGNITE: Injecting Global iNformation In local opTimization mEthods\nCreator:\nCreator:\nDominik Bongartz\nAffiliation: \nAffiliation: \nKU Leuven (KUL)\nTemplate: \nTemplate: \nKU Leuven BOF-IOF\nProject abstract:\nProject abstract:\nNonconvex optimization problems and in particular nonconvex nonlinear programs have countless applications in science and\nengineering, but remain challenging to solve due to suboptimal local optima. Common derivative-based (e.g., Newton-type) methods rely\nonly on local information and have no way to recognize whether a local optimum is global. Deterministic global optimization methods do\nutilize rigorous global information in the form of convex relaxations. However, the branch-and-bound algorithms these are used in often\nhave prohibitively long runtime. In this project, we aim to integrate the rigorous global information of convex relaxations into the\nstrategies that underlie derivative-based methods for unconstrained optimization. The goal is to construct methods that (a) still converge\nto local optima, while (b) having a higher chance to locate good – rather than just any – local optima, and (c) avoiding the long runtime of\nbranch-and-bound, but rather have runtimes comparable to existing derivative-based solvers.\nID: \nID: \n213265\nStart date: \nStart date: \n01-10-2024\nEnd date: \nEnd date: \n30-09-2028\nLast modified: \nLast modified: \n11-03-2025\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n1 of 6\nIGNITE: Injecting Global iNformation In local opTimization mEthods\nIGNITE: Injecting Global iNformation In local opTimization mEthods\nResearch Data Summary\nResearch Data Summary\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For\neach dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know\neach dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know\nwhat data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type\nwhat data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type\nof the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data.\nof the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data.\nDataset\nname / ID\nDescription\nNew or reuse\nDigital or\nPhysical data\nData Type\nFile\nformat\nData\nvolume\nPhysical\nvolume\n \n \nIndicate:\nN\nN\n(ew data)\nor \nE\nE\n(xisting\ndata) \nIndicate: \nD\nD\n(igital) or\nP\nP\n(hysical)\nIndicate:\nA\nA\nudiovisual\nI\nI\nmages\nS\nS\nound\nN\nN\numerical\nT\nT\nextual\nM\nM\nodel\nSO\nSO\nftware\nOther\n(specify)\n \nIndicate:\n<1GB\n<100GB\n<1TB\n<5TB\n>5TB\nNA\n \n1.\nTheoretical\nTesults\nDescription of developed optimization algorithms,\nconvergence proofs\nN\nD\nT\n.tex\n<1 GB\n \n2. Code\nImplementations of developed algorithms\nN\nD\nSO\n.cpp,\n.h, .py\n<1 GB\n \n3.\nBenchmark\nProblems\nOptimization problems on which the performance\nof the developed algorithms is tested\nN, E\nD\nM\n.txt,\n.py,\n.gms\n<1 GB\n \n4. Log Files\nSolver log files documenting the performance of\nthe implemented algorithms (ID 2) on the\nbenchmark problems (ID 3)\nN\nD\nN, T\n.log,\n.txt,\n.csv\n<100 GB\n \nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per\nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per\ndataset or data type:\ndataset or data type:\n3. Benchmark Problems: In addition to newly created problems and problems curated from the engineering literature during the\nproject, data from the following benchmark libraries will be used:\nMINLPLib: \nhttps://www.minlplib.org/download.html\nCOCONUT library: \nhttps://arnold-neumaier.at/glopt/coconut/Benchmark/Benchmark.html\nCUTEst: \nhttps://github.com/ralna/CUTEst\nFloudas, C.A., Pardalos, P.M., Adjiman, C., Esposito, W.R., Gümüs, Z.H., Harding, S.T., Klepeis, J.L., Meyer, C.A. and Schweiger,\nC.A., 2013. Handbook of Test Problems in Local and Global Optimization (Vol. 33). Springer Science & Business Media.\nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If\nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If\nso, refer to specific datasets or data types when appropriate and provide the relevant ethical approval number.\nso, refer to specific datasets or data types when appropriate and provide the relevant ethical approval number.\nNo\nWill you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven\nWill you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven\nor UZ Leuven privacy register number (G or S number).\nor UZ Leuven privacy register number (G or S number).\nNo\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n2 of 6\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)?\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)?\n If so, please comment per dataset or data type where appropriate. \n If so, please comment per dataset or data type where appropriate. \nYes\n2. Code: If the developed algorithms demonstrate good performance, there may be potential to develop them further into a\ncommercial software product, and/or provide consulting based on an open-source code.\nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer\nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer\nagreements, Research collaboration agreements)? If so, please explain in the comment section to what data they relate and what\nagreements, Research collaboration agreements)? If so, please explain in the comment section to what data they relate and what\nrestrictions are in place.\nrestrictions are in place.\nNo\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you\n(re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted.\n(re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted.\nNo\nDocumentation and Metadata\nDocumentation and Metadata\nClearly describe what approach will be followed to capture the accompanying information necessary to keep \nClearly describe what approach will be followed to capture the accompanying information necessary to keep \ndata\ndata\nunderstandable and usable\nunderstandable and usable\n, for yourself and others, now and in the future (e.g. in terms of documentation levels and types\n, for yourself and others, now and in the future (e.g. in terms of documentation levels and types\nrequired, procedures used, Electronic Lab Notebooks, README.txt files, codebook.tsv etc. where this information is recorded). \nrequired, procedures used, Electronic Lab Notebooks, README.txt files, codebook.tsv etc. where this information is recorded). \nTheoretical Results (Dataset 1) will be documented in the form of reports, thus ensuring understandability. These serve as basis\nfor structuring the remaining datasets. Algorithm variants will be given unique names / identifiers that will be used to label\ncorresponding implementations and results in the other datasets.\nCode (Dataset 2) will be developed within the Gitlab instance of KU Leuven. Documentation will be based on best practices for\n(C++) programming, including descriptive names for all objects, short comments in the code were necessary, and automatically\ngenerated html or pdf documentation using, e.g., Doxygen. Additional information about the algorithms and how to use them will\nbe included in a Readme.md as well as manual pages generated using Doxygen. These can be hosted via Gitlab pages to enable\nonline access. The documentation will make reference to the algorithm identifiers from Dataset 1.\nBenchmark Problems (Dataset 3) will be given unique identifiers that will be used to label corresponding results.\nLog Files (Dataset 4) will make reference to the unique algorithm identifiers from Dataset 1 and the unique problem identifiers\nfrom Dataset 3, to clarify which algorithm was used and which problem was solved, respectively.\n \nWill a metadata standard be used to make it easier to \nWill a metadata standard be used to make it easier to \nfind and reuse the data\nfind and reuse the data\n?  \n?  \nIf so, please specify which metadata standard will be used. \nIf so, please specify which metadata standard will be used. \nIf not, please specify which metadata will be created to make the data easier to find and reuse. \nIf not, please specify which metadata will be created to make the data easier to find and reuse. \nNo\nBenchmark Problems (Dataset 3) will be complemented with meta-data in Readme files detailing the data source, and problem\nstatistics (number of variables etc.).\nLog Files (Dataset 4) will be complemented with meta-data in Readme files detailing the algorithm and implementation version\nused, problem, and computer hardware used.\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n3 of 6\nData Storage & Back-up during the Research Project\nData Storage & Back-up during the Research Project\nWhere will the data be stored?\nWhere will the data be stored?\nOther (specify below)\nOneDrive (KU Leuven)\nCode: Gitlab instance of KU Leuven \nHow will the data be backed up?\nHow will the data be backed up?\nStandard back-up provided by KU Leuven ICTS for my storage solution\nIs there currently sufficient storage & backup capacity during the project? \nIs there currently sufficient storage & backup capacity during the project? \nIf no or insufficient storage or backup capacities are available, explain how this will be taken care of. \nIf no or insufficient storage or backup capacities are available, explain how this will be taken care of. \nYes\nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? \nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? \nThe OneDrive for Business environment offered by KU Leuven is access-controlled via multifactor authentication with the KU\nLeuven Authenticator app.\nThe same is applies for the GitLab instance of KU Leuven, as long as the project is set as private.\nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nOneDrive for Business and Gitlab are provided free of charge by KU Leuven.\nData Preservation after the end of the Research Project\nData Preservation after the end of the Research Project\nWhich data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of\nWhich data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of\nthe project? \nthe project? \nIn case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget\nIn case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget\nissues, institutional policies...).\nissues, institutional policies...).\nAll data will be preserved for 10 years according to KU Leuven RDM policy\nWhere will these data be archived (stored and curated for the long-term)? \nWhere will these data be archived (stored and curated for the long-term)? \nLarge Volume Storage (longterm for large volumes)\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n4 of 6\nKU Leuven RDR\nOther (specify below)\nAll research data will the archived on the large volume storage.\nBenchmark Problems may additionally be published via RDR to make them readily accessible to other developers of optimization\nalgorithms.\nCode will also remain available on the Gitlab instance of KU Leuven.\nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\nFor this project, required storage capacity of <1 TB is required, resulting in a cost of <100€ / year, which can be covered by the\ngrant and beyond.\nData Sharing and Reuse\nData Sharing and Reuse\nWill the data (or part of the data) be made available for reuse after/during the project?  \nWill the data (or part of the data) be made available for reuse after/during the project?  \nPlease explain per dataset or data type which data will be made available.\nPlease explain per dataset or data type which data will be made available.\nYes, as open data\nCode (Dataset 2) will be available via the Gitlab instance of KU Leuven.\nNew Benchmark Problems (Dataset 3) may be made available via RDR.\nIf access is restricted, please specify who will be able to access the data and under what conditions. \nIf access is restricted, please specify who will be able to access the data and under what conditions. \nNot applicable\nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party,\nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party,\nlegal restrictions)? \nlegal restrictions)? \nPlease explain per dataset or data type where appropriate.\nPlease explain per dataset or data type where appropriate.\nNo\nWhere will the data be made available?  \nWhere will the data be made available?  \nIf already known, please provide a repository per dataset or data type.\nIf already known, please provide a repository per dataset or data type.\nKU Leuven RDR (Research Data Repository)\nOther (specify below)\nKU Leuven GItlab instance, see above\nWhen will the data be made available? \nWhen will the data be made available? \nUpon publication of research results\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n5 of 6\nWhich data usage licenses are you going to provide? \nWhich data usage licenses are you going to provide? \nIf none, please explain why. \nIf none, please explain why. \nCC-BY 4.0 (data)\nMIT licence (code)\nDo you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please\nDo you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please\nprovide it here. \nprovide it here. \nNo\nWhat are the expected costs for data sharing? How will these costs be covered?  \nWhat are the expected costs for data sharing? How will these costs be covered?  \nNo costs are expected\nResponsibilities\nResponsibilities\nWho will manage data documentation and metadata during the research project? \nWho will manage data documentation and metadata during the research project? \nThe PhD student working on the project will be responsible for data documentation and metadata during the project under\nsupervision of the promoter (Dominik Bongartz).\nWho will manage data storage and backup during the research project? \nWho will manage data storage and backup during the research project? \nThe PhD student working on the project will manage data storage and backup during the project under supervision of the\npromoter (Dominik Bongartz).\nWho will manage data preservation and sharing? \nWho will manage data preservation and sharing? \nThe promoter (Dominik Bongartz) will manage data preservation and sharing, with support from the PhD student.\nWho will update and implement this DMP? \nWho will update and implement this DMP? \nThe promoter (Dominik Bongartz) will be responsible for updating and implementing this DMP, with support from the PhD\nstudent.\nCreated using DMPonline.be. Last modiﬁed 11 March 2025\n6 of 6"
    },
    "clean_full_text": "Plan Overview Plan Overview A Data Management Plan created using DMPonline.be Title: Title: IGNITE: Injecting Global iNformation In local opTimization mEthods Creator: Creator: Dominik Bongartz Affiliation: Affiliation: KU Leuven (KUL) Template: Template: KU Leuven BOF-IOF Project abstract: Project abstract: Nonconvex optimization problems and in particular nonconvex nonlinear programs have countless applications in science and engineering, but remain challenging to solve due to suboptimal local optima. Common derivative-based (e.g., Newton-type) methods rely only on local information and have no way to recognize whether a local optimum is global. Deterministic global optimization methods do utilize rigorous global information in the form of convex relaxations. However, the branch-and-bound algorithms these are used in often have prohibitively long runtime. In this project, we aim to integrate the rigorous global information of convex relaxations into the strategies that underlie derivative-based methods for unconstrained optimization. The goal is to construct methods that (a) still converge to local optima, while (b) having a higher chance to locate good – rather than just any – local optima, and (c) avoiding the long runtime of branch-and-bound, but rather have runtimes comparable to existing derivative-based solvers. ID: ID: 213265 Start date: Start date: 01-10-2024 End date: End date: 30-09-2028 Last modified: Last modified: 11-03-2025 Created using DMPonline.be. Last modiﬁed 11 March 2025 1 of 6 IGNITE: Injecting Global iNformation In local opTimization mEthods IGNITE: Injecting Global iNformation In local opTimization mEthods Research Data Summary Research Data Summary List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know each dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type what data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data. of the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data. Dataset name / ID Description New or reuse Digital or Physical data Data Type File format Data volume Physical volume Indicate: N N (ew data) or E E (xisting data) Indicate: D D (igital) or P P (hysical) Indicate: A A udiovisual I I mages S S ound N N umerical T T extual M M odel SO SO ftware Other (specify) Indicate: <1GB <100GB <1TB <5TB >5TB NA 1. Theoretical Tesults Description of developed optimization algorithms, convergence proofs N D T .tex <1 GB 2. Code Implementations of developed algorithms N D SO .cpp, .h, .py <1 GB 3. Benchmark Problems Optimization problems on which the performance of the developed algorithms is tested N, E D M .txt, .py, .gms <1 GB 4. Log Files Solver log files documenting the performance of the implemented algorithms (ID 2) on the benchmark problems (ID 3) N D N, T .log, .txt, .csv <100 GB If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data type: dataset or data type: 3. Benchmark Problems: In addition to newly created problems and problems curated from the engineering literature during the project, data from the following benchmark libraries will be used: MINLPLib: https://www.minlplib.org/download.html COCONUT library: https://arnold-neumaier.at/glopt/coconut/Benchmark/Benchmark.html CUTEst: https://github.com/ralna/CUTEst Floudas, C.A., Pardalos, P.M., Adjiman, C., Esposito, W.R., Gümüs, Z.H., Harding, S.T., Klepeis, J.L., Meyer, C.A. and Schweiger, C.A., 2013. Handbook of Test Problems in Local and Global Optimization (Vol. 33). Springer Science & Business Media. Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, refer to specific datasets or data types when appropriate and provide the relevant ethical approval number. so, refer to specific datasets or data types when appropriate and provide the relevant ethical approval number. No Will you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven Will you process personal data? If so, please refer to specific datasets or data types when appropriate and provide the KU Leuven or UZ Leuven privacy register number (G or S number). or UZ Leuven privacy register number (G or S number). No Created using DMPonline.be. Last modiﬁed 11 March 2025 2 of 6 Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so, please comment per dataset or data type where appropriate. If so, please comment per dataset or data type where appropriate. Yes 2. Code: If the developed algorithms demonstrate good performance, there may be potential to develop them further into a commercial software product, and/or provide consulting based on an open-source code. Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material or Data transfer agreements, Research collaboration agreements)? If so, please explain in the comment section to what data they relate and what agreements, Research collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place. restrictions are in place. No Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted. (re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted. No Documentation and Metadata Documentation and Metadata Clearly describe what approach will be followed to capture the accompanying information necessary to keep Clearly describe what approach will be followed to capture the accompanying information necessary to keep data data understandable and usable understandable and usable , for yourself and others, now and in the future (e.g. in terms of documentation levels and types , for yourself and others, now and in the future (e.g. in terms of documentation levels and types required, procedures used, Electronic Lab Notebooks, README.txt files, codebook.tsv etc. where this information is recorded). required, procedures used, Electronic Lab Notebooks, README.txt files, codebook.tsv etc. where this information is recorded). Theoretical Results (Dataset 1) will be documented in the form of reports, thus ensuring understandability. These serve as basis for structuring the remaining datasets. Algorithm variants will be given unique names / identifiers that will be used to label corresponding implementations and results in the other datasets. Code (Dataset 2) will be developed within the Gitlab instance of KU Leuven. Documentation will be based on best practices for (C++) programming, including descriptive names for all objects, short comments in the code were necessary, and automatically generated html or pdf documentation using, e.g., Doxygen. Additional information about the algorithms and how to use them will be included in a Readme.md as well as manual pages generated using Doxygen. These can be hosted via Gitlab pages to enable online access. The documentation will make reference to the algorithm identifiers from Dataset 1. Benchmark Problems (Dataset 3) will be given unique identifiers that will be used to label corresponding results. Log Files (Dataset 4) will make reference to the unique algorithm identifiers from Dataset 1 and the unique problem identifiers from Dataset 3, to clarify which algorithm was used and which problem was solved, respectively. Will a metadata standard be used to make it easier to Will a metadata standard be used to make it easier to find and reuse the data find and reuse the data ? ? If so, please specify which metadata standard will be used. If so, please specify which metadata standard will be used. If not, please specify which metadata will be created to make the data easier to find and reuse. If not, please specify which metadata will be created to make the data easier to find and reuse. No Benchmark Problems (Dataset 3) will be complemented with meta-data in Readme files detailing the data source, and problem statistics (number of variables etc.). Log Files (Dataset 4) will be complemented with meta-data in Readme files detailing the algorithm and implementation version used, problem, and computer hardware used. Created using DMPonline.be. Last modiﬁed 11 March 2025 3 of 6 Data Storage & Back-up during the Research Project Data Storage & Back-up during the Research Project Where will the data be stored? Where will the data be stored? Other (specify below) OneDrive (KU Leuven) Code: Gitlab instance of KU Leuven How will the data be backed up? How will the data be backed up? Standard back-up provided by KU Leuven ICTS for my storage solution Is there currently sufficient storage & backup capacity during the project? Is there currently sufficient storage & backup capacity during the project? If no or insufficient storage or backup capacities are available, explain how this will be taken care of. If no or insufficient storage or backup capacities are available, explain how this will be taken care of. Yes How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? The OneDrive for Business environment offered by KU Leuven is access-controlled via multifactor authentication with the KU Leuven Authenticator app. The same is applies for the GitLab instance of KU Leuven, as long as the project is set as private. What are the expected costs for data storage and backup during the research project? How will these costs be covered? What are the expected costs for data storage and backup during the research project? How will these costs be covered? OneDrive for Business and Gitlab are provided free of charge by KU Leuven. Data Preservation after the end of the Research Project Data Preservation after the end of the Research Project Which data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of Which data will be retained for 10 years (or longer, in agreement with other retention policies that are applicable) after the end of the project? the project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, institutional policies...). issues, institutional policies...). All data will be preserved for 10 years according to KU Leuven RDM policy Where will these data be archived (stored and curated for the long-term)? Where will these data be archived (stored and curated for the long-term)? Large Volume Storage (longterm for large volumes) Created using DMPonline.be. Last modiﬁed 11 March 2025 4 of 6 KU Leuven RDR Other (specify below) All research data will the archived on the large volume storage. Benchmark Problems may additionally be published via RDR to make them readily accessible to other developers of optimization algorithms. Code will also remain available on the Gitlab instance of KU Leuven. What are the expected costs for data preservation during the expected retention period? How will these costs be covered? What are the expected costs for data preservation during the expected retention period? How will these costs be covered? For this project, required storage capacity of <1 TB is required, resulting in a cost of <100€ / year, which can be covered by the grant and beyond. Data Sharing and Reuse Data Sharing and Reuse Will the data (or part of the data) be made available for reuse after/during the project? Will the data (or part of the data) be made available for reuse after/during the project? Please explain per dataset or data type which data will be made available. Please explain per dataset or data type which data will be made available. Yes, as open data Code (Dataset 2) will be available via the Gitlab instance of KU Leuven. New Benchmark Problems (Dataset 3) may be made available via RDR. If access is restricted, please specify who will be able to access the data and under what conditions. If access is restricted, please specify who will be able to access the data and under what conditions. Not applicable Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions)? legal restrictions)? Please explain per dataset or data type where appropriate. Please explain per dataset or data type where appropriate. No Where will the data be made available? Where will the data be made available? If already known, please provide a repository per dataset or data type. If already known, please provide a repository per dataset or data type. KU Leuven RDR (Research Data Repository) Other (specify below) KU Leuven GItlab instance, see above When will the data be made available? When will the data be made available? Upon publication of research results Created using DMPonline.be. Last modiﬁed 11 March 2025 5 of 6 Which data usage licenses are you going to provide? Which data usage licenses are you going to provide? If none, please explain why. If none, please explain why. CC-BY 4.0 (data) MIT licence (code) Do you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please Do you intend to add a persistent identifier (PID) to your dataset(s), e.g. a DOI or accession number? If already available, please provide it here. provide it here. No What are the expected costs for data sharing? How will these costs be covered? What are the expected costs for data sharing? How will these costs be covered? No costs are expected Responsibilities Responsibilities Who will manage data documentation and metadata during the research project? Who will manage data documentation and metadata during the research project? The PhD student working on the project will be responsible for data documentation and metadata during the project under supervision of the promoter (Dominik Bongartz). Who will manage data storage and backup during the research project? Who will manage data storage and backup during the research project? The PhD student working on the project will manage data storage and backup during the project under supervision of the promoter (Dominik Bongartz). Who will manage data preservation and sharing? Who will manage data preservation and sharing? The promoter (Dominik Bongartz) will manage data preservation and sharing, with support from the PhD student. Who will update and implement this DMP? Who will update and implement this DMP? The promoter (Dominik Bongartz) will be responsible for updating and implementing this DMP, with support from the PhD student. Created using DMPonline.be. Last modiﬁed 11 March 2025 6 of 6"
}