{
    "document_id": "D-2024-3199",
    "LinkTitle": "D-2024-3199",
    "file_name": "D-2024-3199.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2024-3199.pdf",
    "metadata": {
        "title": "IronHeart",
        "author": "N/A",
        "num_pages": 6
    },
    "content": {
        "full_text": "IronHeart\nIronHeart\nGDPR Record\nGDPR Record\nGDPR record\nGDPR record\nHave you registered personal data processing activities for this project?\nHave you registered personal data processing activities for this project?\nQuestion not answered.\nCreated using DMPonline.be. Last modiﬁed 23 October 2024\n1 of 6\nIronHeart\nIronHeart\nDPIA\nDPIA\nDPIA\nDPIA\nHave you performed a DPIA for the personal data processing activities for this project?\nQuestion not answered.\nCreated using DMPonline.be. Last modiﬁed 23 October 2024\n2 of 6\nIronHeart\nIronHeart\nERC DMP +\nERC DMP +\nProject information\nProject information\nProject Acronym\nProject Acronym\nIronHeart \nProject Number\nProject Number\n101125126 \nData summary\nData summary\nSummary\nSummary\n1. What types and formats of data will the project generate and re-use? \n1. What types and formats of data will the project generate and re-use? \n1.1. Compilation of existing datasets\n1.1. Compilation of existing datasets\n1.1.1. Will you re-use any existing data and how?\n1.1.1. Will you re-use any existing data and how?\nIronHeart researchers will use published data from peer-reviewed publications and books, from data repositories, archives and\ndatabases.\n1.1.2. What is the origin of the data?\n1.1.2. What is the origin of the data?\nSpecific examples of published datasets include:\nThe NASA MESSENGER online data volumes: \nhttps://pds-imaging.jpl.nasa.gov/volumes/mess.html\nThe ESA BepiColombo datasets (still embargoed but accessible to the PI who is a co-I of the MERTIS instrument:\nhttps://www.cosmos.esa.int/web/spice/spice-for-bepicolombo)\nPublished NASA geophysical databases related to planet Mercury: \nhttps://pgda.gsfc.nasa.gov/products/83\nCompiled databases of experimental products related to Mercury: \nhttps://doi.org/10.1038/ngeo2860\n,\nhttps://doi.org/10.1016/j.epsl.2014.01.004\n, \nhttps://doi.org/10.1016/j.epsl.2016.01.030 (only a few key examples are\nprovided here)\nResults of numerical simulations on the thermal evolution of Mercury:  \nhttps://doi.org/10.1002/jgre.20168\n,\nhttps://doi.org/10.1002/2015GL065314, \nhttps://doi.org/10.1016/j.epsl.2017.11.006\n (only a few key examples are provided\nhere)\n1.2 Datasets produced in IronHeart\n1.2 Datasets produced in IronHeart\nNew data produced in this project will be of several types. We believe that the collected research data will be divided in 5 main\ndatasets\n[Dataset 1] Experiments will be produced at high-temperature and high-pressure in furnaces and presses.\nExperiments will produce textural data obtained by electron microscopy (SEM): crystal proportion vs glass proportion,\ncrystal sizes and crystal textures\nExperiments will produce chemical data obtained by electron microscopy (SEM), electron probe micro-analyzer (EPMA)\nand LA-ICP-MS. Softwares to be used will be Astec (SEM), JEOL (EPMA), Iolite (LA-ICP-MS).\nExperimental data will be combined to produce databases of element partitioning between crystals and melt and\nbetween various types of melt (silicate melt, metal melt, sulfide melt)\n[Dataset 2] Geophysical models will produce datasets containing calculated physical properties of Mercury's and proto-\nMercury's interior (temperature gradient, gravity, pressure) and bulk physical properties (moment of inertia, Love numbers).\n[Dataset 3] Numerical models of planet collisions and formation of planet Mercury\n[Dataset 4] Thermal models will produce datasets containing calculated thermal paths for Mercury: thermal evolution of the\nplanet's core and mantle as a function of time from 4.5 Gyr to now.\n[Dataset 5] Combination of geophysical and thermal models will produce new publicly-available codes of interior modeling\nand thermal modeling.\n[Dataset 6] We will produce list of key targets for measurements (chemistry and mineralogy) by spectroscopic instruments\nof the ESA BepiColombo spacecraft (MIXS and MERTIS).\n1.3. What is the purpose of the data generation and its relation to the objectives of the project:\n1.3. What is the purpose of the data generation and its relation to the objectives of the project:\nThe project will generate various types of data (experimental, images, numerical datasets) and research outputs (scripts, models)\nCreated using DMPonline.be. Last modiﬁed 23 October 2024\n3 of 6\nrelated to the formation of planet Mercury. The data serve as a foundation to build models of planet evolution.\n[Dataset 1] Experiments will be produced to determine the mineralogy of Mercury's and proto-Mercury's mantle and core.\nExperiments will also allow estimating the conditions of mantle melting and crust formation. The compositions of the melts\nproduced in these experiments will be compared to surface measurements by MESSENGER and BepiColombo. \n[Dataset 2] Geophysical models will be produced to determine what can be the internal structure of Mercury (mantle, core\nand crust sizes and compositions).\n[Dataset 3] Numerical models of planet collisions will be used to determine the conditions under which Mercury with its large\nmetal core can be formed by one or several (giant) impacts. They will also be used to estimate their relative effect on mantle\nand core sizes and bulk compositions.\n[Dataset 4] Models will be constructed to calculate thermal evolution of paths of Mercury. Based on those realistic estimates\nof bulk planet contraction will be obtained and compared with high-resolution images obtained by MESSENGER and that will\nbe obtained by BepiColombo.\n[Dataset 5] We will produce user-friendly codes of thermal and structural evolution that will be used to test the structure of\nthe planet. Input data in these codes will be the experimental results [Dataset 1] and geophysical data from MESSENGER and\nBepiColombo.\n[Dataset 6] Targets that we will propose for BepiColombo will insure that relevant chemical and mineralogical compositions\nof Mercury's crust are available for IronHeart. \n1.4. What types and formats of data will the project generate/collect?\n1.4. What types and formats of data will the project generate/collect?\n  All data generated as part of this project will be generated in various types of formats:\n[Laboratory; Dataset 1] - Written lab notes and books; compositions of powders for experiments, experimental conditions\n(pressure, temperature, gas flux)\n[Raw data; Datasets 2, 3, 4] - Txt, csv, xlsx files with raw data: Log of experiments (temperature and pressure vs time), raw\nchemical analyses of minerals and melt. \n[Calculations; Datasets 2, 3, 4] - Txt, csv, xlsx files with calculated data. Calculated chemical data (i.e. corrected for\ninstrument drift), geophysical structure of Mercury, thermal evolution of Mercury, numerical results of collision simulations. \n[Figures; Datasets 1, 2, 3, 4] - pdf, jpeg, tiff figures with the results of the calculations will be produced. In addition, Jpeg\nimages of each experiment characterized by backscattered electron imaging and X-ray chemistry will be obtained.\nGIS data [Dataset 6] - Coordinates (longitude, latitude) and description of targets (topography, MESSENGER chemical data,\nresolution, relevance (scientific interest) of the proposed target).\nPy (python) scripts [Dataset 5] - All codes for calculations (chemistry, collisions, thermal evolution, interior structure) will be\ndeveloped in python and will be made publicly available.  \n1.5. What is the expected size of the data?\n1.5. What is the expected size of the data?\n[Laboratory; Dataset 1] - This will be physical storage - each experimental facility has its own lab book\n[Raw data; Datasets 2, 3, 4, 6] - Txt, csv, xlsx, GIS files with raw data: Each file will be a few kb. The total size of [Raw data] is\nexpected to be a few gb. \n[Calculations; Datasets 2, 3, 4] - Txt, csv, xlsx files with calculated data. Calculated chemical data (i.e. corrected for\ninstrument drift), geophysical structure of Mercury, thermal evolution of Mercury, numerical results of collision simulations.\nEach file will be a few kb. The total size of [Raw data] is expected to be a few gb.\n[Figures; Datasets 1, 2, 3, 4] - pdf, jpeg, tiff figures with the results of the calculations will be produced. In addition, Jpeg\nimages of each experiment characterized by backscattered electron imaging and X-ray chemistry will be obtained. Individual\nfiles can range from a few kb to a few gb depending on the amount of calculations or size of microscopy images. \nPy (python) scripts [Dataset 5] - All codes for calculations (chemistry, collisions, thermal evolution, interior structure) will be\ndeveloped in python and will be made publicly available. Py script will be of small size, a few kb each.  \nThe overall size of the data generated in IronHeart is estimated to be up to 100 gb. \n \n1.6. To whom might these datasets be useful (‘data utility’)?\n1.6. To whom might these datasets be useful (‘data utility’)?\nData generated in IronHeart will be useful for researchers, teachers as well as policy makers and governments making decisions\nabout space exploration. Examples:\nEurope and USA are thinking about new missions on Mercury. Data generated in IronHeart will help thinking about scientific\nmeasurements that are currently lacking or relevant sites for a lander.\nSeveral countries develop space telescopes partly to explore exoplanets. The results generated in IronHeart will be critical to\nunderstand the origin and evolution of a category of exoplanets called super-Mercuries.\nExperimental data generated in IronHeart as well as geophysical data will be useful for researchers (and teachers) in\nplanetary sciences.\nFAIR data\nFAIR data\nCreated using DMPonline.be. Last modiﬁed 23 October 2024\n4 of 6\n1. Making data findable\n1. Making data findable\n1.1. Will data be identified by a persistent identifier? \n1.1. Will data be identified by a persistent identifier? \nSince all data will be deposited in data repositories include, e.g. the Research Data Repository (RDR) of KUL\n(https://www.kuleuven.be/rdm/en/rdr), they will receive a DOI in that data repository. \nBoth the raw data obtained from the experiments and techniques used, as well as the processed data will be stored together (in\nsubfolders) in one (parent) folder, \nFor all data that will be catalogued in the repository, metadata will be completed. This will make the data easier to find and re-use.\nMetadata that will be completed (at a minimum) will include: \nDigital Object Identifiers \nVersion numbers\nBibliographic information\nKeywords\nAbstract/description\nAssociated project and community\nAssociated publications and reports\nGrant information\nAccess and licensing info\nLanguage \nDOI numbers will be used for (final) datasets that have been deposited in a repository. \nWhen publications and data are uploaded to the repository, the data owners will enter keywords to describe the publication/data,\nin order to facilitate the search. A set of relevant keywords will be developed in the course of the project, for data owners to\nchoose from. These will be included in an update of the DMP. \n1.2. Will search keywords be provided in the metadata to optimize the possibility for discovery and then potential re-use? \n1.2. Will search keywords be provided in the metadata to optimize the possibility for discovery and then potential re-use? \nKeywords will be added in the metadata to optimize the findability and potential for re-use.\nMoreover, RDR repository will generate discovery metadata that can be harvested and indexed. \n2. Making data openly accessible\n2. Making data openly accessible\n2.1 Will the data be deposited in a trusted repository? \n2.1 Will the data be deposited in a trusted repository? \nIronHeart project's data will be deposited in RDR of KU Leuven. Zenodo or other general repositories might be used as well. The\ndata is assigned an identifier (DOI). The repository will resolve the identifier to a digital object. The data will remain available (by\ndefault) for 20 years via RDR. Metadata will be available while data is available. \nThe code used to generate the data will be made available in KU Leuven GitLab, or other similar code repositories. Methods and\nsoftware tools needed to access the data will be indicated on a case by case basis. \n2.2. Will all data be made openly available? \n2.2. Will all data be made openly available? \nBy default, datasets will not be shared before publishing the research results. \nIn case of publishable research results, datasets will be made available by default (subject to internal decision if dataset sharing\nis not allowed; in some cases, restricted access to data can be allowed, on a by-request basis). Restrictions (if applicable) will be\nmanaged through the aforementioned repositories. For restricted data (if applicable), the identity of the person(s) accessing the\ndata will be ascertained through the access request procedure. \n3. Making data interoperable\n3. Making data interoperable\nWhenever possible, the datafiles will be converted to standardised or open data formats to facilitate long-term usability (e.g., .csv\ninstead of .xlsx). \nUsage of community standards for data and metadata, and controlled vocabularies or ontologies, will allow (meta)data to be\ncombined and exchanged.  \n4. Increase data re-use\n4. Increase data re-use\nWhen sharing the datasets, IronHeart researchers will make sure to provide sufficient documentation for others to understand\nand re-use the data. A detailed document, with the procedures followed for experimental validation and analysis, will be provided\nto act as guide for external evaluation and also to facilitate data re-usage. \nCreated using DMPonline.be. Last modiﬁed 23 October 2024\n5 of 6\nThe project coordinator will take measures to ensure the data is widely available and reusable for third parties. The content of the\ndataset will be clearly described, together with the origin of the data including methodology/procedures for data collection and\nanalysis, the software used, the definitions of variables, the purpose for which the data was collected and quality control\nprocedures that have been used. This will be given in the file, for example when using explanatory lines in code, or in a separate\nfile, such as a readme (.txt) file, a codebook, a list of interview questionnaires, protocols etc. Data and code will be documented\nwith metadata files, e.g. ReadMe files. The primary focus of the data sharing is on validation of the results reported in\npublications. After the project concludes, all data requests will be considered and, when possible, approved. Permission for data\nuse will be granted as long as there are no intellectual property rights (IPR) or confidentiality concerns, and no direct overlap with\nthe primary research. \nIronHeart's PI is aware of the challenges regarding data quality and consistency. As such, early in the project a coding system for\nthe materials samples will be implemented, and protocols are being used for experiments. Repeated measurements and\nexperiments are foreseen (e.g., for sample analysis), including analysis different laboratories. \nIf access to the (raw) data is restricted, then the documentation will be shared openly, if possible. \n5. Allocation of resources and data security\n5. Allocation of resources and data security\nThe overall responsibility for data management lies with the project coordinator who will ensure that data is widely available and\nreusable. \nKU Leuven - Olivier Namur - PI of IronHeart - DM responsible for KU Leuven\nIronHeart data will be preserved, by default, for 20 years. \nThe project coordinator (KU Leuven) provides a virtual drive for the project data (OneDrive for Business). The storage is shared\nhierarchically at WP level. This is the main procedure for backup and recovery. OneDrive is already implemented at KU Leuven so\ncosts for data storage and access should be minimal. \n \nCreated using DMPonline.be. Last modiﬁed 23 October 2024\n6 of 6"
    },
    "clean_full_text": "IronHeart IronHeart GDPR Record GDPR Record GDPR record GDPR record Have you registered personal data processing activities for this project? Have you registered personal data processing activities for this project? Question not answered. Created using DMPonline.be. Last modiﬁed 23 October 2024 1 of 6 IronHeart IronHeart DPIA DPIA DPIA DPIA Have you performed a DPIA for the personal data processing activities for this project? Question not answered. Created using DMPonline.be. Last modiﬁed 23 October 2024 2 of 6 IronHeart IronHeart ERC DMP + ERC DMP + Project information Project information Project Acronym Project Acronym IronHeart Project Number Project Number 101125126 Data summary Data summary Summary Summary 1. What types and formats of data will the project generate and re-use? 1. What types and formats of data will the project generate and re-use? 1.1. Compilation of existing datasets 1.1. Compilation of existing datasets 1.1.1. Will you re-use any existing data and how? 1.1.1. Will you re-use any existing data and how? IronHeart researchers will use published data from peer-reviewed publications and books, from data repositories, archives and databases. 1.1.2. What is the origin of the data? 1.1.2. What is the origin of the data? Specific examples of published datasets include: The NASA MESSENGER online data volumes: https://pds-imaging.jpl.nasa.gov/volumes/mess.html The ESA BepiColombo datasets (still embargoed but accessible to the PI who is a co-I of the MERTIS instrument: https://www.cosmos.esa.int/web/spice/spice-for-bepicolombo) Published NASA geophysical databases related to planet Mercury: https://pgda.gsfc.nasa.gov/products/83 Compiled databases of experimental products related to Mercury: https://doi.org/10.1038/ngeo2860 , https://doi.org/10.1016/j.epsl.2014.01.004 , https://doi.org/10.1016/j.epsl.2016.01.030 (only a few key examples are provided here) Results of numerical simulations on the thermal evolution of Mercury: https://doi.org/10.1002/jgre.20168 , https://doi.org/10.1002/2015GL065314, https://doi.org/10.1016/j.epsl.2017.11.006 (only a few key examples are provided here) 1.2 Datasets produced in IronHeart 1.2 Datasets produced in IronHeart New data produced in this project will be of several types. We believe that the collected research data will be divided in 5 main datasets [Dataset 1] Experiments will be produced at high-temperature and high-pressure in furnaces and presses. Experiments will produce textural data obtained by electron microscopy (SEM): crystal proportion vs glass proportion, crystal sizes and crystal textures Experiments will produce chemical data obtained by electron microscopy (SEM), electron probe micro-analyzer (EPMA) and LA-ICP-MS. Softwares to be used will be Astec (SEM), JEOL (EPMA), Iolite (LA-ICP-MS). Experimental data will be combined to produce databases of element partitioning between crystals and melt and between various types of melt (silicate melt, metal melt, sulfide melt) [Dataset 2] Geophysical models will produce datasets containing calculated physical properties of Mercury's and proto- Mercury's interior (temperature gradient, gravity, pressure) and bulk physical properties (moment of inertia, Love numbers). [Dataset 3] Numerical models of planet collisions and formation of planet Mercury [Dataset 4] Thermal models will produce datasets containing calculated thermal paths for Mercury: thermal evolution of the planet's core and mantle as a function of time from 4.5 Gyr to now. [Dataset 5] Combination of geophysical and thermal models will produce new publicly-available codes of interior modeling and thermal modeling. [Dataset 6] We will produce list of key targets for measurements (chemistry and mineralogy) by spectroscopic instruments of the ESA BepiColombo spacecraft (MIXS and MERTIS). 1.3. What is the purpose of the data generation and its relation to the objectives of the project: 1.3. What is the purpose of the data generation and its relation to the objectives of the project: The project will generate various types of data (experimental, images, numerical datasets) and research outputs (scripts, models) Created using DMPonline.be. Last modiﬁed 23 October 2024 3 of 6 related to the formation of planet Mercury. The data serve as a foundation to build models of planet evolution. [Dataset 1] Experiments will be produced to determine the mineralogy of Mercury's and proto-Mercury's mantle and core. Experiments will also allow estimating the conditions of mantle melting and crust formation. The compositions of the melts produced in these experiments will be compared to surface measurements by MESSENGER and BepiColombo. [Dataset 2] Geophysical models will be produced to determine what can be the internal structure of Mercury (mantle, core and crust sizes and compositions). [Dataset 3] Numerical models of planet collisions will be used to determine the conditions under which Mercury with its large metal core can be formed by one or several (giant) impacts. They will also be used to estimate their relative effect on mantle and core sizes and bulk compositions. [Dataset 4] Models will be constructed to calculate thermal evolution of paths of Mercury. Based on those realistic estimates of bulk planet contraction will be obtained and compared with high-resolution images obtained by MESSENGER and that will be obtained by BepiColombo. [Dataset 5] We will produce user-friendly codes of thermal and structural evolution that will be used to test the structure of the planet. Input data in these codes will be the experimental results [Dataset 1] and geophysical data from MESSENGER and BepiColombo. [Dataset 6] Targets that we will propose for BepiColombo will insure that relevant chemical and mineralogical compositions of Mercury's crust are available for IronHeart. 1.4. What types and formats of data will the project generate/collect? 1.4. What types and formats of data will the project generate/collect? All data generated as part of this project will be generated in various types of formats: [Laboratory; Dataset 1] - Written lab notes and books; compositions of powders for experiments, experimental conditions (pressure, temperature, gas flux) [Raw data; Datasets 2, 3, 4] - Txt, csv, xlsx files with raw data: Log of experiments (temperature and pressure vs time), raw chemical analyses of minerals and melt. [Calculations; Datasets 2, 3, 4] - Txt, csv, xlsx files with calculated data. Calculated chemical data (i.e. corrected for instrument drift), geophysical structure of Mercury, thermal evolution of Mercury, numerical results of collision simulations. [Figures; Datasets 1, 2, 3, 4] - pdf, jpeg, tiff figures with the results of the calculations will be produced. In addition, Jpeg images of each experiment characterized by backscattered electron imaging and X-ray chemistry will be obtained. GIS data [Dataset 6] - Coordinates (longitude, latitude) and description of targets (topography, MESSENGER chemical data, resolution, relevance (scientific interest) of the proposed target). Py (python) scripts [Dataset 5] - All codes for calculations (chemistry, collisions, thermal evolution, interior structure) will be developed in python and will be made publicly available. 1.5. What is the expected size of the data? 1.5. What is the expected size of the data? [Laboratory; Dataset 1] - This will be physical storage - each experimental facility has its own lab book [Raw data; Datasets 2, 3, 4, 6] - Txt, csv, xlsx, GIS files with raw data: Each file will be a few kb. The total size of [Raw data] is expected to be a few gb. [Calculations; Datasets 2, 3, 4] - Txt, csv, xlsx files with calculated data. Calculated chemical data (i.e. corrected for instrument drift), geophysical structure of Mercury, thermal evolution of Mercury, numerical results of collision simulations. Each file will be a few kb. The total size of [Raw data] is expected to be a few gb. [Figures; Datasets 1, 2, 3, 4] - pdf, jpeg, tiff figures with the results of the calculations will be produced. In addition, Jpeg images of each experiment characterized by backscattered electron imaging and X-ray chemistry will be obtained. Individual files can range from a few kb to a few gb depending on the amount of calculations or size of microscopy images. Py (python) scripts [Dataset 5] - All codes for calculations (chemistry, collisions, thermal evolution, interior structure) will be developed in python and will be made publicly available. Py script will be of small size, a few kb each. The overall size of the data generated in IronHeart is estimated to be up to 100 gb. 1.6. To whom might these datasets be useful (‘data utility’)? 1.6. To whom might these datasets be useful (‘data utility’)? Data generated in IronHeart will be useful for researchers, teachers as well as policy makers and governments making decisions about space exploration. Examples: Europe and USA are thinking about new missions on Mercury. Data generated in IronHeart will help thinking about scientific measurements that are currently lacking or relevant sites for a lander. Several countries develop space telescopes partly to explore exoplanets. The results generated in IronHeart will be critical to understand the origin and evolution of a category of exoplanets called super-Mercuries. Experimental data generated in IronHeart as well as geophysical data will be useful for researchers (and teachers) in planetary sciences. FAIR data FAIR data Created using DMPonline.be. Last modiﬁed 23 October 2024 4 of 6 1. Making data findable 1. Making data findable 1.1. Will data be identified by a persistent identifier? 1.1. Will data be identified by a persistent identifier? Since all data will be deposited in data repositories include, e.g. the Research Data Repository (RDR) of KUL (https://www.kuleuven.be/rdm/en/rdr), they will receive a DOI in that data repository. Both the raw data obtained from the experiments and techniques used, as well as the processed data will be stored together (in subfolders) in one (parent) folder, For all data that will be catalogued in the repository, metadata will be completed. This will make the data easier to find and re-use. Metadata that will be completed (at a minimum) will include: Digital Object Identifiers Version numbers Bibliographic information Keywords Abstract/description Associated project and community Associated publications and reports Grant information Access and licensing info Language DOI numbers will be used for (final) datasets that have been deposited in a repository. When publications and data are uploaded to the repository, the data owners will enter keywords to describe the publication/data, in order to facilitate the search. A set of relevant keywords will be developed in the course of the project, for data owners to choose from. These will be included in an update of the DMP. 1.2. Will search keywords be provided in the metadata to optimize the possibility for discovery and then potential re-use? 1.2. Will search keywords be provided in the metadata to optimize the possibility for discovery and then potential re-use? Keywords will be added in the metadata to optimize the findability and potential for re-use. Moreover, RDR repository will generate discovery metadata that can be harvested and indexed. 2. Making data openly accessible 2. Making data openly accessible 2.1 Will the data be deposited in a trusted repository? 2.1 Will the data be deposited in a trusted repository? IronHeart project's data will be deposited in RDR of KU Leuven. Zenodo or other general repositories might be used as well. The data is assigned an identifier (DOI). The repository will resolve the identifier to a digital object. The data will remain available (by default) for 20 years via RDR. Metadata will be available while data is available. The code used to generate the data will be made available in KU Leuven GitLab, or other similar code repositories. Methods and software tools needed to access the data will be indicated on a case by case basis. 2.2. Will all data be made openly available? 2.2. Will all data be made openly available? By default, datasets will not be shared before publishing the research results. In case of publishable research results, datasets will be made available by default (subject to internal decision if dataset sharing is not allowed; in some cases, restricted access to data can be allowed, on a by-request basis). Restrictions (if applicable) will be managed through the aforementioned repositories. For restricted data (if applicable), the identity of the person(s) accessing the data will be ascertained through the access request procedure. 3. Making data interoperable 3. Making data interoperable Whenever possible, the datafiles will be converted to standardised or open data formats to facilitate long-term usability (e.g., .csv instead of .xlsx). Usage of community standards for data and metadata, and controlled vocabularies or ontologies, will allow (meta)data to be combined and exchanged. 4. Increase data re-use 4. Increase data re-use When sharing the datasets, IronHeart researchers will make sure to provide sufficient documentation for others to understand and re-use the data. A detailed document, with the procedures followed for experimental validation and analysis, will be provided to act as guide for external evaluation and also to facilitate data re-usage. Created using DMPonline.be. Last modiﬁed 23 October 2024 5 of 6 The project coordinator will take measures to ensure the data is widely available and reusable for third parties. The content of the dataset will be clearly described, together with the origin of the data including methodology/procedures for data collection and analysis, the software used, the definitions of variables, the purpose for which the data was collected and quality control procedures that have been used. This will be given in the file, for example when using explanatory lines in code, or in a separate file, such as a readme (.txt) file, a codebook, a list of interview questionnaires, protocols etc. Data and code will be documented with metadata files, e.g. ReadMe files. The primary focus of the data sharing is on validation of the results reported in publications. After the project concludes, all data requests will be considered and, when possible, approved. Permission for data use will be granted as long as there are no intellectual property rights (IPR) or confidentiality concerns, and no direct overlap with the primary research. IronHeart's PI is aware of the challenges regarding data quality and consistency. As such, early in the project a coding system for the materials samples will be implemented, and protocols are being used for experiments. Repeated measurements and experiments are foreseen (e.g., for sample analysis), including analysis different laboratories. If access to the (raw) data is restricted, then the documentation will be shared openly, if possible. 5. Allocation of resources and data security 5. Allocation of resources and data security The overall responsibility for data management lies with the project coordinator who will ensure that data is widely available and reusable. KU Leuven - Olivier Namur - PI of IronHeart - DM responsible for KU Leuven IronHeart data will be preserved, by default, for 20 years. The project coordinator (KU Leuven) provides a virtual drive for the project data (OneDrive for Business). The storage is shared hierarchically at WP level. This is the main procedure for backup and recovery. OneDrive is already implemented at KU Leuven so costs for data storage and access should be minimal. Created using DMPonline.be. Last modiﬁed 23 October 2024 6 of 6"
}