{
    "document_id": "D-2021-1328",
    "LinkTitle": "D-2021-1328",
    "file_name": "D-2021-1328.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2021-1328.pdf",
    "metadata": {
        "title": "D-2021-1328",
        "author": "Marion MAETENS",
        "num_pages": 8
    },
    "content": {
        "full_text": "1297322N  DMP  V1.0 \n1  \nDMP in the context of FWO Postdoctoral Fellow – senior  LIQUIDEVO: Unravelling breast cancer \nheterogeneity,  progression and treatment resistance in the context of a rapid  post -mortem institutional  \ntissue donation program using  phylogenetic reconstruction algorithms and an Open Science  approach.  \nProject Name: DMP LIQUIDEVO  \nPrincipal Investigator / Researcher: Christine Desmedt  \nInstitution: KU Leuven  \n \n1. GENERAL INFORMATION  \nName of the project lead (PI)  \nDMP LIQUIDEVO  \nFrançois Richard  \n \nInternal Funds Project number & title  \n1297322N LIQUIDEVO: Unravelling breast cancer heterogeneity,  progression and treatment resistance in  \nthe context of a rapid  post-mortem institutional tissue donation program using  phylogenetic reconstruction  \nalgorithms and an Open Science  approach.  \n \n2. DATA DESCRIPTION  \n2.1. Will you generate/collect new data and/or make use of existing data?  \n \nWe will generate and collect new data (prospective data and samples collection and make use of existing \ndata (retrospective data and samples collection ). \n \nThe project will collect pseudonymized clinical data collected after the patient consented to the study. \nClinical, histopathological and treatment data will be entered in the eCRF that we have designed in REDcap . \nAlso sample metadata (SPREC based) will be collected in LabCollector, a database that we have \ncustomized for the needs of LIQUIDEVO . \n \nOur research will generate:  \n- Genomic data: sequencing data (.fastqc and bam files) ; \n- Scripts (R, bash) to analyse the data; \n- A web platform allowing browsing in the results ; \n- Code Ocean capsules and framagit  pages to reproduce and access the code, respectively ; \n- Manuscripts and publications.  \n \n1297322N  DMP  V1.0 \n2 In terms of data storage, data will be stored on UZ Leuven drives (eCRF) and KU Leuven drives (all other \ndata) in a GDPR compliant manner and with regular backups provided by the IT services for at least 10 \nyears after the end of  LIQUIDEVO . \n  \nWith regard t o manuscript publication: in line  with GDPR and KU Leuven Open Science policy, no personnel \ndata will be made publicly available through public repositories such as GitHub and Code Ocean. A version \nof the manuscript will be uploaded to Lirias. Personal dat a (e.g. raw sequencing data) will be deposited on \npublic repositories such as the EGA, under restricted access.  \n \n2.2. What data will you collect, generate or reuse? Describe the origin, type and format of the data \n(per dataset) and its (estimated) volume. This may be easiest in a numbered list or table and per \nobjective of the project . \n \nWork \npackage  Data type  N° of \ncases  Data Source  Data content  Data \nFormat  Volume  \n(Go) \nWP1  Primary and \nsecondary use, \nclinical and sample \ndata collection  15  Patient file  Demographic, \npathological, \nclinical, \ntreatment, \noutcome data \nand blood \nresults ; \nSamples data  eCRF \n(RedCap), \nR files, \nLab \ncollector, \nExcel files   0.5 \nWP2  Primary use, WGS  125 HiSeq 4000  genomics \ndata fastq and \n.bam files   3750  \nWP4 Primary use, TGS  270 HiSeq 4000  genomics \ndata fastq and \n.bam files   405 \nWP6 Primary use; \nwebsite source \ncode  1 LTBCR - \nbioinformatics  R code  R and text \nfiles 1 \n \n \n \n \n1297322N  DMP  V1.0 \n3 3. ETHICAL AND LEGAL ISSUES  \n3.1. Will you use personal data? If so, shortly describe the kind of personal data you will use. Add \nthe reference to the file in KU Leuven's Record of Processing Activities. Be aware that registering \nthe fact that you process personal data is a legal obligation.  \n \nYes, we will use personal data. Data, irrespective of the WPs, includ e demographic (age, gender),  \npathological, clinical, treatment and outcome data as well as sequencing data  on tissue and liq uid samples \nincluding whole genome as well as targeted genome sequencing.  \n \nPlease note, GDPR does not apply to deceased patients.  \n \nThe compliance monitoring form is the following: E-2021 -2462 . \n \n3.2. Are there any ethical issues concerning the creation and/or use of the data (e.g.  experiments \non humans or animals, dual use)? If so, add the reference to the formal approval by the relevant \nethical review committee(s).  \n \nLIQUIDEVO is part of t he UPTIDER project which was approved by the EC UZ/KU Leuven: S64410.  \n \n3.3. Does your research  possibly result in research data with potential for tech transfer and \nvalorisation? Will IP restrictions be claimed for the data you created? If so, for what data and \nwhich restrictions will be asserted?  \n \nThere is potential tech transfer/valorization in t he putative assays/biomarkers we measure or we aim to \ndiscover. We are working with the Leuven Research and Development department (LRD) and the legal \nadvisors from UZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer \nAgre ements (MTA/DTAs) we have set -up in the context of this project.  \n \n3.4. Do existing 3rd party agreements restrict dissemination or exploitation of the data you \n(re)use? If so, to what data do they relate and what restrictions regarding reuse and sharing are  in \nplace?  \n \nWe are working with the Leuven Research and Development department (LRD) and the legal advisors from \nUZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer Agreements \n(MTA/DTAs) we have set -up in the context of t his project.  There is no specific data restriction.  \n \n4. DOCUMENTATION AND METADATA  \n4.1. What documentation will be provided to enable understanding and reuse of the data \ncollected/generated in this project ? \n \n1297322N  DMP  V1.0 \n4 All collected clinical data are stored  in an eCRF (REDCap)  in which the documentation is automatically \nprovided th rough the auto generated dictionary and code book where all the requested data are described. \nAll collected data belonging to the sample collection are stored in an online lab managem ent system called \nLab Collector  based on SPREC requirements where all the requested data are described.  \n \nThe lab-specific generic data management plan  will guide researchers through data collection and \nprocessing workflows, ensuring efficient safe storage,  keeping track of data use and associated processing \nrelated to each experimental step, and enabling data query filtering of the collected data.  \n \nRegarding omics data, bioinformatics pipeline are shared on a common git repository and heavily described \nso that they can be reproduced. When possible docker -like structure container will be used to easily share \nand perform bioinformatics pipeline. This container allows to enclose code and software so that they can \nbe reused with the exact same versions and param eters . \n \nThird -party software and algorithms that are used are referenced by their version numbers in our method \nsection and are installed as modules on the VSC and/or containers (Docker, Singularity) on the VSC, to \nensure reproducibility . \n \nAt the publication level, a companion code capsule hosted by code ocean will be build. It will allow \nreproducing the figures of the paper, browsing code and raw data. In case of restricted access on the data, \na synthetic dataset mimic king the characteristic of  the real data will be made available instead (see section \n7.2). \n \n \n4.2. Will a metadata standard be used? If so, describe in detail which standard will be used. If not, \nstate in detail which metadata will be created to make the data easy/easier to find and  reuse.  \n \nMetadata will follow Data Cite’s recommendations  (Fenner et al., 2019) . \n \n5. DATA STORAGE AND BACKUP DURING THE PROJECT  \n5.1. Where will the data be stored?  \n \nThe minimum preservation term of 10 years after the end of the project will be applied to all datasets.  \nBiological samples obtained under research agreement will be kept according to the EC licenses and \nagreements. In effect, consent is obtained to store the samples for the specific research purposes stipulated \nin the informed consent. Putative remnant clin ical/patient samples are stored in the UZ Leuven biobank.  \nHard copies (eg. the Informed Consent forms  and paper lab notebooks) are kept in locked cabinets in the \nlab of the PI concerned.  \n \nThe data will be stored on the KU Leuven servers. All systems but La b Collector run on a secured and \nbacked up server of KULeuven (managed by ICT of the Biomedical Sciences Group). These systems also \n1297322N  DMP  V1.0 \n5 provide a logging system so no data can ever be erased, making that everything will be traceable and \nstored long -term (well beyond the common 5 -year requirement). Lab Collector data base is externally and \nprofessionally managed by the company “AgileBio”.  \n \nDeveloped algorithms and software will be stored on  the KU Leuven servers , as well on public repositories \nsuch as framagit.c om and codeocean.com.  \n \nRegarding the web platform, it will be hosted on a virtual server that will be created by the IT department of \nthe KU Leuven (500 euros / year, covered by laboratory funds). Aggregated data will be transferred from \nthe L -drive to the  virtual server at the time of publication.  \n \n5.2. How will the data be backed up?  \n \nThe hosting KUL server is automatically backed up using KUL services, multiple times per day. Concerning \nLabCollector, backups are automatically performed twice a day.  \n \n5.3. Is there currently sufficient storage & backup capacity during the project? If yes, specify \nconcisely. If no or insufficient storage or backup capacities are available, then explain how this \nwill be taken care of.  \n \nThere is sufficient storage and back -up capacity on all KU Leuven servers:  \n- the “L -drive” is an easily scalable system, built from General Parallel File System (GPFS) cluster with \nNetApp series storage systems, and a CTDB samba cluster in the front -end.  \n- the Staging and Archive on VSC are also sufficiently scalable (petabyte scale).  \n \n5.4. What are the expected costs for data storage and backup during the project? How will these \ncosts be covered?  \n \nThe total estimated cost of data storage and backup during the project is  1100 per year . This estimation is \nbased on the following costs:  \n- 500 euros  for storage on the L -drive of 4200  Go at 0.111 EUR/Go/year . \n- 600 for storage on the VSC cluster of 1000 Go at 0.6 EUR/Go/year . \n \nBudget for compute and data storage is budgeted via the laboratory funds.   \n \n5.5. Data security: how will you  ensure that the data are securely stored and not accessed or \nmodified by unauthorized persons?  \n  \nOur eCRF, our lab management system (Lab Collector), and the network drive dedicated to the team (L -\ndrive) are password access -protected by users, with person -based decision on rights to access and modify \ndata. Moreover, this is the same for the VSC secured storage which is only accessible to VSC accounts, \nand specifically our volume will only be accessible to group members.  \n1297322N  DMP  V1.0 \n6  \n6. DATA PRESERVATION AFTER THE END OF THE PROJECT  \n6.1. Which data will be retained for the expected 10  year period after the end of the project? If only \na selection of the data can/will be preserved, clearly state why this is the case (legal or contr actual \nrestrictions, physical preservation issues, ...).  \n \nThe minimum preservation term of 10 years after the end of the project will be applied to all datasets  \ndescribed above.  \n \n6.2. Where will these data be archived (= stored for the long term)?  \n \nAs a general rule, datasets will be made openly accessible, whenever possible via existing platforms that \nsupport FAIR data sharing (www.fairsharing.org), at the latest at the time of publication or preprint \ndeposition.  \n \nFor all other datasets, long term storag e will be ensured as follows:  \n- Large sequencing/omics data: will be stored on “L -drive”.  \n- Small digital files: files will be stored on the “L -drive”.  \n- Developed algorithms and software will be stored on L -drive, as well on public repositories such as \nframagit.com and codeocean.com.  \n- Clinical and sample data will be stored in our lab management tools (eCRF and Lab Collector).  \n \n6.3. What are the expected costs for data preservation during these 10 years? How will the costs \nbe covered?  \n \nThe total estimated cost of data storage during the 10 years after the end of the project is  5000 euros . This \nestimation is based on the total given in Table 1 and the cost of storage on the L -Drive (0,11 1/Go/year). \nThe cost will be covered by the labor atory budget.  \n \n7. DATA SHARING AND RE -USE \n7.1. Are there any factors restricting or preventing the sharing of (some of) the data (e.g. as \ndefined in an agreement with a 3rd party, legal restrictions or because of IP potential)?  \n \nThere is no specific restriction.  \nPersonal data will only be published after de -identification and identifiers will not be published.  \nPlease note, GDPR does not apply to deceased patients.  \n \n7.2. Which data will be made available after the end of the project?  \n \n1297322N  DMP  V1.0 \n7 We are committed to publish research results  (concerning all datasets)  to communicate them to peers and \nto a wide audience. All research outputs supporting publications will be made ope nly accessible. Depending \non their nature, some data may be made available prior to publication, either on an individual basis to \ninterested researchers and/or potential new collaborators, or publicly via repositories (e.g. negative data). \nMTA and or DTA h ave been set -up in this sense and will be set -up if needed.  \n \nAs part of the open access plan, data will be put available for external users through open source pathways . \nIn that case, these data will be made available after appropriate IP protection.  \n \nUpon  publication, all anonymized patient details supporting a manuscript will be made publicly available as \nsupplemental information. Personal data will only be published/shared after de -identification and identifiers \nwill not be published/shared.  \n \nOmics datas ets will be deposited in open access repositories such the NCBI Gene Expression Omnibus \n(GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software \ncode driving the project will be stored in a private online git re pository of the laboratory. As soon as the \nmanuscript is publicly available, the repository will be changed to a public repository. The platform Code \nCapsule will be used upon publication to increase reproducibility of the research and open both data and \ncode supporting the publication. The code required to generate the figures of the paper will be available \nonline. Publicly available data will be directly included in the capsule allowing to easily reproduce the paper \nonline. In case part of the data falls under restricted access, a synthetic  version of it will be made available, \nallowing the user to run the code. Proper data will be made available with a granted MTA or DTA.  \n \n7.3. Where/how will the data be made available for reuse?  \n \nIn an Open Acce ss repository.  \nUpon publication, all anonymized patient details supporting a manuscript will be made publicly available as \nsupplemental information.  \n \nOmics datasets will be deposited in open access repositories such the NCBI Gene Expression Omnibus \n(GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software \ncode driving the project will be stored in a private online git repository of the laboratory. As soon as the \nmanuscript is publicly available, the repository wi ll be changed to a public repository . \n \nA web platform  hosted on a virtual server at the KU Leuven will allow browsing the results of the publication, \nshowing only aggregated data.  \n \n7.4. When will the data be made available?  \n \nUpon publication. However, depending on their nature, some data may be made available prior to \npublication, either on an individual basis to interested researchers and/or potential new collaborators, or \n1297322N  DMP  V1.0 \n8 publicly via repositories (e.g. negative data). MTA and or DTA have been set -up in this sense and will be \nset-up if needed.  \n \n7.5. Who will be able to access the data and under what conditions?  \n \nWhenever possible, datasets and the appropriate metadata will be made publicly available through \nrepositories that support FAIR data sharing.  \nMoreover, as mentioned above MTA and or DTA have been set -up and will be set -up if needed.  \n \n7.6. What are the expected costs for data sharing? How will these costs be covered?  \n \nIt is the intention to minimize data management costs by implementing standard  procedures e.g. for \nmetadata collection and file storage and organization from the start of the project, and by using free -to-use \ndata repositories and dissemination facilities whenever possible.  Data management costs will be covered \nby the laboratory bud get. \n \n8. RESPONSIBILITIES  \n8.1. Who will be responsible for the data documentation & metadata?  \n \nMetadata will be documented by the senior post -doc, research manager, PhD students and technical staff \nat the time of data collection and analysis.  \n \n8.2. Who will be responsible for data storage & back up during the project?  \n  \nThe senior post -doc, research manager and technical staff will ensure data storage and back up, with \nsupport from ICTS, gbiomed -IT staff, and UZ -IT staff.  \n \n8.3. Who will be responsible fo r ensuring data preservation and sharing?  \n  \nThe PI is responsible for data preservation and sharing, with support from the team, ICTS, gbiomed -IT staff, \nand UZ -IT staff.  \n \n8.4. Who bears the end responsibility for updating & implementing this DMP?  \n  \nThe PI is ultimately responsible for all data management during and after data collection, including \nimplementing and updating the DMP.  \n \n "
    },
    "clean_full_text": "1297322N DMP V1.0 1 DMP in the context of FWO Postdoctoral Fellow – senior LIQUIDEVO: Unravelling breast cancer heterogeneity, progression and treatment resistance in the context of a rapid post -mortem institutional tissue donation program using phylogenetic reconstruction algorithms and an Open Science approach. Project Name: DMP LIQUIDEVO Principal Investigator / Researcher: Christine Desmedt Institution: KU Leuven 1. GENERAL INFORMATION Name of the project lead (PI) DMP LIQUIDEVO François Richard Internal Funds Project number & title 1297322N LIQUIDEVO: Unravelling breast cancer heterogeneity, progression and treatment resistance in the context of a rapid post-mortem institutional tissue donation program using phylogenetic reconstruction algorithms and an Open Science approach. 2. DATA DESCRIPTION 2.1. Will you generate/collect new data and/or make use of existing data? We will generate and collect new data (prospective data and samples collection and make use of existing data (retrospective data and samples collection ). The project will collect pseudonymized clinical data collected after the patient consented to the study. Clinical, histopathological and treatment data will be entered in the eCRF that we have designed in REDcap . Also sample metadata (SPREC based) will be collected in LabCollector, a database that we have customized for the needs of LIQUIDEVO . Our research will generate: - Genomic data: sequencing data (.fastqc and bam files) ; - Scripts (R, bash) to analyse the data; - A web platform allowing browsing in the results ; - Code Ocean capsules and framagit pages to reproduce and access the code, respectively ; - Manuscripts and publications. 1297322N DMP V1.0 2 In terms of data storage, data will be stored on UZ Leuven drives (eCRF) and KU Leuven drives (all other data) in a GDPR compliant manner and with regular backups provided by the IT services for at least 10 years after the end of LIQUIDEVO . With regard t o manuscript publication: in line with GDPR and KU Leuven Open Science policy, no personnel data will be made publicly available through public repositories such as GitHub and Code Ocean. A version of the manuscript will be uploaded to Lirias. Personal dat a (e.g. raw sequencing data) will be deposited on public repositories such as the EGA, under restricted access. 2.2. What data will you collect, generate or reuse? Describe the origin, type and format of the data (per dataset) and its (estimated) volume. This may be easiest in a numbered list or table and per objective of the project . Work package Data type N° of cases Data Source Data content Data Format Volume (Go) WP1 Primary and secondary use, clinical and sample data collection 15 Patient file Demographic, pathological, clinical, treatment, outcome data and blood results ; Samples data eCRF (RedCap), R files, Lab collector, Excel files 0.5 WP2 Primary use, WGS 125 HiSeq 4000 genomics data fastq and .bam files 3750 WP4 Primary use, TGS 270 HiSeq 4000 genomics data fastq and .bam files 405 WP6 Primary use; website source code 1 LTBCR - bioinformatics R code R and text files 1 1297322N DMP V1.0 3 3. ETHICAL AND LEGAL ISSUES 3.1. Will you use personal data? If so, shortly describe the kind of personal data you will use. Add the reference to the file in KU Leuven's Record of Processing Activities. Be aware that registering the fact that you process personal data is a legal obligation. Yes, we will use personal data. Data, irrespective of the WPs, includ e demographic (age, gender), pathological, clinical, treatment and outcome data as well as sequencing data on tissue and liq uid samples including whole genome as well as targeted genome sequencing. Please note, GDPR does not apply to deceased patients. The compliance monitoring form is the following: E-2021 -2462 . 3.2. Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, add the reference to the formal approval by the relevant ethical review committee(s). LIQUIDEVO is part of t he UPTIDER project which was approved by the EC UZ/KU Leuven: S64410. 3.3. Does your research possibly result in research data with potential for tech transfer and valorisation? Will IP restrictions be claimed for the data you created? If so, for what data and which restrictions will be asserted? There is potential tech transfer/valorization in t he putative assays/biomarkers we measure or we aim to discover. We are working with the Leuven Research and Development department (LRD) and the legal advisors from UZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer Agre ements (MTA/DTAs) we have set -up in the context of this project. 3.4. Do existing 3rd party agreements restrict dissemination or exploitation of the data you (re)use? If so, to what data do they relate and what restrictions regarding reuse and sharing are in place? We are working with the Leuven Research and Development department (LRD) and the legal advisors from UZ Leuven. They are involved in all the Material Transfer Agreements and Data Transfer Agreements (MTA/DTAs) we have set -up in the context of t his project. There is no specific data restriction. 4. DOCUMENTATION AND METADATA 4.1. What documentation will be provided to enable understanding and reuse of the data collected/generated in this project ? 1297322N DMP V1.0 4 All collected clinical data are stored in an eCRF (REDCap) in which the documentation is automatically provided th rough the auto generated dictionary and code book where all the requested data are described. All collected data belonging to the sample collection are stored in an online lab managem ent system called Lab Collector based on SPREC requirements where all the requested data are described. The lab-specific generic data management plan will guide researchers through data collection and processing workflows, ensuring efficient safe storage, keeping track of data use and associated processing related to each experimental step, and enabling data query filtering of the collected data. Regarding omics data, bioinformatics pipeline are shared on a common git repository and heavily described so that they can be reproduced. When possible docker -like structure container will be used to easily share and perform bioinformatics pipeline. This container allows to enclose code and software so that they can be reused with the exact same versions and param eters . Third -party software and algorithms that are used are referenced by their version numbers in our method section and are installed as modules on the VSC and/or containers (Docker, Singularity) on the VSC, to ensure reproducibility . At the publication level, a companion code capsule hosted by code ocean will be build. It will allow reproducing the figures of the paper, browsing code and raw data. In case of restricted access on the data, a synthetic dataset mimic king the characteristic of the real data will be made available instead (see section 7.2). 4.2. Will a metadata standard be used? If so, describe in detail which standard will be used. If not, state in detail which metadata will be created to make the data easy/easier to find and reuse. Metadata will follow Data Cite’s recommendations (Fenner et al., 2019) . 5. DATA STORAGE AND BACKUP DURING THE PROJECT 5.1. Where will the data be stored? The minimum preservation term of 10 years after the end of the project will be applied to all datasets. Biological samples obtained under research agreement will be kept according to the EC licenses and agreements. In effect, consent is obtained to store the samples for the specific research purposes stipulated in the informed consent. Putative remnant clin ical/patient samples are stored in the UZ Leuven biobank. Hard copies (eg. the Informed Consent forms and paper lab notebooks) are kept in locked cabinets in the lab of the PI concerned. The data will be stored on the KU Leuven servers. All systems but La b Collector run on a secured and backed up server of KULeuven (managed by ICT of the Biomedical Sciences Group). These systems also 1297322N DMP V1.0 5 provide a logging system so no data can ever be erased, making that everything will be traceable and stored long -term (well beyond the common 5 -year requirement). Lab Collector data base is externally and professionally managed by the company “AgileBio”. Developed algorithms and software will be stored on the KU Leuven servers , as well on public repositories such as framagit.c om and codeocean.com. Regarding the web platform, it will be hosted on a virtual server that will be created by the IT department of the KU Leuven (500 euros / year, covered by laboratory funds). Aggregated data will be transferred from the L -drive to the virtual server at the time of publication. 5.2. How will the data be backed up? The hosting KUL server is automatically backed up using KUL services, multiple times per day. Concerning LabCollector, backups are automatically performed twice a day. 5.3. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. If no or insufficient storage or backup capacities are available, then explain how this will be taken care of. There is sufficient storage and back -up capacity on all KU Leuven servers: - the “L -drive” is an easily scalable system, built from General Parallel File System (GPFS) cluster with NetApp series storage systems, and a CTDB samba cluster in the front -end. - the Staging and Archive on VSC are also sufficiently scalable (petabyte scale). 5.4. What are the expected costs for data storage and backup during the project? How will these costs be covered? The total estimated cost of data storage and backup during the project is 1100 per year . This estimation is based on the following costs: - 500 euros for storage on the L -drive of 4200 Go at 0.111 EUR/Go/year . - 600 for storage on the VSC cluster of 1000 Go at 0.6 EUR/Go/year . Budget for compute and data storage is budgeted via the laboratory funds. 5.5. Data security: how will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? Our eCRF, our lab management system (Lab Collector), and the network drive dedicated to the team (L - drive) are password access -protected by users, with person -based decision on rights to access and modify data. Moreover, this is the same for the VSC secured storage which is only accessible to VSC accounts, and specifically our volume will only be accessible to group members. 1297322N DMP V1.0 6 6. DATA PRESERVATION AFTER THE END OF THE PROJECT 6.1. Which data will be retained for the expected 10 year period after the end of the project? If only a selection of the data can/will be preserved, clearly state why this is the case (legal or contr actual restrictions, physical preservation issues, ...). The minimum preservation term of 10 years after the end of the project will be applied to all datasets described above. 6.2. Where will these data be archived (= stored for the long term)? As a general rule, datasets will be made openly accessible, whenever possible via existing platforms that support FAIR data sharing (www.fairsharing.org), at the latest at the time of publication or preprint deposition. For all other datasets, long term storag e will be ensured as follows: - Large sequencing/omics data: will be stored on “L -drive”. - Small digital files: files will be stored on the “L -drive”. - Developed algorithms and software will be stored on L -drive, as well on public repositories such as framagit.com and codeocean.com. - Clinical and sample data will be stored in our lab management tools (eCRF and Lab Collector). 6.3. What are the expected costs for data preservation during these 10 years? How will the costs be covered? The total estimated cost of data storage during the 10 years after the end of the project is 5000 euros . This estimation is based on the total given in Table 1 and the cost of storage on the L -Drive (0,11 1/Go/year). The cost will be covered by the labor atory budget. 7. DATA SHARING AND RE -USE 7.1. Are there any factors restricting or preventing the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions or because of IP potential)? There is no specific restriction. Personal data will only be published after de -identification and identifiers will not be published. Please note, GDPR does not apply to deceased patients. 7.2. Which data will be made available after the end of the project? 1297322N DMP V1.0 7 We are committed to publish research results (concerning all datasets) to communicate them to peers and to a wide audience. All research outputs supporting publications will be made ope nly accessible. Depending on their nature, some data may be made available prior to publication, either on an individual basis to interested researchers and/or potential new collaborators, or publicly via repositories (e.g. negative data). MTA and or DTA h ave been set -up in this sense and will be set -up if needed. As part of the open access plan, data will be put available for external users through open source pathways . In that case, these data will be made available after appropriate IP protection. Upon publication, all anonymized patient details supporting a manuscript will be made publicly available as supplemental information. Personal data will only be published/shared after de -identification and identifiers will not be published/shared. Omics datas ets will be deposited in open access repositories such the NCBI Gene Expression Omnibus (GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software code driving the project will be stored in a private online git re pository of the laboratory. As soon as the manuscript is publicly available, the repository will be changed to a public repository. The platform Code Capsule will be used upon publication to increase reproducibility of the research and open both data and code supporting the publication. The code required to generate the figures of the paper will be available online. Publicly available data will be directly included in the capsule allowing to easily reproduce the paper online. In case part of the data falls under restricted access, a synthetic version of it will be made available, allowing the user to run the code. Proper data will be made available with a granted MTA or DTA. 7.3. Where/how will the data be made available for reuse? In an Open Acce ss repository. Upon publication, all anonymized patient details supporting a manuscript will be made publicly available as supplemental information. Omics datasets will be deposited in open access repositories such the NCBI Gene Expression Omnibus (GEO) or The European Genome -phenome Archive (EGA). All the relevant algorithms, scripts and software code driving the project will be stored in a private online git repository of the laboratory. As soon as the manuscript is publicly available, the repository wi ll be changed to a public repository . A web platform hosted on a virtual server at the KU Leuven will allow browsing the results of the publication, showing only aggregated data. 7.4. When will the data be made available? Upon publication. However, depending on their nature, some data may be made available prior to publication, either on an individual basis to interested researchers and/or potential new collaborators, or 1297322N DMP V1.0 8 publicly via repositories (e.g. negative data). MTA and or DTA have been set -up in this sense and will be set-up if needed. 7.5. Who will be able to access the data and under what conditions? Whenever possible, datasets and the appropriate metadata will be made publicly available through repositories that support FAIR data sharing. Moreover, as mentioned above MTA and or DTA have been set -up and will be set -up if needed. 7.6. What are the expected costs for data sharing? How will these costs be covered? It is the intention to minimize data management costs by implementing standard procedures e.g. for metadata collection and file storage and organization from the start of the project, and by using free -to-use data repositories and dissemination facilities whenever possible. Data management costs will be covered by the laboratory bud get. 8. RESPONSIBILITIES 8.1. Who will be responsible for the data documentation & metadata? Metadata will be documented by the senior post -doc, research manager, PhD students and technical staff at the time of data collection and analysis. 8.2. Who will be responsible for data storage & back up during the project? The senior post -doc, research manager and technical staff will ensure data storage and back up, with support from ICTS, gbiomed -IT staff, and UZ -IT staff. 8.3. Who will be responsible fo r ensuring data preservation and sharing? The PI is responsible for data preservation and sharing, with support from the team, ICTS, gbiomed -IT staff, and UZ -IT staff. 8.4. Who bears the end responsibility for updating & implementing this DMP? The PI is ultimately responsible for all data management during and after data collection, including implementing and updating the DMP."
}