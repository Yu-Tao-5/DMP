{
    "document_id": "D-2021-1229",
    "LinkTitle": "D-2021-1229",
    "file_name": "D-2021-1229.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2021-1229.pdf",
    "metadata": {
        "title": "Viral-associated pulmonary aspergillosis: new perspectives on pathophysiology to enable host-directed medicine - DMP title",
        "author": "N/A",
        "num_pages": 10
    },
    "content": {
        "full_text": "DMP title\nProject Name\n Viral-associated pulmonary aspergillosis: new perspectives on pathophysiology to\nenable host-directed medicine - DMP title\nGrant Title\n 11M6922N\nPrincipal Investigator / Researcher\n Simon Feys\nProject Data Contact\n Simon Feys\nDescription\n Influenza- and COVID-19-associated pulmonary aspergillosis (IAPA/CAPA, together\nviral-associated pulmonary aspergillosis or VAPA) comprise a severe healthcare burden with high\nmortality. Knowledge gaps: VAPA-pathophysiology has never been examined before. LC3-\nassociated phagocytosis (LAP) and Pentraxin-3 (PTX3), essential for fungal killing, might be key\nplayers in IAPA and VAPA pathogenesis, respectively. Prospective data and clinical risk factors for\nIAPA are lacking. Approach: we have recently established a zebrafish larvae model for IAPA,\nwhich will be used for visualization of the innate immune response and of LC3-associated\nphagocytosis in IAPA. Human PTX3 single-nucleotide polymorphism (SNP) analysis will be\nperformed to assess whether they predispose to VAPA-development. Single-cell RNA-sequencing\n(scRNA-seq) is a powerful technique to unravel cellular/molecular mechanisms governing VAPA-\npathogenesis, which will be used on broncho-alveolar lavage fluid and post-mortem biopsies of\nsevere influenza and COVID-19 patients with or without VAPA. We will analyze data of a\nprospective international multicenter trial on IAPA. Expected outcome: New insights in VAPA-\npathogenesis, with identification of diagnostic/prognostic biomarkers and potential\nimmunomodulatory therapeutical targets. Generation of prospective data on IAPA epidemiology\nand clinical risk factors, allowing identification of patients-at-risk for development of IAPA.\nInstitution\n KU Leuven\n1. General Information\nName applicant\nSimon Feys\nFWO Project Number & Title\n11M6922N: Viral-associated pulmonary aspergillosis: new perspectives on the pathophysiological\nand clinical aspects to enable host-directed medicine\nAffiliation\nKU Leuven\n2. Data description\nWill you generate/collect new data and/or make use of existing data?\nGenerate new data\nReuse existing data\nDescribe in detail the origin, type and format of the data (per dataset) and its\n(estimated) volume. This may be easiest in a table (see example) or as a data flow and\nper WP or objective of the project. If you reuse existing data, specify the source of\nthese data. \nDistinguish data types (the kind of content) from data formats (the\ntechnical format).\nWork\npackage\nType of data\nFormat\nVolume\nHow created\nWP1.1\nSNP-results (RT-\nqPCR data)\n.xls\nmax 100\nMB\nSNP-analysis of\nblood and\nbronchoalveolar\nlavage fluid\nsamples from\npatients with\nsevere influenza\nor COVID-19\nwith or without\naspergillosis.\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n1 of 10\nWP1.1\nObservational\npseudonymized\nclinical patient\ndata\nonline\neCRF\nformat\n(REDcap,\nCastor),\n.xls\nmax 20MB\nObservational\ndata derived\nfrom clinical\npatient records\nin a prospective\nand\nretrospective\nstudy\n(Contagious,\nPIAS, Variomic\nstudy), used to\nlink with SNP-\nanalyses.\nWP1.2\nMicroscopy\nimages\n.tif, .lif\n100-200GB\nHigh-resolution\nfluorescence\nmicroscopy of\nzebrafish larvae\ninfected with\ninfluenza\nvirus, \nAspergillus\nor both, or\nsham-injected.\nWP1.2\nRT-qPCR results\n.xls\nmax 10MB\nRT-qPCR results\nof zebrafish\nlarvae infected\nwith influenza\nvirus.\nWP1.2\nObservational\nnumeric data of\nzebrafish\nlarvae \n.xls\nmax 10MB\nObservational\nresults from\nzebrafish larvae\nexperiments. \nWP2\nscRNA-\nseq results\n.fastq and\n.xls\n +/- 550\nGB (scRNA-\nseq from\n+/- 55\npatients at\n10 GB per\npatient)\nResults obtained\nfrom scRNA-\nsequencing\nbronchoalveolar\nlavage fluid of\npatients with\nsevere influenza\nor COVID-19\nwith or without\naspergillosis.\nWP2\nObservational\npseudonymized\nclinical patient\ndata\nonline\neCRF\nformat\n(REDcap),\n.xls\nmax 5MB\nObservational\ndata derived\nfrom clinical\npatient records\nin a prospective\nstudy\n(Contagious\nstudy), used to\nlink with scRNA-\nseq data.\nWP3\nObservational\npseudonymized\nclinical patient\ndata\nonline\neCRF\nformat\n(Castor),\n.xls\nmax\n100MB\nObservational\ndata derived\nfrom clinical\npatient records\nin a prospective\nstudy (IAPAFLU\nstudy).\nWP1,2,3\nInformed\nconsent form\ntext,\nprinted\npaper\nNA\n \nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n2 of 10\nWP1,2,3\nPatient sample\ncollection\n(blood,\nbronchoalveolar\nlavage fluid,\nnasal/oral/anal\nswabs)\nbiologic\nsamples\nkept at -\n20°C or -\n80°C\nNA\nDirectly\ncollected from\nthe patient\n3. Legal and ethical issues\nWill you use personal data? \nIf so, shortly describe the kind of personal data you will\nuse. Add the reference to your file in KU Leuven's Register of Data Processing for\nResearch and Public Service Purposes (PRET application). \nBe aware that registering\nthe fact that you process personal data is a legal obligation.\nYes\nEC Research S-numbers: S63881, S62072, S65588, S64259\nPrivacy compliance S-numbers: S63381, S65588, S64259\nShort description of the kind of personal data that will be used: clinical data of patients admitted\nto ICU with severe influenza or severe COVID-19, with or without aspergillosis. Data consists of\ndemographic data, medical history before admission, clinical parameters and disease history at\nICU admission, laboratory and radiographical parameters, and clinical outcome parameters. \nAre there any ethical issues concerning the creation and/or use of the data (e.g.\nexperiments on humans or animals, dual use)? If so, add the reference to the formal\napproval by the relevant ethical review committee(s)\nYes\nEC Research S-numbers: S63881, S62072, S65588, S64259\nECD P-number: P070/2021\nDoes your work possibly result in research data with potential for tech transfer and\nvalorisation? Will IP restrictions be claimed for the data you created? If so, for what\ndata and which restrictions will be asserted?\nNo\nDo existing 3rd party agreements restrict dissemination or exploitation of the data\nyou (re)use? If so, to what data do they relate and what restrictions are in place?\nNo\n4. Documentation and metadata\nWhat documentation will be provided to enable reuse of the data collected/generated\nin this project?\nAll data with relation to patients will be coded.\nWP1.1:\nThe information contains the date the SNP-analysis was performed, the study\ndesign, methodology, the protocol (or a link to the protocol), reagents, and sampling. The\nlab notebooks also contain links to the electronic files that contain the raw data, the processed\nresults or other relevant data. Encoded patient data is stored in Redcap or in Castor eCRFs and in\nexcel exports of these data. \nWP1.2:\nThe information contains the date the experiment was performed, the study design,\nmethodology, the protocol (or a link to the protocol), reagents, and sampling. The lab notebooks\nalso contain links to the electronic files that contain the raw data (e.g. of RT-qPCR …), the\nprocessed results or other relevant data.\nProtocols are digitally available in Word documents and research results are available in Excel\ndocuments collected in specific folders. Data files will be logically grouped in folders (according\nto sub-parts of the project). The description of the experiments will contain all information such\nthat another analyst or scientist can repeat the experiments.\nWP2:\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n3 of 10\nDocumentation will consist of notes in the Electronic Laboratory Notebook that refers to specific\ndatasets. These notes will describe the biological/clinical samples used, experimental setup and\nprotocols used, sequences generated, links to the specific computer location and the specific\nnames of the respective datasets. Metadata sheets are maintained with the connection between\nlab samples, sample IDs and files in the data storage so that lab samples, data files and\nexperimental notes remain properly linked to the corresponding samples IDs.\nResearch methods and practices (SOPs) are fully documented. When wet lab techniques, scripts,\nalgorithms and software tools are finalized, they are additionally described in manuscripts and/or\non GitHub.\nRaw sequencing data (.fastq files; each named with corresponding sampleID) is collected per\nsequencing run, including an .xlsx file with the sample sheet information containing the sample\nIDs sequenced in that run and the sequencing run information per sample ID (Illumina\nsequencer, lane and index information). The name of the folder will contain the date of the\nsequencing run and the Illumina sequencer used. When data are published, raw and processed\nsequencing data will be uploaded on a public repository (e.g. EGA) with appropriate access\ncontrol if required, to enable sharing and long-term validity of the data.\nWP3:\nData generated in this work package is managed by Radboudumc as part of the H2020 project\nHDM-FUN. In line with Radboudumc policy, (meta)data that are suitable for reuse will be available\nto other researchers upon request using the DANS EASY repository that is certified\n(CoreTrustSeal/ nestor Seal 2016). DANS uses Digital Object Identifiers (DOIs). Each dataset\nstored in EASY has a unique DOI, and new datasets are automatically assigned a DOI upon\ndeposition. You can use this DOI when citing the associated dataset. Each dataset also contains a\nset of instructions in “Cite as” format to facilitate data citation by secondary users using the DOI.\nThe deposit in the DANS EASY archive contains metadata from the Dublin Core standard,\nenriched with DataCite metadata fields. The metadata fields in DANS comply with the guidelines\nof the Dublin Core standard/DataCite and include keywords. Any transformations, restructuring\nand analysis are performed through scripts/syntax files and/or documentation. Version control\nwill be applied that tracks changes in documents, files, syntaxes. Data will be collected using\nCastor-EDC. This is a GCP-compliant EDC. Castor-EDC also enables data managers to add\nmetadata to fields. To make the data Interoperable standard data names and types (ontology)\nwill be used, such as SNOMED, MedDRA. When research data is completed and ready for storage,\nit will be uploaded to partners institutional repository or to Zenodo (https://www.zenodo.org/),\nwhen a partner has not access to an institutional repository. A DOI will be assigned to datasets\nfor effective and persistent citation when uploaded in a repository. This DOI can be used in any\nrelevant publications to direct readers to the underlying dataset. Data from each experiment is\nsaved in a word or excel file and each word or excel file is recorded in a spreadsheet with the\ndate and title of experiment. Search keywords will be provided when the dataset is uploaded to\nthe institutional repository and/or to Zenodo which will optimise possibilities for re-used.\n \nWill a metadata standard be used? If so, \ndescribe in detail which standard will be\nused. \nIf no, state in detail which metadata will be created to make the data\neasy/easier to find and reuse.\nYes\nNo\nWP1.1:\nMetadata from SNP-analyses (performed in a RT-qPCR-system) are inherently stored in exported\nfiles (including all RT-qPCR settings). \n \nWP1.2:\nMetadata from RT-qPCR files are inherently stored in exported files (including all RT-qPCR\nsettings). Metadata related to microscopy images generated during the work package will be\nadded to the title of each .lif-file and .tif image (timepoint, microscope settings, and experiment\nnumber which refers to an additional file containing experiment metadata), but most metadata\nare also inherently stored in the files created by the instrument (.lif). \nWP2:\nSequencing data types require specific metadata when submitted to public repositories such\nas EGA, ArrayExpress, GEO or ENA. Data documentation will be tailored to their ultimate\ndeposition in public repositories, with spreadsheet headers corresponding to fields required by\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n4 of 10\nthese public repositories. Technical and analytical methods used to generate the data will be\ndocumented in sufficient detail to allow for independent reproduction. These will include analysis\npackage version numbers, analysis kit, disease status, treatment type and duration, organism,\ngenome build…. For single-cell experiments, each droplet barcode will also be retained alongside\nthe associated single-cell quality metrics. When depositing data in a repository, the final dataset\nwill be accompanied by this information in the file format that the repository provides. This will\nallow the data to be understood by other members of the laboratory and add context to the\ndataset for future reuse.\nWP3:\nThe deposit in the DANS EASY archive contains metadata from the Dublin Core standard,\nenriched with DataCite metadata fields. The metadata fields in DANS comply with the guidelines\nof the Dublin Core standard/DataCite and include keywords. Any transformations, restructuring\nand analysis are performed through scripts/syntax files and/or documentation. Version control\nwill be applied that tracks changes in documents, files, syntaxes. Data will be collected using\nCastor-EDC. This is a GCP-compliant EDC. Castor-EDC also enables data managers to add\nmetadata to fields. \nTo make the data Interoperable standard data names and types (ontology) will be used, such as\nSNOMED, MedDRA. For labdata this is LOINC. When research data is completed and ready for\nstorage, it will be uploaded to partners institutional repository or to Zenodo\n(https://www.zenodo.org/), when a partner has not access to an institutional repository. A DOI will\nbe assigned to datasets for effective and persistent citation when uploaded in a repository. This\nDOI can be used in any relevant publications to direct readers to the underlying dataset. Data\nfrom each experiment is saved in a word or excel file and each word or excel file is recorded in a\nspreadsheet with the date and title of experiment.\nHDM-FUN naming convention for project datasets will comprise the following:\nA unique chronological number of the datasets\nThe title of the dataset\nEach new version of a dataset will be named with a version number (e.g., v1.0, v1.1, v1.2\netc)\nA prefix “HDM-FUN” indicating a project dataset\nA unique identifier number linking with the dataset WP and deliverable (e.g., WP1_D1.1”)\nExample: \n01_\n \nTITLE OF DATASET\n_v1.0_HDM-FUN_WP1_D1.1.xlsx\nSearch keywords will be provided when the dataset is uploaded to the institutional repository\nand/or to Zenodo which will optimise possibilities for re-use.\n5. Data storage and backup during the FWO project\nWhere will the data be stored?\nElectronic data\nThe electronic data generated during the SNP work package (WP1.1) will be stored in secured,\npassword-protected and back-up servers of UZ Leuven. \nAll electronical data collected and generated during the scRNA-seq work package (WP2) and the\nzebrafish work package (WP1.2) will be processed and (temporarily) stored on secured,\npassword-protected and backed up servers of VIB-KU Leuven and KU Leuven respectively\n(managed by ICT of the Biomedical Sciences Group).\nThe sequencing data generated during the scRNA-seq work package (WP2) will either be stored\non VIB-KU Leuven servers or on the Flemish Supercomputer Centre (VSC), initially in the staging\nand archive area, and later only in the archive area (archive is mirrored).\nThe electronic data generated during the observational study work package (WP3) will be stored\ncentrally at Radboudumc (Nijmegen, the Netherlands) as Radboudumc is the sponsor of this\nstudy, in Digital Research Environment (DRE), which is a cloud-based dedicated and\nsecure workspace. The DRE consists of workspaces, from within tools can be used which enable\nus to import, merge, optimize, store, analyze, archive and share clinical and research data. Each\nworkspace is completely secure and fully scalable. DRE provides the necessary security, ICT\ninfrastructure and compliance with international laws and regulations. \nSamples\nFor the SNP work package (WP1.1), all patient samples will be stored in UZ Leuven in labeled\ntubes in -20°C or -80°C freezers purchased by own funding. The samples will be registered and\nhandled according to the UZ Leuven Biobank guidelines.\nFor the zebrafish work package (WP1.2), all samples generated during experiments will be stored\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n5 of 10\nin labeled tubes in the Rega Institute (KU Leuven) in -20°C or -80°C freezers purchased by own\nfunding.Samples will be registered in the FreezerPro (the sample handling system of the Rega\nInstitute). \nFor the scRNA-seq work package (WP2), all patient samples, ˜single-cell suspensions and\nsequence library preparations will be stored in labeled tubes or SBS plates in -20°C or -80°C\nfreezers purchased by our own funding. The samples will be registered and handled according to\nthe UZ Leuven Biobank guidelines.\nFor the observational study work package (WP3), all patient samples are sent to the biobank of\nRadboudumc Nijmegen for centrally-managed storage. \n \nHow is backup of the data provided?\nKU/UZ Leuven drives are backed-up automatically on a daily basis using KU/UZ Leuven services.\nRadboudumc drives are backed-up automatically. All sequencing data stored on the Flemish\nSupercomputer Centre (VSC) will be regularly transferred to the archive area that is mirrored.\nIs there currently sufficient storage & backup capacity during the project? If yes,\nspecify concisely. If no or insufficient storage or backup capacities are available then\nexplain how this will be taken care of.\nYes\nThere is sufficient storage and back-up capacity on all described servers. For VIB/KU Leuven\nservers (which will hold the majority of data in this project) specifically:\n- The “L-drive” is an easily scalable system, built from General Parallel File System (GPFS) cluster\nwith NetApp eseries storage systems, and a CTDB samba cluster in the front-end.\n- The “J-drive” is based on a cluster of NetApp FAS8040 controllers with an Ontap 9.1P9 operating\nsystem.\n- The Staging and Archive on VSC are also sufficiently scalable (petabyte scale)\nWhat are the expected costs for data storage and back up during the project? How\nwill these costs be covered?\nThe total estimated cost of data storage during the 4 years of this FWO project is +/-1100 EUR.\nThis estimation is based on the following costs:\nThe costs of digital data storage are as follows: €868,9/5 TB/Year for the “L-drive” and\n€519/TB/Year for the “J-drive”.\nThe cost of VSC archive is €70/TB/Year, and staging €130/TB/Year.\nWe expect costs to drop slightly during the coming four years.\nFor the observational study with data storage by Radboudumc Nijmegen in the Castor\nenvironment, no budgeting is necessary as this is a free service by the Radboudumc Nijmegen. \nAll costs for data storage will be covered by own funding.\nData security: how will you ensure that the data are securely stored and not accessed\nor modified by unauthorized persons?\nObservational clinical patient information as well as sequencing data and associated\npseudonymized patient/clinical information is considered sensitive information and will be\nhandled as such.\nThe data generated in this project will be processed and stored on the VIB-KU Leuven and UZ\nLeuven IT infrastructure or Radboudumc/Castor infrastructure which are protected by a genuine\nuser authentication system relying on username and password. Access to the data as well as the\naccess level will be limited on a project need and individual basis. Only the researchers working\non the project have access to these data. Due to the sample labelling as protective measure, the\nresearchers are not able to decipher the identity of the donor.\nNo personal data will be stored on the VSC nor local drives, except for the nucleic acid\nsequences. The coding key to patient information of linked pseudonymized data does not carry\nany personal identifiers and all records containing the identity of each participant will be kept\nprivate and confidential. The coding key will be kept by the PI, ICU physician prof. dr. Joost\nWauters. \n6. Data preservation after the FWO project\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n6 of 10\nWhich data will be retained for the expected 5 year period after the end of the\nproject? In case only a selection of the data can/will be preserved, clearly state the\nreasons for this (legal or contractual restrictions, physical preservation issues, ...).\nAll electronical data collected in the two first work packages of this FWO project will be retained\nfor the expected 5 year period after the end of the project. All (remaining) biological samples are\npreserved for 50 years, in accordance with the guidelines of Biobank UZ/KU Leuven. All samples\ntaken during the observational study will be stored in the Radboudumc biobank for a minimum of\n10 years after end of the study.\nWhere will the data be archived (= stored for the longer term)?\nAs a general rule, datasets will be made openly accessible, whenever possible via existing\nplatforms that support FAIR data sharing (\nwww.fairsharing.org\n), at the latest at the time of\npublication.\nLong term storage will be ensured as follows for the first two work packages:\nLarge sequencing data will be stored on VSC archive\nSmall digital files, including TIFF files, will be stored on the “L-drive”.\nDeveloped algorithms and software will be stored on VSC archive and/or L-drive, as well on\npublic repositories such as Github.com\nFor the third work package: all data will be archived by Radboudumc Nijmegen in the Znodo data\nsharing repository. \nAll biological samples obtained during the first two work packages are registered and stored at\nthe Biobank UZ/KU Leuven, in accordance with their guidelines. All samples taken during the\nobservational study will be stored in the Radboudumc biobank for a minimum of 10 years after\nend of the study.\nWhat are the expected costs for data preservation during the retention period of 5\nyears? How will the costs be covered?\nThe total estimated cost of data storage for 5 years after the end of the project is +/- €700 (main\ncosts approximately 200GB on KU Leuven L-drive and approximately 550GB on VSC). \nAll costs for data preservation will be covered by our own funding.\n7. Data sharing and reuse\nAre there any factors restricting or preventing the sharing of (some of) the data (e.g.\nas defined in an agreement with a 3rd party, legal restrictions)?\nNo\nWhich data will be made available after the end of the project?\nWP1:\nData resulting in publication will be made available as required, other data upon reasonable\nrequest.\nWP2:\nThe promotor (and co-promotors) of this project are committed to publishing scientific research\nin order to communicate results both to peers and a wider audience. All research outputs\nsupporting publications will be made openly accessible, at the latest, at the time of publication\n(or preprint deposition) via the required link in the publication or upon reasonable request and\nafter an embargo period after publication.\nData that will be made available include:\nDouble-coded raw sequencing data.\nPersonal data will be double coded and no reference to subject name will be made.\nScripts, algorithms and software tools.\nResults will be published as Open Access in peer reviewed journal.\nUpon reasonable request, scRNA-seq data will be reused by transfer through Belnet Filesender or\nsecure copy.\nWP3:\nData will be shared through Zenodo. \nWhere/how will the data be made available for reuse?\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n7 of 10\nIn an Open Access repository\nOther (specify):\nWP1\nWhenever possible, datasets and appropriate metadata will be made publicly available through\nrepositories that support FAIR data sharing. Personal data will be double coded and no reference\nto subject name will be made. Data will be made available upon reasonable request by e-mail.\nWP2:\nWhenever possible, datasets and appropriate metadata will be made publicly available through\nrepositories that support FAIR data sharing. Personal data will be double coded and no reference\nto subject name will be made.\nSharing policies for specific research outputs are detailed below:\nDouble-coded raw sequencing data (linked to double-coded patient data) will be deposited\nin open access repositories with restricted access control such as the EBI European\nGenome-phenome Archive (EGA). The EGA is a repository for personally identifiable genetic\nand phenotypic data. Sequencing data at EGA will only be available upon reasonable\nrequest via our institutional data access committee and if necessary a material transfer\nagreement will be concluded with the beneficiaries in order to describe the types of reuse\nthat are permitted. The double-coded read count data matrix (linked to double-coded\npatient data) will be available on an interactive webserver\n(\nhttp://blueprint.lambrechtslab.org\n).\nDouble-coded patient data: Upon publication, all double-coded patient details supporting a\nmanuscript will be made publicly available as supplemental information.\nResearch documentation: All protocols used to generate published data will be described in\nthe corresponding manuscript(s), and the related documentation will be included as\nsupplementary information. These data and all other documents (raw data) deposited in the\nE-Notebook are accessible to the PI and the research staff, and will be made available upon\nrequest.\nManuscripts: All scientific publications will be shared openly.\nFor the scRNA-seq work package, at the time of publication, research results will be summarized\non the co-promoters’ websites (\nhttps://gbiomed.kuleuven.be/english/research/50488876\n,\nhttps://www.vibcancer.be/diether-lambrechts\n) and post-print pdf versions of publications will be\nmade available there if allowed by copyright agreements, possibly after an embargo as\ndetermined by the publisher. Before the end of the embargo or in cases where sharing the post-\nprint is not allowed due to copyright agreements, a pre-print version of the manuscript will be\nmade available. (Pre-print) publications will also be automatically added to our institutional\nrepository, Lirias 2.0, based on the authors name and ORCID ID.\nAlgorithms, scripts and software: All the relevant algorithms, scripts and software toosls\ndriving the project will be described in manuscripts and/or on GitHub (\nhttps://github.com\n).\nData that do not support publication will be either deposited in an open access repository or\nmade available upon request by email. Data will be reused by transfer via Belnet Filesender\nor secure copy.\nWP3:\nData will be shared through Zenodo. \nWhen will the data be made available?\nUpon publication of the research results\nAll research outputs will be made openly accessible, at the latest, at the time of publication (or\npreprint deposition). No embargo will be foreseen unless imposed e.g. by pending publications,\npotential IP requirements – note that patent application filing will be planned so that publications\nneed not be delayed.\nWho will be able to access the data and under what conditions?\nWP1:\nData will be available on demand. Access will be considered upon reasonable request.\nWP2:\nWhenever possible, datasets and the appropriate metadata will be made publicly available\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n8 of 10\nthrough repositories that support FAIR data sharing. As detailed above, metadata will contain\nsufficient information to support data interpretation and reuse, and will be conform to community\nnorms. These repositories clearly describe their conditions of use (typically under a Creative\nCommons CC0 1.0 Universal (CC0 1.0) Public Domain Dedication or an ODC Public Domain\nDedication and Licence, with a material transfer agreement when applicable). Interested parties\nwill thereby be allowed to access data directly, and they will give credit to the authors for the\ndata used by citing the corresponding DOI. A CC-BY license will be opted for when possible. For\ndata shared directly by the PI (and approval of the 3\nrd\n party if necessary), a material transfer\nagreement (and a non-disclosure agreement if applicable) will be concluded with the\nbeneficiaries in order to clearly describe the types of reuse that are permitted.\nFor KU Leuven data submitted to the EBI European Genome-phenome Archive (EGA), which\noperates under controlled access, the data access/submission requests will be received by the\nGenomics Data Access Committee (DAC) of KU Leuven\n(\nhttps://homes.esat.kuleuven.be/~bioiuser/dac/\n) and processed in consultation with the\ncopromotors produced data. The DAC will provide general guidance in terms of policies and will\nbe referred to in handling controversial cases.  \nWP3:\nThe dataset will be uploaded in a cvs format in Zenodo as an open access dataset under a CC-BY\nlicense. Therefore, it will be available to anyone for any purpose, provided that they give\nappropriate credit to the creators. \nWhat are the expected costs for data sharing? How will the costs be covered?\nIt is the intention to minimize data management costs by implementing standard operating\nprocedures (SOPs) e.g. for metadata collection and file storage and organization from the start of\nthe project, and by using free-to-use data repositories and dissemination facilities whenever\npossible.\n \nAll data management costs will be covered by own funding.\n8. Responsibilities\nWho will be responsible for data documentation & metadata?\n(Meta)data will be documented by the research and technical staff at the time of data collection\nand analysis, by taking careful notes in the E-notebook that refer to specific datasets. The staff\nincludes the PhD students and study nurses involved in the SNP-project (WP1.1); the PhD\nstudent(s), master thesis students, lab assistants involved in the zebrafish project (WP1.2); PhD\nstudent(s), technical assistants and bio-informaticians directly involved with the scRNA-seq\nresearch project (WP2); myself, study nurses and promotor involved in the clinical observational\ntrial (WP3).\nWho will be responsible for data storage & back up during the project?\nThe staff will ensure data storage and back up, with support from ICTS, gbiomed-IT staff, and UZ-\nIT staff. For WP3, Radboudumc is responsible for data storage and back-up. More specifically for\nthe scRNA-seq work package, Gino Philips, a junior computer scientist will handle storage and\nback-up of the sequencing data, under supervision of senior computer scientist Bram Boeckx who\nhas extensive experience in data handling and use of the Flemish Super Computer (VSC)\nenvironment.\n \nFinal responsibility for data storage & back-up lies with promotor and co-promotors of this\nproject, supported by ICTS, HPC, gbiomed-IT staff and UZ-IT staff. For WP3, final responsibility\nlies with the promotor and with prof. Frank Van De Veerdonk (Radboudumc). \nWho will be responsible for ensuring data preservation and reuse ?\nThe staff will ensure data storage and back up, with support from ICTS, gbiomed-IT staff, and UZ-\nIT staff. For WP3, Radboudumc is responsible for data storage and back-up. More specifically for\nthe scRNA-seq work package, Gino Philips, a junior computer scientist will handle storage and\nback-up of the sequencing data, under supervision of senior computer scientist Bram Boeckx who\nhas extensive experience in data handling and use of the Flemish Super Computer (VSC)\nenvironment.\n \nFinal responsibility for data storage & back-up lies with promotor and co-promotors of this\nproject, supported by ICTS, HPC, gbiomed-IT staff and UZ-IT staff. For WP3, final responsibility\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n9 of 10\nlies with the promotor and with prof. Frank Van De Veerdonk (Radboudumc). \nWho bears the end responsibility for updating & implementing this DMP?\nThe PI bears the end responsibility of updating & implementing this DMP.\nThis document was generated by DMPonline (http://dmponline.dcc.ac.uk)\n10 of 10"
    },
    "clean_full_text": "DMP title Project Name Viral-associated pulmonary aspergillosis: new perspectives on pathophysiology to enable host-directed medicine - DMP title Grant Title 11M6922N Principal Investigator / Researcher Simon Feys Project Data Contact Simon Feys Description Influenza- and COVID-19-associated pulmonary aspergillosis (IAPA/CAPA, together viral-associated pulmonary aspergillosis or VAPA) comprise a severe healthcare burden with high mortality. Knowledge gaps: VAPA-pathophysiology has never been examined before. LC3- associated phagocytosis (LAP) and Pentraxin-3 (PTX3), essential for fungal killing, might be key players in IAPA and VAPA pathogenesis, respectively. Prospective data and clinical risk factors for IAPA are lacking. Approach: we have recently established a zebrafish larvae model for IAPA, which will be used for visualization of the innate immune response and of LC3-associated phagocytosis in IAPA. Human PTX3 single-nucleotide polymorphism (SNP) analysis will be performed to assess whether they predispose to VAPA-development. Single-cell RNA-sequencing (scRNA-seq) is a powerful technique to unravel cellular/molecular mechanisms governing VAPA- pathogenesis, which will be used on broncho-alveolar lavage fluid and post-mortem biopsies of severe influenza and COVID-19 patients with or without VAPA. We will analyze data of a prospective international multicenter trial on IAPA. Expected outcome: New insights in VAPA- pathogenesis, with identification of diagnostic/prognostic biomarkers and potential immunomodulatory therapeutical targets. Generation of prospective data on IAPA epidemiology and clinical risk factors, allowing identification of patients-at-risk for development of IAPA. Institution KU Leuven 1. General Information Name applicant Simon Feys FWO Project Number & Title 11M6922N: Viral-associated pulmonary aspergillosis: new perspectives on the pathophysiological and clinical aspects to enable host-directed medicine Affiliation KU Leuven 2. Data description Will you generate/collect new data and/or make use of existing data? Generate new data Reuse existing data Describe in detail the origin, type and format of the data (per dataset) and its (estimated) volume. This may be easiest in a table (see example) or as a data flow and per WP or objective of the project. If you reuse existing data, specify the source of these data. Distinguish data types (the kind of content) from data formats (the technical format). Work package Type of data Format Volume How created WP1.1 SNP-results (RT- qPCR data) .xls max 100 MB SNP-analysis of blood and bronchoalveolar lavage fluid samples from patients with severe influenza or COVID-19 with or without aspergillosis. This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 1 of 10 WP1.1 Observational pseudonymized clinical patient data online eCRF format (REDcap, Castor), .xls max 20MB Observational data derived from clinical patient records in a prospective and retrospective study (Contagious, PIAS, Variomic study), used to link with SNP- analyses. WP1.2 Microscopy images .tif, .lif 100-200GB High-resolution fluorescence microscopy of zebrafish larvae infected with influenza virus, Aspergillus or both, or sham-injected. WP1.2 RT-qPCR results .xls max 10MB RT-qPCR results of zebrafish larvae infected with influenza virus. WP1.2 Observational numeric data of zebrafish larvae .xls max 10MB Observational results from zebrafish larvae experiments. WP2 scRNA- seq results .fastq and .xls +/- 550 GB (scRNA- seq from +/- 55 patients at 10 GB per patient) Results obtained from scRNA- sequencing bronchoalveolar lavage fluid of patients with severe influenza or COVID-19 with or without aspergillosis. WP2 Observational pseudonymized clinical patient data online eCRF format (REDcap), .xls max 5MB Observational data derived from clinical patient records in a prospective study (Contagious study), used to link with scRNA- seq data. WP3 Observational pseudonymized clinical patient data online eCRF format (Castor), .xls max 100MB Observational data derived from clinical patient records in a prospective study (IAPAFLU study). WP1,2,3 Informed consent form text, printed paper NA This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 2 of 10 WP1,2,3 Patient sample collection (blood, bronchoalveolar lavage fluid, nasal/oral/anal swabs) biologic samples kept at - 20°C or - 80°C NA Directly collected from the patient 3. Legal and ethical issues Will you use personal data? If so, shortly describe the kind of personal data you will use. Add the reference to your file in KU Leuven's Register of Data Processing for Research and Public Service Purposes (PRET application). Be aware that registering the fact that you process personal data is a legal obligation. Yes EC Research S-numbers: S63881, S62072, S65588, S64259 Privacy compliance S-numbers: S63381, S65588, S64259 Short description of the kind of personal data that will be used: clinical data of patients admitted to ICU with severe influenza or severe COVID-19, with or without aspergillosis. Data consists of demographic data, medical history before admission, clinical parameters and disease history at ICU admission, laboratory and radiographical parameters, and clinical outcome parameters. Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? If so, add the reference to the formal approval by the relevant ethical review committee(s) Yes EC Research S-numbers: S63881, S62072, S65588, S64259 ECD P-number: P070/2021 Does your work possibly result in research data with potential for tech transfer and valorisation? Will IP restrictions be claimed for the data you created? If so, for what data and which restrictions will be asserted? No Do existing 3rd party agreements restrict dissemination or exploitation of the data you (re)use? If so, to what data do they relate and what restrictions are in place? No 4. Documentation and metadata What documentation will be provided to enable reuse of the data collected/generated in this project? All data with relation to patients will be coded. WP1.1: The information contains the date the SNP-analysis was performed, the study design, methodology, the protocol (or a link to the protocol), reagents, and sampling. The lab notebooks also contain links to the electronic files that contain the raw data, the processed results or other relevant data. Encoded patient data is stored in Redcap or in Castor eCRFs and in excel exports of these data. WP1.2: The information contains the date the experiment was performed, the study design, methodology, the protocol (or a link to the protocol), reagents, and sampling. The lab notebooks also contain links to the electronic files that contain the raw data (e.g. of RT-qPCR …), the processed results or other relevant data. Protocols are digitally available in Word documents and research results are available in Excel documents collected in specific folders. Data files will be logically grouped in folders (according to sub-parts of the project). The description of the experiments will contain all information such that another analyst or scientist can repeat the experiments. WP2: This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 3 of 10 Documentation will consist of notes in the Electronic Laboratory Notebook that refers to specific datasets. These notes will describe the biological/clinical samples used, experimental setup and protocols used, sequences generated, links to the specific computer location and the specific names of the respective datasets. Metadata sheets are maintained with the connection between lab samples, sample IDs and files in the data storage so that lab samples, data files and experimental notes remain properly linked to the corresponding samples IDs. Research methods and practices (SOPs) are fully documented. When wet lab techniques, scripts, algorithms and software tools are finalized, they are additionally described in manuscripts and/or on GitHub. Raw sequencing data (.fastq files; each named with corresponding sampleID) is collected per sequencing run, including an .xlsx file with the sample sheet information containing the sample IDs sequenced in that run and the sequencing run information per sample ID (Illumina sequencer, lane and index information). The name of the folder will contain the date of the sequencing run and the Illumina sequencer used. When data are published, raw and processed sequencing data will be uploaded on a public repository (e.g. EGA) with appropriate access control if required, to enable sharing and long-term validity of the data. WP3: Data generated in this work package is managed by Radboudumc as part of the H2020 project HDM-FUN. In line with Radboudumc policy, (meta)data that are suitable for reuse will be available to other researchers upon request using the DANS EASY repository that is certified (CoreTrustSeal/ nestor Seal 2016). DANS uses Digital Object Identifiers (DOIs). Each dataset stored in EASY has a unique DOI, and new datasets are automatically assigned a DOI upon deposition. You can use this DOI when citing the associated dataset. Each dataset also contains a set of instructions in “Cite as” format to facilitate data citation by secondary users using the DOI. The deposit in the DANS EASY archive contains metadata from the Dublin Core standard, enriched with DataCite metadata fields. The metadata fields in DANS comply with the guidelines of the Dublin Core standard/DataCite and include keywords. Any transformations, restructuring and analysis are performed through scripts/syntax files and/or documentation. Version control will be applied that tracks changes in documents, files, syntaxes. Data will be collected using Castor-EDC. This is a GCP-compliant EDC. Castor-EDC also enables data managers to add metadata to fields. To make the data Interoperable standard data names and types (ontology) will be used, such as SNOMED, MedDRA. When research data is completed and ready for storage, it will be uploaded to partners institutional repository or to Zenodo (https://www.zenodo.org/), when a partner has not access to an institutional repository. A DOI will be assigned to datasets for effective and persistent citation when uploaded in a repository. This DOI can be used in any relevant publications to direct readers to the underlying dataset. Data from each experiment is saved in a word or excel file and each word or excel file is recorded in a spreadsheet with the date and title of experiment. Search keywords will be provided when the dataset is uploaded to the institutional repository and/or to Zenodo which will optimise possibilities for re-used. Will a metadata standard be used? If so, describe in detail which standard will be used. If no, state in detail which metadata will be created to make the data easy/easier to find and reuse. Yes No WP1.1: Metadata from SNP-analyses (performed in a RT-qPCR-system) are inherently stored in exported files (including all RT-qPCR settings). WP1.2: Metadata from RT-qPCR files are inherently stored in exported files (including all RT-qPCR settings). Metadata related to microscopy images generated during the work package will be added to the title of each .lif-file and .tif image (timepoint, microscope settings, and experiment number which refers to an additional file containing experiment metadata), but most metadata are also inherently stored in the files created by the instrument (.lif). WP2: Sequencing data types require specific metadata when submitted to public repositories such as EGA, ArrayExpress, GEO or ENA. Data documentation will be tailored to their ultimate deposition in public repositories, with spreadsheet headers corresponding to fields required by This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 4 of 10 these public repositories. Technical and analytical methods used to generate the data will be documented in sufficient detail to allow for independent reproduction. These will include analysis package version numbers, analysis kit, disease status, treatment type and duration, organism, genome build…. For single-cell experiments, each droplet barcode will also be retained alongside the associated single-cell quality metrics. When depositing data in a repository, the final dataset will be accompanied by this information in the file format that the repository provides. This will allow the data to be understood by other members of the laboratory and add context to the dataset for future reuse. WP3: The deposit in the DANS EASY archive contains metadata from the Dublin Core standard, enriched with DataCite metadata fields. The metadata fields in DANS comply with the guidelines of the Dublin Core standard/DataCite and include keywords. Any transformations, restructuring and analysis are performed through scripts/syntax files and/or documentation. Version control will be applied that tracks changes in documents, files, syntaxes. Data will be collected using Castor-EDC. This is a GCP-compliant EDC. Castor-EDC also enables data managers to add metadata to fields. To make the data Interoperable standard data names and types (ontology) will be used, such as SNOMED, MedDRA. For labdata this is LOINC. When research data is completed and ready for storage, it will be uploaded to partners institutional repository or to Zenodo (https://www.zenodo.org/), when a partner has not access to an institutional repository. A DOI will be assigned to datasets for effective and persistent citation when uploaded in a repository. This DOI can be used in any relevant publications to direct readers to the underlying dataset. Data from each experiment is saved in a word or excel file and each word or excel file is recorded in a spreadsheet with the date and title of experiment. HDM-FUN naming convention for project datasets will comprise the following: A unique chronological number of the datasets The title of the dataset Each new version of a dataset will be named with a version number (e.g., v1.0, v1.1, v1.2 etc) A prefix “HDM-FUN” indicating a project dataset A unique identifier number linking with the dataset WP and deliverable (e.g., WP1_D1.1”) Example: 01_ TITLE OF DATASET _v1.0_HDM-FUN_WP1_D1.1.xlsx Search keywords will be provided when the dataset is uploaded to the institutional repository and/or to Zenodo which will optimise possibilities for re-use. 5. Data storage and backup during the FWO project Where will the data be stored? Electronic data The electronic data generated during the SNP work package (WP1.1) will be stored in secured, password-protected and back-up servers of UZ Leuven. All electronical data collected and generated during the scRNA-seq work package (WP2) and the zebrafish work package (WP1.2) will be processed and (temporarily) stored on secured, password-protected and backed up servers of VIB-KU Leuven and KU Leuven respectively (managed by ICT of the Biomedical Sciences Group). The sequencing data generated during the scRNA-seq work package (WP2) will either be stored on VIB-KU Leuven servers or on the Flemish Supercomputer Centre (VSC), initially in the staging and archive area, and later only in the archive area (archive is mirrored). The electronic data generated during the observational study work package (WP3) will be stored centrally at Radboudumc (Nijmegen, the Netherlands) as Radboudumc is the sponsor of this study, in Digital Research Environment (DRE), which is a cloud-based dedicated and secure workspace. The DRE consists of workspaces, from within tools can be used which enable us to import, merge, optimize, store, analyze, archive and share clinical and research data. Each workspace is completely secure and fully scalable. DRE provides the necessary security, ICT infrastructure and compliance with international laws and regulations. Samples For the SNP work package (WP1.1), all patient samples will be stored in UZ Leuven in labeled tubes in -20°C or -80°C freezers purchased by own funding. The samples will be registered and handled according to the UZ Leuven Biobank guidelines. For the zebrafish work package (WP1.2), all samples generated during experiments will be stored This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 5 of 10 in labeled tubes in the Rega Institute (KU Leuven) in -20°C or -80°C freezers purchased by own funding.Samples will be registered in the FreezerPro (the sample handling system of the Rega Institute). For the scRNA-seq work package (WP2), all patient samples, ˜single-cell suspensions and sequence library preparations will be stored in labeled tubes or SBS plates in -20°C or -80°C freezers purchased by our own funding. The samples will be registered and handled according to the UZ Leuven Biobank guidelines. For the observational study work package (WP3), all patient samples are sent to the biobank of Radboudumc Nijmegen for centrally-managed storage. How is backup of the data provided? KU/UZ Leuven drives are backed-up automatically on a daily basis using KU/UZ Leuven services. Radboudumc drives are backed-up automatically. All sequencing data stored on the Flemish Supercomputer Centre (VSC) will be regularly transferred to the archive area that is mirrored. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. If no or insufficient storage or backup capacities are available then explain how this will be taken care of. Yes There is sufficient storage and back-up capacity on all described servers. For VIB/KU Leuven servers (which will hold the majority of data in this project) specifically: - The “L-drive” is an easily scalable system, built from General Parallel File System (GPFS) cluster with NetApp eseries storage systems, and a CTDB samba cluster in the front-end. - The “J-drive” is based on a cluster of NetApp FAS8040 controllers with an Ontap 9.1P9 operating system. - The Staging and Archive on VSC are also sufficiently scalable (petabyte scale) What are the expected costs for data storage and back up during the project? How will these costs be covered? The total estimated cost of data storage during the 4 years of this FWO project is +/-1100 EUR. This estimation is based on the following costs: The costs of digital data storage are as follows: €868,9/5 TB/Year for the “L-drive” and €519/TB/Year for the “J-drive”. The cost of VSC archive is €70/TB/Year, and staging €130/TB/Year. We expect costs to drop slightly during the coming four years. For the observational study with data storage by Radboudumc Nijmegen in the Castor environment, no budgeting is necessary as this is a free service by the Radboudumc Nijmegen. All costs for data storage will be covered by own funding. Data security: how will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? Observational clinical patient information as well as sequencing data and associated pseudonymized patient/clinical information is considered sensitive information and will be handled as such. The data generated in this project will be processed and stored on the VIB-KU Leuven and UZ Leuven IT infrastructure or Radboudumc/Castor infrastructure which are protected by a genuine user authentication system relying on username and password. Access to the data as well as the access level will be limited on a project need and individual basis. Only the researchers working on the project have access to these data. Due to the sample labelling as protective measure, the researchers are not able to decipher the identity of the donor. No personal data will be stored on the VSC nor local drives, except for the nucleic acid sequences. The coding key to patient information of linked pseudonymized data does not carry any personal identifiers and all records containing the identity of each participant will be kept private and confidential. The coding key will be kept by the PI, ICU physician prof. dr. Joost Wauters. 6. Data preservation after the FWO project This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 6 of 10 Which data will be retained for the expected 5 year period after the end of the project? In case only a selection of the data can/will be preserved, clearly state the reasons for this (legal or contractual restrictions, physical preservation issues, ...). All electronical data collected in the two first work packages of this FWO project will be retained for the expected 5 year period after the end of the project. All (remaining) biological samples are preserved for 50 years, in accordance with the guidelines of Biobank UZ/KU Leuven. All samples taken during the observational study will be stored in the Radboudumc biobank for a minimum of 10 years after end of the study. Where will the data be archived (= stored for the longer term)? As a general rule, datasets will be made openly accessible, whenever possible via existing platforms that support FAIR data sharing ( www.fairsharing.org ), at the latest at the time of publication. Long term storage will be ensured as follows for the first two work packages: Large sequencing data will be stored on VSC archive Small digital files, including TIFF files, will be stored on the “L-drive”. Developed algorithms and software will be stored on VSC archive and/or L-drive, as well on public repositories such as Github.com For the third work package: all data will be archived by Radboudumc Nijmegen in the Znodo data sharing repository. All biological samples obtained during the first two work packages are registered and stored at the Biobank UZ/KU Leuven, in accordance with their guidelines. All samples taken during the observational study will be stored in the Radboudumc biobank for a minimum of 10 years after end of the study. What are the expected costs for data preservation during the retention period of 5 years? How will the costs be covered? The total estimated cost of data storage for 5 years after the end of the project is +/- €700 (main costs approximately 200GB on KU Leuven L-drive and approximately 550GB on VSC). All costs for data preservation will be covered by our own funding. 7. Data sharing and reuse Are there any factors restricting or preventing the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions)? No Which data will be made available after the end of the project? WP1: Data resulting in publication will be made available as required, other data upon reasonable request. WP2: The promotor (and co-promotors) of this project are committed to publishing scientific research in order to communicate results both to peers and a wider audience. All research outputs supporting publications will be made openly accessible, at the latest, at the time of publication (or preprint deposition) via the required link in the publication or upon reasonable request and after an embargo period after publication. Data that will be made available include: Double-coded raw sequencing data. Personal data will be double coded and no reference to subject name will be made. Scripts, algorithms and software tools. Results will be published as Open Access in peer reviewed journal. Upon reasonable request, scRNA-seq data will be reused by transfer through Belnet Filesender or secure copy. WP3: Data will be shared through Zenodo. Where/how will the data be made available for reuse? This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 7 of 10 In an Open Access repository Other (specify): WP1 Whenever possible, datasets and appropriate metadata will be made publicly available through repositories that support FAIR data sharing. Personal data will be double coded and no reference to subject name will be made. Data will be made available upon reasonable request by e-mail. WP2: Whenever possible, datasets and appropriate metadata will be made publicly available through repositories that support FAIR data sharing. Personal data will be double coded and no reference to subject name will be made. Sharing policies for specific research outputs are detailed below: Double-coded raw sequencing data (linked to double-coded patient data) will be deposited in open access repositories with restricted access control such as the EBI European Genome-phenome Archive (EGA). The EGA is a repository for personally identifiable genetic and phenotypic data. Sequencing data at EGA will only be available upon reasonable request via our institutional data access committee and if necessary a material transfer agreement will be concluded with the beneficiaries in order to describe the types of reuse that are permitted. The double-coded read count data matrix (linked to double-coded patient data) will be available on an interactive webserver ( http://blueprint.lambrechtslab.org ). Double-coded patient data: Upon publication, all double-coded patient details supporting a manuscript will be made publicly available as supplemental information. Research documentation: All protocols used to generate published data will be described in the corresponding manuscript(s), and the related documentation will be included as supplementary information. These data and all other documents (raw data) deposited in the E-Notebook are accessible to the PI and the research staff, and will be made available upon request. Manuscripts: All scientific publications will be shared openly. For the scRNA-seq work package, at the time of publication, research results will be summarized on the co-promoters’ websites ( https://gbiomed.kuleuven.be/english/research/50488876 , https://www.vibcancer.be/diether-lambrechts ) and post-print pdf versions of publications will be made available there if allowed by copyright agreements, possibly after an embargo as determined by the publisher. Before the end of the embargo or in cases where sharing the post- print is not allowed due to copyright agreements, a pre-print version of the manuscript will be made available. (Pre-print) publications will also be automatically added to our institutional repository, Lirias 2.0, based on the authors name and ORCID ID. Algorithms, scripts and software: All the relevant algorithms, scripts and software toosls driving the project will be described in manuscripts and/or on GitHub ( https://github.com ). Data that do not support publication will be either deposited in an open access repository or made available upon request by email. Data will be reused by transfer via Belnet Filesender or secure copy. WP3: Data will be shared through Zenodo. When will the data be made available? Upon publication of the research results All research outputs will be made openly accessible, at the latest, at the time of publication (or preprint deposition). No embargo will be foreseen unless imposed e.g. by pending publications, potential IP requirements – note that patent application filing will be planned so that publications need not be delayed. Who will be able to access the data and under what conditions? WP1: Data will be available on demand. Access will be considered upon reasonable request. WP2: Whenever possible, datasets and the appropriate metadata will be made publicly available This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 8 of 10 through repositories that support FAIR data sharing. As detailed above, metadata will contain sufficient information to support data interpretation and reuse, and will be conform to community norms. These repositories clearly describe their conditions of use (typically under a Creative Commons CC0 1.0 Universal (CC0 1.0) Public Domain Dedication or an ODC Public Domain Dedication and Licence, with a material transfer agreement when applicable). Interested parties will thereby be allowed to access data directly, and they will give credit to the authors for the data used by citing the corresponding DOI. A CC-BY license will be opted for when possible. For data shared directly by the PI (and approval of the 3 rd party if necessary), a material transfer agreement (and a non-disclosure agreement if applicable) will be concluded with the beneficiaries in order to clearly describe the types of reuse that are permitted. For KU Leuven data submitted to the EBI European Genome-phenome Archive (EGA), which operates under controlled access, the data access/submission requests will be received by the Genomics Data Access Committee (DAC) of KU Leuven ( https://homes.esat.kuleuven.be/~bioiuser/dac/ ) and processed in consultation with the copromotors produced data. The DAC will provide general guidance in terms of policies and will be referred to in handling controversial cases. WP3: The dataset will be uploaded in a cvs format in Zenodo as an open access dataset under a CC-BY license. Therefore, it will be available to anyone for any purpose, provided that they give appropriate credit to the creators. What are the expected costs for data sharing? How will the costs be covered? It is the intention to minimize data management costs by implementing standard operating procedures (SOPs) e.g. for metadata collection and file storage and organization from the start of the project, and by using free-to-use data repositories and dissemination facilities whenever possible. All data management costs will be covered by own funding. 8. Responsibilities Who will be responsible for data documentation & metadata? (Meta)data will be documented by the research and technical staff at the time of data collection and analysis, by taking careful notes in the E-notebook that refer to specific datasets. The staff includes the PhD students and study nurses involved in the SNP-project (WP1.1); the PhD student(s), master thesis students, lab assistants involved in the zebrafish project (WP1.2); PhD student(s), technical assistants and bio-informaticians directly involved with the scRNA-seq research project (WP2); myself, study nurses and promotor involved in the clinical observational trial (WP3). Who will be responsible for data storage & back up during the project? The staff will ensure data storage and back up, with support from ICTS, gbiomed-IT staff, and UZ- IT staff. For WP3, Radboudumc is responsible for data storage and back-up. More specifically for the scRNA-seq work package, Gino Philips, a junior computer scientist will handle storage and back-up of the sequencing data, under supervision of senior computer scientist Bram Boeckx who has extensive experience in data handling and use of the Flemish Super Computer (VSC) environment. Final responsibility for data storage & back-up lies with promotor and co-promotors of this project, supported by ICTS, HPC, gbiomed-IT staff and UZ-IT staff. For WP3, final responsibility lies with the promotor and with prof. Frank Van De Veerdonk (Radboudumc). Who will be responsible for ensuring data preservation and reuse ? The staff will ensure data storage and back up, with support from ICTS, gbiomed-IT staff, and UZ- IT staff. For WP3, Radboudumc is responsible for data storage and back-up. More specifically for the scRNA-seq work package, Gino Philips, a junior computer scientist will handle storage and back-up of the sequencing data, under supervision of senior computer scientist Bram Boeckx who has extensive experience in data handling and use of the Flemish Super Computer (VSC) environment. Final responsibility for data storage & back-up lies with promotor and co-promotors of this project, supported by ICTS, HPC, gbiomed-IT staff and UZ-IT staff. For WP3, final responsibility This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 9 of 10 lies with the promotor and with prof. Frank Van De Veerdonk (Radboudumc). Who bears the end responsibility for updating & implementing this DMP? The PI bears the end responsibility of updating & implementing this DMP. This document was generated by DMPonline (http://dmponline.dcc.ac.uk) 10 of 10"
}