{
    "document_id": "D-2024-2946",
    "LinkTitle": "D-2024-2946",
    "file_name": "D-2024-2946.pdf",
    "file_path": "/Users/JADEPOTTER5/Downloads/DMP-MT/processed_data/pdfs_new/org_pdfs/D-2024-2946.pdf",
    "metadata": {
        "title": "SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time",
        "author": "N/A",
        "num_pages": 13
    },
    "content": {
        "full_text": "SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nA Data Management Plan created using DMPonline.be\nCreators: \nCreators: \nLars Borm, n.n. n.n.\nAffiliation: \nAffiliation: \nKU Leuven (KUL)\nFunder: \nFunder: \nFonds voor Wetenschappelijk Onderzoek - Research Foundation Flanders (FWO)\nTemplate: \nTemplate: \nFWO DMP (Flemish Standard DMP)\nPrincipal Investigator:\nPrincipal Investigator:\n \nn.n. n.n.\nData Manager:\nData Manager:\n \nLars Borm\nGrant number / URL: \nGrant number / URL: \nBIO1-G044124N\nID: \nID: \n204765\nStart date: \nStart date: \n01-01-2024\nEnd date: \nEnd date: \n31-12-2027\nProject abstract:\nProject abstract:\nTracking and understanding cellular differentiation during the development of a multicellular organism at single-cell resolution is a long-standing\nchallenge in biology. While single-cell multi-omics, combined with genomic sequence analysis, provides a powerful means to infer gene regulatory\nnetworks for a specific tissue, or for a specific time point (i.e., a snapshot), such approaches are limited in throughput and lack the power to reconstruct\ndynamic cell lineages. To address this, we will develop and apply high-throughput spatial transcriptomics technologies that allow tracking cellular\nlineages during development. We will implement a new version of the EEL method (Borm et al., Nat Biotech 2022), which provides large-scale, low-\ncost, and single-cell resolution measurements of gene expression for 500-1000 genes simultaneously. We will apply this approach to generate a\ncomprehensive spatial atlas of Drosophila melanogaster, from the egg to the adult, covering each developmental state, of all cell types in the animal.\nBy integrating this 3D transcriptome atlas with pre-existing single-cell multi-omics data, we will reconstruct spatially-controlled trajectories for each\ncell type. By exploiting the integrated chromatin accessibility data and the underlying genome sequence, we will develop deep learning models that\npredict chromatin accessibility and gene expression from the genome sequence, across time and space.\nLast modified: \nLast modified: \n30-05-2024\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n1 of 13\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nDPIA\nDPIA\nDPIA\nDPIA\nHave you performed a DPIA for the personal data processing activities for this project?\nHave you performed a DPIA for the personal data processing activities for this project?\nQuestion not answered.\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n2 of 13\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nGDPR\nGDPR\nGDPR\nGDPR\nHave you registered personal data processing activities for this project?\nHave you registered personal data processing activities for this project?\nQuestion not answered.\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n3 of 13\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nApplication DMP\nApplication DMP\nQuestionnaire\nQuestionnaire\nDescribe the datatypes (surveys, sequences, manuscripts, objects … ) the research will collect and/or generate and /or (re)use. (use up to 700\nDescribe the datatypes (surveys, sequences, manuscripts, objects … ) the research will collect and/or generate and /or (re)use. (use up to 700\ncharacters)\ncharacters)\nQuestion not answered.\nSpecify in which way the following provisions are in place in order to preserve the data during and at least 5 years after the end of the research?\nSpecify in which way the following provisions are in place in order to preserve the data during and at least 5 years after the end of the research?\nMotivate your answer. (use up to 700 characters)\nMotivate your answer. (use up to 700 characters)\nQuestion not answered.\nWhat’s the reason why you wish to deviate from the principle of preservation of data and of the minimum preservation term of 5 years? (max.\nWhat’s the reason why you wish to deviate from the principle of preservation of data and of the minimum preservation term of 5 years? (max.\n700 characters)\n700 characters)\nQuestion not answered.\nAre there issues concerning research data indicated in the ethics questionnaire of this application form? Which specific security measures do\nAre there issues concerning research data indicated in the ethics questionnaire of this application form? Which specific security measures do\nthose data require? (use up to 700 characters)\nthose data require? (use up to 700 characters)\nQuestion not answered.\nWhich other issues related to the data management are relevant to mention? (use up to 700 characters)\nWhich other issues related to the data management are relevant to mention? (use up to 700 characters)\nQuestion not answered.\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n4 of 13\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nSpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time\nFWO DMP (Flemish Standard DMP)\nFWO DMP (Flemish Standard DMP)\n1. Research Data Summary\n1. Research Data Summary\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or\nList and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or\ndata type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate\ndata type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate\nwhether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its\nwhether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its\ntechnical format (file extension), and an estimate of the upper limit of the volume of the data.\ntechnical format (file extension), and an estimate of the upper limit of the volume of the data.\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n5 of 13\n \n \n \n \nOnly for\ndigital data\nOnly for\ndigital data \nOnly for\ndigital data \nOnly for\nphysical\ndata\nDataset Name\nDescription\nNew or reused\nDigital\nor\nPhysical\nDigital Data\nType\nDigital Data\nformat\nDigital data\nvolume\n(MB/GB/TB)\nPhysical\nvolume\nAim 1.4\nImage analysis\ncode\nCode to analyse the raw imaging\ndata. \nreused\nDigital\nSoftware\n.py\n< 100MB\n \nAim 2.1\nRaw imaging\ndata of\nmultiplexed\nsmFISH\nRaw imaing data of multiplexed\nsmFISH. Per sample there will\nbe a image for each decoding\ncycle and color channel. 132\nexperiments are planned. Which\nwill have 13 cycles in 3 color\nchannels: 33 files per\nexperiment. \nNew\nDigital\nExperimental\nOriginal\nfiles will be\nNikon .nd2\nfiles which\nwill be\ncompressed\nto ZARR\nwith\nmetadata\n>50TB\nExpected\n260TB after\ncompression.\n \nAim 2.1\nImaging\nmetadata\nImaging specific metadata linked\nto the images mentioned above.\nNew\nDigital\nExperimental\n.yaml and/or\nincorporated\ninto ZARR\n<100MB\n \nAim 2.1\nLog files\nLog files of wetlab experiment\nNew\nDigital\nExperimental\n.log\n<100MB\n \nAim 2.1\nRNA locations\nExtracted locations (XYZ) and\ngene identity of all detected\nRNA molecules\nNew\nDigital\nDerived and\ncompiled\ndata\n.parquet\n<5TB\n \nAim 2.1\nCell by Gene\nexpression\nmatrix with\nmetadata.\nTabular data with gene\nexpression for each cells. Also\ncontains metadata: Location, cell\ntype, annotation, sample, age.\nNew \nDigital \nDerived and\ncompiled\ndata\n.h3ad \n<5TB \n \nAim 2.2\nCellular\nlineages\nConnections between cells as\nsparse matrix.\nNew\nDigital \nDerived and\ncompiled\ndata\nSparse\nmatrix\nformat\n<100MB\n \nAim 2.3-4\nGene\nexpression\nmaps\nImages of gene expression for\nothers to browse on website. \nNew\nDigital\nDerived and\ncompiled\ndata\n.png, .http\n< 100GB\n \nAim 3\nData\nintegration\nIntegration with excisting single\ncell RNA and ATAC sequencing\ndata (own and public)\nreused\nDigital\nDerived and\ncompiled\ndata\n \n \n \nAim 3.1\neGRN\ninference\nSCENIC+ inference of gene\nregulatory networks\nNew\nDigital \nDerived and\ncompiled\ndata\n \n \n \nAim 3.2\nEnhancer\nactivity over\ntime\nConvolutional Neural Network\nto identify enhancers driving\ndifferentiation in time\nNew\nDigital\nDerived and\ncompiled\ndata\n \n \n \nAim 3.3\nDeepSCENIC-\nST\nExtend DeepSCENIC with time\nand space. \nNew\nDigital\nDerived and\ncompiled\ndata\n.py\n<100MB\n \nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data\nIf you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data\ntype:\ntype:\nOwn\nOwn\n datasets/tools\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n6 of 13\nAim\nAim\nDataset/tool\nDataset/tool\nSource\nSource\nAim 1\npysmFISH\nhttps://github.com/linnarsson-lab/pysmFISH_auto/tree/master/pysmFISH\nAim 3\nDrosophila single cell RNA- and ATAC-seq data.\nPublished:\nFCA: DOI 10.1126/science.abk2432\nBrain: DOI 10.1038/s41586-021-04262-z\nEye antennal disk: DOI 10.15252/msb.20209438\nAlso unpublished datasets, generated in-house.\nAim 3.1\nSCENIC+\nDOI 10.1038/s41592-023-01938-4\nAim 3.2-3\nDeepSCENIC\nUnpublished, generated in house. \n \nExternal\nExternal\n datasets/tools\nAim\nAim\nDataset/tool\nDataset/tool\nSource\nSource\nAim 3\nTangram\nDOI: 10.1038/s41592-021-01264-7 \nAim3\nDrosophila single cell RNA- and ATAC-seq data.\nembryo and larva: DOI 10.1101/2024.02.06.577903\nEmbryo: https://doi.org/10.1038/nature25981\n \nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? Describe these\nAre there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? Describe these\nissues in the comment section. Please refer to specific datasets or data types when appropriate.\nissues in the comment section. Please refer to specific datasets or data types when appropriate.\nNo\nThe project is on Drosophila melanogaster.\nWill you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer to specific\nWill you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer to specific\ndatasets or data types when appropriate.\ndatasets or data types when appropriate.\nNo\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so,\nDoes your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so,\nplease comment per dataset or data type where appropriate.\nplease comment per dataset or data type where appropriate.\nYes\nAim1 \nDeveloping the wet-lab chemistry to do multiplexed smFISH detection in Drosophila may have patentable parts. However, this space is very\ncrowded so this would only be applicable if there is a major advance over existing protocols/products. \nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer agreements/ research\nDo existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer agreements/ research\ncollaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place.\ncollaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place.\nNo\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please\nAre there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please\nexplain in the comment section to what data they relate and which restrictions will be asserted.\nexplain in the comment section to what data they relate and which restrictions will be asserted.\nNo\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n7 of 13\n2. Documentation and Metadata\n2. Documentation and Metadata\nClearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable and usable,\nClearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable and usable,\nfor yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures used, Electronic Lab\nfor yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures used, Electronic Lab\nNotebooks, README.txt files, Codebook.tsv etc. where this information is recorded).\nNotebooks, README.txt files, Codebook.tsv etc. where this information is recorded).\nAll experiments will get a unique experiment identification number. This ID number will be linked to all instances of the data. Either in the file\nname or in the folder name.\nThe ID has the format of <Initials>EXPYYYYMMDD_<topic>\nLike: LBEXP20240417_Mouse_brain_section_3\nThe data generation is automated by a home-build robot. This machine performs detailed logging of each automated step of the experiment.\nFurthermore, any manual procedures will be written to the same log file by the user. The log file will also contain all associated metadata of\nthe sample (age, sex, strain, sectioning method etc.). The completed log file will be uploaded to the ELN, and will travel with the raw and\nprocessed data. Any downstream processing will be added to the ELN and to log files with the raw/processed data.\nThe robot also makes an experiment sumary that is easier to read than the log file (but all information is also in the log file). This file has the\nname: <Experimental ID>_config.yaml and is in the yaml format. \nThis file contains:\nAge: #Age of sample\nBarcode: #True if barcoded\nBarcode_length: #Barcode length\nChamber_EXP: #Flow cells\nChemistry: #Name of experimental method\nCodebooks: #Gene decoding codebooks\n  Codebook_Atto425: None\n  Codebook_Cy3: codebookHG2_20210508.parquet\n  Codebook_Cy5: gene_hGBM20201124.parquet\n  Codebook_Cy7: None\n  Codebook_DAPI: None\n  Codebook_Europium: None\n  Codebook_FITC: None\n  Codebook_TxRed: None\nDescription: #One sentence description of experiment\nEXP_name: #Experiment ID\nExperiment_type: #Type of experiment\nHeatshock_temperature: #Temperature\nHyb_time_1_A: #Time\nHyb_time_1_B: None\nHyb_time_1_C: None\nHyb_time_2_A: None\nHyb_time_2_B: None\nHyb_time_2_C: None\nHybmix_volume: #Volume\nImaging_temperature: #Temperature\nMachine: #Microscope ID\nMulticolor_barcode: #True if multicolor barcode\nOperator: #Name of operator\nOrientation: #Orientation of sample\nOverlapping_percentage: #Percentage of overlap\nPipeline: #Image analysis pipeline\nPosition: #Positionin sample\nProbes_FASTA: #Fasta files with probe sequences\n  Probes_FASTA_Atto425: None\n  Probes_FASTA_Cy3: HG2.fasta\n  Probes_FASTA_Cy5: HG.fasta\n  Probes_FASTA_Cy7: None\n  Probes_FASTA_DAPI: None\n  Probes_FASTA_Europium: None\n  Probes_FASTA_FITC: None\n  Probes_FASTA_TxRed: None\nProgram: #Program\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n8 of 13\nProtocols_io: #Link to protocol\nReadout_temperature: #Temperature\nRegionImaged: #Name of anatomical region\nSample: #Sample ID\nSectionID: #Section ID\nSpecies: #Species\nStaining_temperature: #Temperature\nStart_date: #Date YYYYMMDD\nStitchingChannel: #Channel name\nStitching_type: #Stitching method\nStrain: #Sample strain\nStripping_temperature: #Temperature\nTarget_cycles: #Nubmer of cycles\nTissue: #Tissue type\nroi: #field of view numbers.\n \n \nTo allow long term access and use of research data will be stored or converted to open file formats as much as possible.\n• Containers: TAR, ZIP \n• databases: XML, CSV, JSON\n• Statistics: DTA, POR, SAS, SAV \n• Images: ZARR, TIFF, JPEG 2000, PNG, GIF \n• Tabular data: CSV, TXT, H5\n• Text: XML, PDF/A, HTML, JSON, TXT, RTF, YAML\n• Sequencing data: FASTA, FASTQ\nWe use controlled vocabularies or ontologies when applicable to provide unambiguous meaning, for example:\n• Gene Onotology: molecular function, cellular component, and biological role of RNA seq\n• ENSEMBL or NBCI identifiers: gene identity \n• HUGO Gene Nomenclature Committee: names and symbol of human genes\n• Mouse Genome Informatics: names and symbol of mouse genes\n• FlyBase: names and symbol of Drosophila genes\n• Chicken Gene Nomenclature Committee: names and symbol of chicken genes\n• UniProt protein accessions: protein identity\nWill a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per dataset or data type)\nWill a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per dataset or data type)\nwhich metadata standard will be used. If not, please specify (where appropriate per dataset or data type) which metadata will be created to\nwhich metadata standard will be used. If not, please specify (where appropriate per dataset or data type) which metadata will be created to\nmake the data easier to find and reuse.\nmake the data easier to find and reuse.\nYes\nMetadata will be documented by the research and technical staff at the time of data collection and analysis, by taking careful notes in the\nelectronic laboratory notebook (E-notebook) and/or in hard copy lab notebooks that refer to specific datasets. All datasets will be accompanied\nby a log file that contains all metadata and experimental procedures to generate the data. Also see the information above. \nSpecific cases:\nFor final versions of the cell by gene matrix, we will adhere to the metadata standard of https://cellxgene.cziscience.com/. \nUnfortunately, there are no metadata standards for the raw data of the field of spatially resolved transcriptomics. However, there are new\nprojects such as SpatialData (https://github.com/scverse/spatialdata) which have the potential to become the standard. We will closely monitor\nthese and incorporate them when applicable and mature. \n \n3. Data storage & back-up during the research project\n3. Data storage & back-up during the research project\nWhere will the data be stored?\nWhere will the data be stored?\nDigital data\nDigital data\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n9 of 13\nPrimary processing of the images will be on the VIB datacore which has secure storage. When processed, the files will be written to the\nManGO platform of KU Leuven.\nThe ManGO platform for storage and management of large volumes of active research data will be used for medium-term storage. This\nplatform allows secure storage, manual and automated metadata coupling, data workflows, and file sharing.\nKU Leuven further offers fast (\"J-drive) and slower (\"L-drive\") server storage that allows reading/writing/modification of non-\nconfidential, confidential, and strictly confidential data.\nData that is no longer active, can be archived on the KU Leuven \"K-drive\", which allows reading of non-confidential, confidential, and\nstrictly confidential data.\nAlternative cold storage will be explored provided by commercial \nNote on the large data size of the raw images:\nThe field of spatial transcriptomics is relatively young and many standards for raw-data storage are still under development. Furthermore, there\nare currently no public repositories to share this kind of data. Everyone in the field would like this but, the large data size (tens to hundreds of\nterrabytes) poses a serious chalange for storage and sharing. Even though the storage capacity of the current infrastructure available to us, is\nsufficient, this project has an exceptionally large demand for storage. Therefore we will look for ways to reduce the storage load through\ncompression, and explore alternative ways of storage of raw data, such as tape storage. Furthermore, there is also a discussion in the field if all\nthe raw data needs to be stored. These methods generate very similar imaging to Illumina DNA sequencing, and Illumina machines do not save\nthe raw images. In fact, the company 10X already discards all the raw data on their Xenium platform, and only saves the derived RNA\nlocalizations. Nevertheless, we will aim to store all the raw data because we think this is important for transparency and data sharing. But wil\nwill also monitor the developments in the field and actively contribute to the discussion on raw data storage. \n \nAlgorithms, scripts and software:\nAlgorithms, scripts and software:\nAll the relevant algorithms, scripts and software code will be stored on the lab GitHub account (https://github.com/aertslab). \nOmics data: omics data generated during the project will be stored on KU Leuven servers, VIB datacore or ManGO platform.\nPhysical samples\nPhysical samples\nFly tissue samples: Tissues will be stored locally in the laboratory. \nFly line stocks are preserved as a minimum of two separate cultures, each maintained at 18°C on a 4-to-5-week generation cycle. \nHow will the data be backed up?\nHow will the data be backed up?\nVIB Datacore drives are backed-up according to the following scheme\n- Data stored on the VIB Datacore is stored with internal redundancy and duplicated on an independent server. Snapshots are made at regular\nintervals (hourly, daily and monthly) in case data needs to be recovered. The data itself is synchronized on two separate hardware storage\nsystems, each 2 PB large. The data is protected against calamities at either site by synchronizing it in real-time at hardware level.\n \nKU Leuven drives are backed-up according to the following scheme:\n- data stored in ManGO: Snapshots are made at regular intervals (hourly, daily and monthly) in case data needs to be recovered. The data itself\nis synchronized on two separate hardware storage systems, each 6 PB large, located at Leuven and at Heverlee (ICTS). The data is protected\nagainst calamities at either site by synchronizing it in real-time at hardware level.\n- data stored on the “L-drive” is backed up daily using snapshot technology, where all incremental changes in respect of the previous version\nare kept online; the last 14 backups are kept.\n- data stored on the “J-drive” is backed up hourly, daily (every day at midnight) and weekly (at midnight between Saturday and Sunday); in\neach case the last 6 backups are kept.\n- data stored on the digital vault is backed up using snapshot technology, where all incremental changes in respect of the previous version are\nkept online. As standard, 10% of the requested storage is reserved for backups using the following backup regime: an hourly backup (at 8 a.m.,\n12 p.m., 4 p.m. and 8 p.m.), the last 6 of which are kept; a daily backup (every day) at midnight, the last 6 of which are kept; and a weekly\nbackup (every week) at midnight between Saturday and Sunday, the last 2 of which are kept.\nIs there currently sufficient storage & backup capacity during the project? If yes, specify concisely.\nIs there currently sufficient storage & backup capacity during the project? If yes, specify concisely.\nIf no or insufficient storage or backup capacities are available, then explain how this will be taken care of.\nIf no or insufficient storage or backup capacities are available, then explain how this will be taken care of.\nYes\nUnprocessed smFISH images are expected to be 4 TB per experiment and will be stored and processed via the VIB Datacore.  These images\nwill be directly compressed and they are expected to be 2 TB and are stored on the KU Leuven ManGO platform). Around 130 experiments\nare planned. Corresponding to 520 TB raw data and around 260 TB after compression.\nBoth the VIB Datacore and ManGO platform are equipped to handle and store this volume of data during this project.\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n10 of 13\nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons?\nHow will you ensure that the data are securely stored and not accessed or modified by unauthorized persons?\nThe buildings on our campus are restricted by badge system so only employees are allowed in and visitors are allowed under supervision\nafter registration.\nAccess to the “L-drive”, “J-drive”, and ManGO servers is possible only through using a KU Leuven user-id and password with two-factor\nauthentication. This only provides access to their own data, or data that was shared to them. \nAccess to the VIB Datacore servers is possible only through using a VIB user-id and password with two-factor authentication. This only\nprovides access to their own data, or data that was shared to them. \nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nWhat are the expected costs for data storage and backup during the research project? How will these costs be covered?\nThe costs of digital data storage are as follows: 569,2€/5TB/Year for the “L-drive”, 519€/TB/Year for the “J-drive”, and 35€/TB/Year for\nthe ManGO platform.\nLarge datasets (>100 GB) are stored on the ManGO platform. Total storage requirement for this project on the ManGO platform is\nexpected to be 260 TB, costing an estimated 9,100€/Year.\nData storage and backup costs are included in general lab costs.\nHowever, if we find a cheaper data storage alternative we might put the raw data there after the derivative files have been generated for the\nbiological analysis. An option would be to put the data on a \"cold storage\" platform provided by Google or Amazon, that has the lowest cost\nand is suitable for data that is not often needed. Google's lowest cost storage is 14 €/TB/Year.\n4. Data preservation after the end of the research project\n4. Data preservation after the end of the research project\nWhich data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after the end of the\nWhich data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after the end of the\nproject? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues,\nproject? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues,\ninstitutional policies...).\ninstitutional policies...).\nAccording to KU Leuven RDM policy, relevant research data will be preserved on the university's servers for a minimum of 10 years. Such\ndata include data that are at the basis of a publication, that can only be generated or collected once, that are generated as a result of a substantial\nfinancial or personal effort, or are likely to be reused within the research unit or in wider contexts.\nThis project will generate a very large raw dataset expected to be in the range of 250TB after compression. The largest portion of the dataset\nare the raw images. To save space these will be converted to the ZARR format and compressed with a lossless compression algorithm so that\nall raw data is saved. \nFurthermore, the metadata, RNA localization and cell by gene tables files will be stored. \nAny temporary derivatives of the raw data that are not the final result, will be deleted. For example, to detect objects in the images the\nbackground of the images first needs to be filtered out. These filtered images will be deleted to save space. However the stored raw data and\nthe analysis code will ensure that these can be regenerated if needed.\nRaw data of failed experiments, if any, will be deleted to save space.\nFinal machine learning models will be stored. \nWhere will these data be archived (stored and curated for the long-term)?\nWhere will these data be archived (stored and curated for the long-term)?\nAs a general rule all research outputs (data, documentation, and metadata) related to publications will be made openly accessible, whenever\npossible via existing platforms that support FAIR data sharing (www.fairsharing.org). We aim at communicating our results in top journals\nthat require full disclosure upon publication of all included data, either in the main text, in supplementary material or in a separate data\nrepository.\nOther research data will be archived on KU Leuven servers as described above.\nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\nWhat are the expected costs for data preservation during the expected retention period? How will these costs be covered?\n-The costs of digital data storage are as follows: 569,2€/5TB/Year for the \"K-drive\" and the “L-drive”, 519€/TB/Year for the “J- drive”, and\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n11 of 13\n35€/TB/Year for the ManGO platform. Data storage and backup costs are included in general lab costs.\nWe will look into cheaper storage alternative such as tape storage or other cold storage alternatives with has an estimated cost of 7\neuro/TB/year. \n5. Data sharing and reuse\n5. Data sharing and reuse\nWill the data (or part of the data) be made available for reuse after/during the project?  In the comment section please explain per dataset or\nWill the data (or part of the data) be made available for reuse after/during the project?  In the comment section please explain per dataset or\ndata type which data will be made available.\ndata type which data will be made available.\nOther, please specify:\nYes, in an Open Access repository\nFor the raw image data there are currently no open repositories that can host this kind and size of data. Therefore, the raw image data will be\navailable upon request and directly transfered. \nThe derived cell by gene matrices with their metadata will be made available in Open Access Repositories. \nIf access is restricted, please specify who will be able to access the data and under what conditions.\nIf access is restricted, please specify who will be able to access the data and under what conditions.\nNot applicable. \nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal\nAre there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal\nrestrictions)? Please explain in the comment section per dataset or data type where appropriate.\nrestrictions)? Please explain in the comment section per dataset or data type where appropriate.\nNo\nWhere will the data be made available? If already known, please provide a repository per dataset or data type.\nWhere will the data be made available? If already known, please provide a repository per dataset or data type.\nDatasets for which databases are available will be deposited there:\nThe cell by gene matrices will be shared on https://cellxgene.cziscience.com/ and potentially also on SCope.aertslab.org.\nComputational workflows, models, and metadata will be stored on platforms such as Github, Kipoi, and Zenodo with proper versioning.\nThere are currently no repositories for raw spatial imaging data that can handle the large volume of raw images. Therefore, the raw\nimages will be available upon request. Potentially, a minimal example dataset will be shared on https://idr.openmicroscopy.org/ or a\nsimilar database. If the situation changes in the future, we will upload the data to available databases. \nWhen will the data be made available?\nWhen will the data be made available?\nAll research outputs (data, documentation, code, and associated metadata) will be made openly accessible at the latest at the time of\npublication. No embargo will be foreseen unless imposed e.g. by pending publications, potential IP requirements – note that patent application\nfiling will be planned so that publications need not be delayed - or ongoing projects requiring confidential data. In those cases, datasets will be\nmade publicly available as soon as the embargo date is reached.\nWhich data usage licenses are you going to provide? If none, please explain why.\nWhich data usage licenses are you going to provide? If none, please explain why.\nData is typically available under a Creative Commons CC0 1.0 Universal (CC0 1.0) Public Domain Dedication, a Creative Commons\nAttribution (CC-BY), or an ODC Public Domain Dedication and Licence, with a material transfer agreement when applicable. Software and\ncode usually are available under a GNU General Public License or an Academic Non-commercial Software License.\nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n12 of 13\nDo you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the comment\nDo you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the comment\nsection.\nsection.\nYes\nWhat are the expected costs for data sharing? How will these costs be covered?\nWhat are the expected costs for data sharing? How will these costs be covered?\nIt is the intention to minimize data management costs by implementing standard procedures e.g. for metadata collection and file storage and\norganization from the start of the project, and by using free-to-use data repositories and dissemination facilities whenever possible. Data\nmanagement costs will be covered by the laboratory budget.\n6. Responsibilities\n6. Responsibilities\nWho will manage data documentation and metadata during the research project?\nWho will manage data documentation and metadata during the research project?\nThe researchers who generate the data are responsible for managing data, documentation, and metadata. \nWho will manage data storage and backup during the research project?\nWho will manage data storage and backup during the research project?\nThe researchers who generate the data are responsible for storage and backup, with support from René Custers and Alexander Botzki for the\nelectronic laboratory notebook (ELN) and from Raf De Coster for the KU Leuven drives. \nWho will manage data preservation and sharing?\nWho will manage data preservation and sharing?\nLars Borm and Stein Aerts are \nresponsible for data preservation and sharing, with support from the research and technical staff involved in the\nproject, from René Custers and Alexander Botzki for the electronic laboratory notebook (ELN) and from Raf De Coster for the KU Leuven\ndrives. \nWho will update and implement this DMP?\nWho will update and implement this DMP?\nLars Borm and Stein Aerts are ultimately responsible for all data management during and after data collection, including implementing and\nupdating the DMP. \nCreated using DMPonline.be. Last modiﬁed 30 May 2024\n13 of 13"
    },
    "clean_full_text": "SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time A Data Management Plan created using DMPonline.be Creators: Creators: Lars Borm, n.n. n.n. Affiliation: Affiliation: KU Leuven (KUL) Funder: Funder: Fonds voor Wetenschappelijk Onderzoek - Research Foundation Flanders (FWO) Template: Template: FWO DMP (Flemish Standard DMP) Principal Investigator: Principal Investigator: n.n. n.n. Data Manager: Data Manager: Lars Borm Grant number / URL: Grant number / URL: BIO1-G044124N ID: ID: 204765 Start date: Start date: 01-01-2024 End date: End date: 31-12-2027 Project abstract: Project abstract: Tracking and understanding cellular differentiation during the development of a multicellular organism at single-cell resolution is a long-standing challenge in biology. While single-cell multi-omics, combined with genomic sequence analysis, provides a powerful means to infer gene regulatory networks for a specific tissue, or for a specific time point (i.e., a snapshot), such approaches are limited in throughput and lack the power to reconstruct dynamic cell lineages. To address this, we will develop and apply high-throughput spatial transcriptomics technologies that allow tracking cellular lineages during development. We will implement a new version of the EEL method (Borm et al., Nat Biotech 2022), which provides large-scale, low- cost, and single-cell resolution measurements of gene expression for 500-1000 genes simultaneously. We will apply this approach to generate a comprehensive spatial atlas of Drosophila melanogaster, from the egg to the adult, covering each developmental state, of all cell types in the animal. By integrating this 3D transcriptome atlas with pre-existing single-cell multi-omics data, we will reconstruct spatially-controlled trajectories for each cell type. By exploiting the integrated chromatin accessibility data and the underlying genome sequence, we will develop deep learning models that predict chromatin accessibility and gene expression from the genome sequence, across time and space. Last modified: Last modified: 30-05-2024 Created using DMPonline.be. Last modiﬁed 30 May 2024 1 of 13 SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time DPIA DPIA DPIA DPIA Have you performed a DPIA for the personal data processing activities for this project? Have you performed a DPIA for the personal data processing activities for this project? Question not answered. Created using DMPonline.be. Last modiﬁed 30 May 2024 2 of 13 SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time GDPR GDPR GDPR GDPR Have you registered personal data processing activities for this project? Have you registered personal data processing activities for this project? Question not answered. Created using DMPonline.be. Last modiﬁed 30 May 2024 3 of 13 SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time Application DMP Application DMP Questionnaire Questionnaire Describe the datatypes (surveys, sequences, manuscripts, objects … ) the research will collect and/or generate and /or (re)use. (use up to 700 Describe the datatypes (surveys, sequences, manuscripts, objects … ) the research will collect and/or generate and /or (re)use. (use up to 700 characters) characters) Question not answered. Specify in which way the following provisions are in place in order to preserve the data during and at least 5 years after the end of the research? Specify in which way the following provisions are in place in order to preserve the data during and at least 5 years after the end of the research? Motivate your answer. (use up to 700 characters) Motivate your answer. (use up to 700 characters) Question not answered. What’s the reason why you wish to deviate from the principle of preservation of data and of the minimum preservation term of 5 years? (max. What’s the reason why you wish to deviate from the principle of preservation of data and of the minimum preservation term of 5 years? (max. 700 characters) 700 characters) Question not answered. Are there issues concerning research data indicated in the ethics questionnaire of this application form? Which specific security measures do Are there issues concerning research data indicated in the ethics questionnaire of this application form? Which specific security measures do those data require? (use up to 700 characters) those data require? (use up to 700 characters) Question not answered. Which other issues related to the data management are relevant to mention? (use up to 700 characters) Which other issues related to the data management are relevant to mention? (use up to 700 characters) Question not answered. Created using DMPonline.be. Last modiﬁed 30 May 2024 4 of 13 SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time SpaceTimeOmics: combining high-throughput spatial omics with AI to model gene regulation in space and time FWO DMP (Flemish Standard DMP) FWO DMP (Flemish Standard DMP) 1. Research Data Summary 1. Research Data Summary List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or List and describe all datasets or research materials that you plan to generate/collect or reuse during your research project. For each dataset or data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate data type (observational, experimental etc.), provide a short name & description (sufficient for yourself to know what data it is about), indicate whether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its whether the data are newly generated/collected or reused, digital or physical, also indicate the type of the data (the kind of content), its technical format (file extension), and an estimate of the upper limit of the volume of the data. technical format (file extension), and an estimate of the upper limit of the volume of the data. Created using DMPonline.be. Last modiﬁed 30 May 2024 5 of 13 Only for digital data Only for digital data Only for digital data Only for physical data Dataset Name Description New or reused Digital or Physical Digital Data Type Digital Data format Digital data volume (MB/GB/TB) Physical volume Aim 1.4 Image analysis code Code to analyse the raw imaging data. reused Digital Software .py < 100MB Aim 2.1 Raw imaging data of multiplexed smFISH Raw imaing data of multiplexed smFISH. Per sample there will be a image for each decoding cycle and color channel. 132 experiments are planned. Which will have 13 cycles in 3 color channels: 33 files per experiment. New Digital Experimental Original files will be Nikon .nd2 files which will be compressed to ZARR with metadata >50TB Expected 260TB after compression. Aim 2.1 Imaging metadata Imaging specific metadata linked to the images mentioned above. New Digital Experimental .yaml and/or incorporated into ZARR <100MB Aim 2.1 Log files Log files of wetlab experiment New Digital Experimental .log <100MB Aim 2.1 RNA locations Extracted locations (XYZ) and gene identity of all detected RNA molecules New Digital Derived and compiled data .parquet <5TB Aim 2.1 Cell by Gene expression matrix with metadata. Tabular data with gene expression for each cells. Also contains metadata: Location, cell type, annotation, sample, age. New Digital Derived and compiled data .h3ad <5TB Aim 2.2 Cellular lineages Connections between cells as sparse matrix. New Digital Derived and compiled data Sparse matrix format <100MB Aim 2.3-4 Gene expression maps Images of gene expression for others to browse on website. New Digital Derived and compiled data .png, .http < 100GB Aim 3 Data integration Integration with excisting single cell RNA and ATAC sequencing data (own and public) reused Digital Derived and compiled data Aim 3.1 eGRN inference SCENIC+ inference of gene regulatory networks New Digital Derived and compiled data Aim 3.2 Enhancer activity over time Convolutional Neural Network to identify enhancers driving differentiation in time New Digital Derived and compiled data Aim 3.3 DeepSCENIC- ST Extend DeepSCENIC with time and space. New Digital Derived and compiled data .py <100MB If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data If you reuse existing data, please specify the source, preferably by using a persistent identifier (e.g. DOI, Handle, URL etc.) per dataset or data type: type: Own Own datasets/tools Created using DMPonline.be. Last modiﬁed 30 May 2024 6 of 13 Aim Aim Dataset/tool Dataset/tool Source Source Aim 1 pysmFISH https://github.com/linnarsson-lab/pysmFISH_auto/tree/master/pysmFISH Aim 3 Drosophila single cell RNA- and ATAC-seq data. Published: FCA: DOI 10.1126/science.abk2432 Brain: DOI 10.1038/s41586-021-04262-z Eye antennal disk: DOI 10.15252/msb.20209438 Also unpublished datasets, generated in-house. Aim 3.1 SCENIC+ DOI 10.1038/s41592-023-01938-4 Aim 3.2-3 DeepSCENIC Unpublished, generated in house. External External datasets/tools Aim Aim Dataset/tool Dataset/tool Source Source Aim 3 Tangram DOI: 10.1038/s41592-021-01264-7 Aim3 Drosophila single cell RNA- and ATAC-seq data. embryo and larva: DOI 10.1101/2024.02.06.577903 Embryo: https://doi.org/10.1038/nature25981 Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? Describe these Are there any ethical issues concerning the creation and/or use of the data (e.g. experiments on humans or animals, dual use)? Describe these issues in the comment section. Please refer to specific datasets or data types when appropriate. issues in the comment section. Please refer to specific datasets or data types when appropriate. No The project is on Drosophila melanogaster. Will you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer to specific Will you process personal data? If so, briefly describe the kind of personal data you will use in the comment section. Please refer to specific datasets or data types when appropriate. datasets or data types when appropriate. No Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so, Does your work have potential for commercial valorization (e.g. tech transfer, for example spin-offs, commercial exploitation, …)? If so, please comment per dataset or data type where appropriate. please comment per dataset or data type where appropriate. Yes Aim1 Developing the wet-lab chemistry to do multiplexed smFISH detection in Drosophila may have patentable parts. However, this space is very crowded so this would only be applicable if there is a major advance over existing protocols/products. Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer agreements/ research Do existing 3rd party agreements restrict exploitation or dissemination of the data you (re)use (e.g. Material/Data transfer agreements/ research collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place. collaboration agreements)? If so, please explain in the comment section to what data they relate and what restrictions are in place. No Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please Are there any other legal issues, such as intellectual property rights and ownership, to be managed related to the data you (re)use? If so, please explain in the comment section to what data they relate and which restrictions will be asserted. explain in the comment section to what data they relate and which restrictions will be asserted. No Created using DMPonline.be. Last modiﬁed 30 May 2024 7 of 13 2. Documentation and Metadata 2. Documentation and Metadata Clearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable and usable, Clearly describe what approach will be followed to capture the accompanying information necessary to keep data understandable and usable, for yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures used, Electronic Lab for yourself and others, now and in the future (e.g., in terms of documentation levels and types required, procedures used, Electronic Lab Notebooks, README.txt files, Codebook.tsv etc. where this information is recorded). Notebooks, README.txt files, Codebook.tsv etc. where this information is recorded). All experiments will get a unique experiment identification number. This ID number will be linked to all instances of the data. Either in the file name or in the folder name. The ID has the format of <Initials>EXPYYYYMMDD_<topic> Like: LBEXP20240417_Mouse_brain_section_3 The data generation is automated by a home-build robot. This machine performs detailed logging of each automated step of the experiment. Furthermore, any manual procedures will be written to the same log file by the user. The log file will also contain all associated metadata of the sample (age, sex, strain, sectioning method etc.). The completed log file will be uploaded to the ELN, and will travel with the raw and processed data. Any downstream processing will be added to the ELN and to log files with the raw/processed data. The robot also makes an experiment sumary that is easier to read than the log file (but all information is also in the log file). This file has the name: <Experimental ID>_config.yaml and is in the yaml format. This file contains: Age: #Age of sample Barcode: #True if barcoded Barcode_length: #Barcode length Chamber_EXP: #Flow cells Chemistry: #Name of experimental method Codebooks: #Gene decoding codebooks Codebook_Atto425: None Codebook_Cy3: codebookHG2_20210508.parquet Codebook_Cy5: gene_hGBM20201124.parquet Codebook_Cy7: None Codebook_DAPI: None Codebook_Europium: None Codebook_FITC: None Codebook_TxRed: None Description: #One sentence description of experiment EXP_name: #Experiment ID Experiment_type: #Type of experiment Heatshock_temperature: #Temperature Hyb_time_1_A: #Time Hyb_time_1_B: None Hyb_time_1_C: None Hyb_time_2_A: None Hyb_time_2_B: None Hyb_time_2_C: None Hybmix_volume: #Volume Imaging_temperature: #Temperature Machine: #Microscope ID Multicolor_barcode: #True if multicolor barcode Operator: #Name of operator Orientation: #Orientation of sample Overlapping_percentage: #Percentage of overlap Pipeline: #Image analysis pipeline Position: #Positionin sample Probes_FASTA: #Fasta files with probe sequences Probes_FASTA_Atto425: None Probes_FASTA_Cy3: HG2.fasta Probes_FASTA_Cy5: HG.fasta Probes_FASTA_Cy7: None Probes_FASTA_DAPI: None Probes_FASTA_Europium: None Probes_FASTA_FITC: None Probes_FASTA_TxRed: None Program: #Program Created using DMPonline.be. Last modiﬁed 30 May 2024 8 of 13 Protocols_io: #Link to protocol Readout_temperature: #Temperature RegionImaged: #Name of anatomical region Sample: #Sample ID SectionID: #Section ID Species: #Species Staining_temperature: #Temperature Start_date: #Date YYYYMMDD StitchingChannel: #Channel name Stitching_type: #Stitching method Strain: #Sample strain Stripping_temperature: #Temperature Target_cycles: #Nubmer of cycles Tissue: #Tissue type roi: #field of view numbers. To allow long term access and use of research data will be stored or converted to open file formats as much as possible. • Containers: TAR, ZIP • databases: XML, CSV, JSON • Statistics: DTA, POR, SAS, SAV • Images: ZARR, TIFF, JPEG 2000, PNG, GIF • Tabular data: CSV, TXT, H5 • Text: XML, PDF/A, HTML, JSON, TXT, RTF, YAML • Sequencing data: FASTA, FASTQ We use controlled vocabularies or ontologies when applicable to provide unambiguous meaning, for example: • Gene Onotology: molecular function, cellular component, and biological role of RNA seq • ENSEMBL or NBCI identifiers: gene identity • HUGO Gene Nomenclature Committee: names and symbol of human genes • Mouse Genome Informatics: names and symbol of mouse genes • FlyBase: names and symbol of Drosophila genes • Chicken Gene Nomenclature Committee: names and symbol of chicken genes • UniProt protein accessions: protein identity Will a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per dataset or data type) Will a metadata standard be used to make it easier to find and reuse the data? If so, please specify (where appropriate per dataset or data type) which metadata standard will be used. If not, please specify (where appropriate per dataset or data type) which metadata will be created to which metadata standard will be used. If not, please specify (where appropriate per dataset or data type) which metadata will be created to make the data easier to find and reuse. make the data easier to find and reuse. Yes Metadata will be documented by the research and technical staff at the time of data collection and analysis, by taking careful notes in the electronic laboratory notebook (E-notebook) and/or in hard copy lab notebooks that refer to specific datasets. All datasets will be accompanied by a log file that contains all metadata and experimental procedures to generate the data. Also see the information above. Specific cases: For final versions of the cell by gene matrix, we will adhere to the metadata standard of https://cellxgene.cziscience.com/. Unfortunately, there are no metadata standards for the raw data of the field of spatially resolved transcriptomics. However, there are new projects such as SpatialData (https://github.com/scverse/spatialdata) which have the potential to become the standard. We will closely monitor these and incorporate them when applicable and mature. 3. Data storage & back-up during the research project 3. Data storage & back-up during the research project Where will the data be stored? Where will the data be stored? Digital data Digital data Created using DMPonline.be. Last modiﬁed 30 May 2024 9 of 13 Primary processing of the images will be on the VIB datacore which has secure storage. When processed, the files will be written to the ManGO platform of KU Leuven. The ManGO platform for storage and management of large volumes of active research data will be used for medium-term storage. This platform allows secure storage, manual and automated metadata coupling, data workflows, and file sharing. KU Leuven further offers fast (\"J-drive) and slower (\"L-drive\") server storage that allows reading/writing/modification of non- confidential, confidential, and strictly confidential data. Data that is no longer active, can be archived on the KU Leuven \"K-drive\", which allows reading of non-confidential, confidential, and strictly confidential data. Alternative cold storage will be explored provided by commercial Note on the large data size of the raw images: The field of spatial transcriptomics is relatively young and many standards for raw-data storage are still under development. Furthermore, there are currently no public repositories to share this kind of data. Everyone in the field would like this but, the large data size (tens to hundreds of terrabytes) poses a serious chalange for storage and sharing. Even though the storage capacity of the current infrastructure available to us, is sufficient, this project has an exceptionally large demand for storage. Therefore we will look for ways to reduce the storage load through compression, and explore alternative ways of storage of raw data, such as tape storage. Furthermore, there is also a discussion in the field if all the raw data needs to be stored. These methods generate very similar imaging to Illumina DNA sequencing, and Illumina machines do not save the raw images. In fact, the company 10X already discards all the raw data on their Xenium platform, and only saves the derived RNA localizations. Nevertheless, we will aim to store all the raw data because we think this is important for transparency and data sharing. But wil will also monitor the developments in the field and actively contribute to the discussion on raw data storage. Algorithms, scripts and software: Algorithms, scripts and software: All the relevant algorithms, scripts and software code will be stored on the lab GitHub account (https://github.com/aertslab). Omics data: omics data generated during the project will be stored on KU Leuven servers, VIB datacore or ManGO platform. Physical samples Physical samples Fly tissue samples: Tissues will be stored locally in the laboratory. Fly line stocks are preserved as a minimum of two separate cultures, each maintained at 18°C on a 4-to-5-week generation cycle. How will the data be backed up? How will the data be backed up? VIB Datacore drives are backed-up according to the following scheme - Data stored on the VIB Datacore is stored with internal redundancy and duplicated on an independent server. Snapshots are made at regular intervals (hourly, daily and monthly) in case data needs to be recovered. The data itself is synchronized on two separate hardware storage systems, each 2 PB large. The data is protected against calamities at either site by synchronizing it in real-time at hardware level. KU Leuven drives are backed-up according to the following scheme: - data stored in ManGO: Snapshots are made at regular intervals (hourly, daily and monthly) in case data needs to be recovered. The data itself is synchronized on two separate hardware storage systems, each 6 PB large, located at Leuven and at Heverlee (ICTS). The data is protected against calamities at either site by synchronizing it in real-time at hardware level. - data stored on the “L-drive” is backed up daily using snapshot technology, where all incremental changes in respect of the previous version are kept online; the last 14 backups are kept. - data stored on the “J-drive” is backed up hourly, daily (every day at midnight) and weekly (at midnight between Saturday and Sunday); in each case the last 6 backups are kept. - data stored on the digital vault is backed up using snapshot technology, where all incremental changes in respect of the previous version are kept online. As standard, 10% of the requested storage is reserved for backups using the following backup regime: an hourly backup (at 8 a.m., 12 p.m., 4 p.m. and 8 p.m.), the last 6 of which are kept; a daily backup (every day) at midnight, the last 6 of which are kept; and a weekly backup (every week) at midnight between Saturday and Sunday, the last 2 of which are kept. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. Is there currently sufficient storage & backup capacity during the project? If yes, specify concisely. If no or insufficient storage or backup capacities are available, then explain how this will be taken care of. If no or insufficient storage or backup capacities are available, then explain how this will be taken care of. Yes Unprocessed smFISH images are expected to be 4 TB per experiment and will be stored and processed via the VIB Datacore. These images will be directly compressed and they are expected to be 2 TB and are stored on the KU Leuven ManGO platform). Around 130 experiments are planned. Corresponding to 520 TB raw data and around 260 TB after compression. Both the VIB Datacore and ManGO platform are equipped to handle and store this volume of data during this project. Created using DMPonline.be. Last modiﬁed 30 May 2024 10 of 13 How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? How will you ensure that the data are securely stored and not accessed or modified by unauthorized persons? The buildings on our campus are restricted by badge system so only employees are allowed in and visitors are allowed under supervision after registration. Access to the “L-drive”, “J-drive”, and ManGO servers is possible only through using a KU Leuven user-id and password with two-factor authentication. This only provides access to their own data, or data that was shared to them. Access to the VIB Datacore servers is possible only through using a VIB user-id and password with two-factor authentication. This only provides access to their own data, or data that was shared to them. What are the expected costs for data storage and backup during the research project? How will these costs be covered? What are the expected costs for data storage and backup during the research project? How will these costs be covered? The costs of digital data storage are as follows: 569,2€/5TB/Year for the “L-drive”, 519€/TB/Year for the “J-drive”, and 35€/TB/Year for the ManGO platform. Large datasets (>100 GB) are stored on the ManGO platform. Total storage requirement for this project on the ManGO platform is expected to be 260 TB, costing an estimated 9,100€/Year. Data storage and backup costs are included in general lab costs. However, if we find a cheaper data storage alternative we might put the raw data there after the derivative files have been generated for the biological analysis. An option would be to put the data on a \"cold storage\" platform provided by Google or Amazon, that has the lowest cost and is suitable for data that is not often needed. Google's lowest cost storage is 14 €/TB/Year. 4. Data preservation after the end of the research project 4. Data preservation after the end of the research project Which data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after the end of the Which data will be retained for at least five years (or longer, in agreement with other retention policies that are applicable) after the end of the project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, project? In case some data cannot be preserved, clearly state the reasons for this (e.g. legal or contractual restrictions, storage/budget issues, institutional policies...). institutional policies...). According to KU Leuven RDM policy, relevant research data will be preserved on the university's servers for a minimum of 10 years. Such data include data that are at the basis of a publication, that can only be generated or collected once, that are generated as a result of a substantial financial or personal effort, or are likely to be reused within the research unit or in wider contexts. This project will generate a very large raw dataset expected to be in the range of 250TB after compression. The largest portion of the dataset are the raw images. To save space these will be converted to the ZARR format and compressed with a lossless compression algorithm so that all raw data is saved. Furthermore, the metadata, RNA localization and cell by gene tables files will be stored. Any temporary derivatives of the raw data that are not the final result, will be deleted. For example, to detect objects in the images the background of the images first needs to be filtered out. These filtered images will be deleted to save space. However the stored raw data and the analysis code will ensure that these can be regenerated if needed. Raw data of failed experiments, if any, will be deleted to save space. Final machine learning models will be stored. Where will these data be archived (stored and curated for the long-term)? Where will these data be archived (stored and curated for the long-term)? As a general rule all research outputs (data, documentation, and metadata) related to publications will be made openly accessible, whenever possible via existing platforms that support FAIR data sharing (www.fairsharing.org). We aim at communicating our results in top journals that require full disclosure upon publication of all included data, either in the main text, in supplementary material or in a separate data repository. Other research data will be archived on KU Leuven servers as described above. What are the expected costs for data preservation during the expected retention period? How will these costs be covered? What are the expected costs for data preservation during the expected retention period? How will these costs be covered? -The costs of digital data storage are as follows: 569,2€/5TB/Year for the \"K-drive\" and the “L-drive”, 519€/TB/Year for the “J- drive”, and Created using DMPonline.be. Last modiﬁed 30 May 2024 11 of 13 35€/TB/Year for the ManGO platform. Data storage and backup costs are included in general lab costs. We will look into cheaper storage alternative such as tape storage or other cold storage alternatives with has an estimated cost of 7 euro/TB/year. 5. Data sharing and reuse 5. Data sharing and reuse Will the data (or part of the data) be made available for reuse after/during the project? In the comment section please explain per dataset or Will the data (or part of the data) be made available for reuse after/during the project? In the comment section please explain per dataset or data type which data will be made available. data type which data will be made available. Other, please specify: Yes, in an Open Access repository For the raw image data there are currently no open repositories that can host this kind and size of data. Therefore, the raw image data will be available upon request and directly transfered. The derived cell by gene matrices with their metadata will be made available in Open Access Repositories. If access is restricted, please specify who will be able to access the data and under what conditions. If access is restricted, please specify who will be able to access the data and under what conditions. Not applicable. Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal Are there any factors that restrict or prevent the sharing of (some of) the data (e.g. as defined in an agreement with a 3rd party, legal restrictions)? Please explain in the comment section per dataset or data type where appropriate. restrictions)? Please explain in the comment section per dataset or data type where appropriate. No Where will the data be made available? If already known, please provide a repository per dataset or data type. Where will the data be made available? If already known, please provide a repository per dataset or data type. Datasets for which databases are available will be deposited there: The cell by gene matrices will be shared on https://cellxgene.cziscience.com/ and potentially also on SCope.aertslab.org. Computational workflows, models, and metadata will be stored on platforms such as Github, Kipoi, and Zenodo with proper versioning. There are currently no repositories for raw spatial imaging data that can handle the large volume of raw images. Therefore, the raw images will be available upon request. Potentially, a minimal example dataset will be shared on https://idr.openmicroscopy.org/ or a similar database. If the situation changes in the future, we will upload the data to available databases. When will the data be made available? When will the data be made available? All research outputs (data, documentation, code, and associated metadata) will be made openly accessible at the latest at the time of publication. No embargo will be foreseen unless imposed e.g. by pending publications, potential IP requirements – note that patent application filing will be planned so that publications need not be delayed - or ongoing projects requiring confidential data. In those cases, datasets will be made publicly available as soon as the embargo date is reached. Which data usage licenses are you going to provide? If none, please explain why. Which data usage licenses are you going to provide? If none, please explain why. Data is typically available under a Creative Commons CC0 1.0 Universal (CC0 1.0) Public Domain Dedication, a Creative Commons Attribution (CC-BY), or an ODC Public Domain Dedication and Licence, with a material transfer agreement when applicable. Software and code usually are available under a GNU General Public License or an Academic Non-commercial Software License. Created using DMPonline.be. Last modiﬁed 30 May 2024 12 of 13 Do you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the comment Do you intend to add a PID/DOI/accession number to your dataset(s)? If already available, you have the option to provide it in the comment section. section. Yes What are the expected costs for data sharing? How will these costs be covered? What are the expected costs for data sharing? How will these costs be covered? It is the intention to minimize data management costs by implementing standard procedures e.g. for metadata collection and file storage and organization from the start of the project, and by using free-to-use data repositories and dissemination facilities whenever possible. Data management costs will be covered by the laboratory budget. 6. Responsibilities 6. Responsibilities Who will manage data documentation and metadata during the research project? Who will manage data documentation and metadata during the research project? The researchers who generate the data are responsible for managing data, documentation, and metadata. Who will manage data storage and backup during the research project? Who will manage data storage and backup during the research project? The researchers who generate the data are responsible for storage and backup, with support from René Custers and Alexander Botzki for the electronic laboratory notebook (ELN) and from Raf De Coster for the KU Leuven drives. Who will manage data preservation and sharing? Who will manage data preservation and sharing? Lars Borm and Stein Aerts are responsible for data preservation and sharing, with support from the research and technical staff involved in the project, from René Custers and Alexander Botzki for the electronic laboratory notebook (ELN) and from Raf De Coster for the KU Leuven drives. Who will update and implement this DMP? Who will update and implement this DMP? Lars Borm and Stein Aerts are ultimately responsible for all data management during and after data collection, including implementing and updating the DMP. Created using DMPonline.be. Last modiﬁed 30 May 2024 13 of 13"
}